source,title,url,published,summary
Anthropic News,"Jan 13, 2026 Announcements Introducing Anthropic Labs",https://www.anthropic.com/news/introducing-anthropic-labs,2026-01-13 22:43:39,
Anthropic News,"Jan 11, 2026 Announcements Advancing Claude in healthcare and the life sciences",https://www.anthropic.com/news/healthcare-life-sciences,2026-01-11 22:38:42,
NVIDIA Technical Blog,Multi-Agent Warehouse AI Command Layer Enables Operational Excellence and Supply Chain Intelligence,https://developer.nvidia.com/blog/multi-agent-warehouse-ai-command-layer-enables-operational-excellence-and-supply-chain-intelligence,2026-01-09 14:00:00+0000,"Warehouses have never been more automated, more data-rich, or more operationally demanding than they are now—yet they still rely on systems that can’t keep..."
NVIDIA Technical Blog,"Build an AI Catalog System That Delivers Localized, Interactive Product Experiences",https://developer.nvidia.com/blog/build-an-ai-catalog-system-that-delivers-localized-interactive-product-experiences,2026-01-09 14:00:00+0000,"E-commerce catalogs often contain sparse product data, generic images, a basic title, and short description. This limits discoverability, engagement, and..."
NVIDIA Technical Blog,Delivering Massive Performance Leaps for Mixture of Experts Inference on NVIDIA Blackwell,https://developer.nvidia.com/blog/delivering-massive-performance-leaps-for-mixture-of-experts-inference-on-nvidia-blackwell,2026-01-08 19:43:16+0000,"As AI models continue to get smarter, people can rely on them for an expanding set of tasks. This leads users—from consumers to enterprises—to interact with..."
NVIDIA Technical Blog,Accelerating LLM and VLM Inference for Automotive and Robotics with NVIDIA TensorRT Edge-LLM,https://developer.nvidia.com/blog/accelerating-llm-and-vlm-inference-for-automotive-and-robotics-with-nvidia-tensorrt-edge-llm,2026-01-08 17:28:49+0000,Large language models (LLMs) and multimodal reasoning systems are rapidly expanding beyond the data center. Automotive and robotics developers increasingly want...
NVIDIA Technical Blog,Redefining Secure AI Infrastructure with NVIDIA BlueField Astra for NVIDIA Vera Rubin NVL72,https://developer.nvidia.com/blog/redefining-secure-ai-infrastructure-with-nvidia-bluefield-astra-for-nvidia-vera-rubin-nvl72,2026-01-07 17:00:00+0000,"Large-scale AI innovation is driving unprecedented demand for accelerated computing infrastructure. Training trillion-parameter foundation models, serving them..."
NVIDIA Technical Blog,Introducing NVIDIA BlueField-4-Powered Inference Context Memory Storage Platform for the Next Frontier of AI,https://developer.nvidia.com/blog/introducing-nvidia-bluefield-4-powered-inference-context-memory-storage-platform-for-the-next-frontier-of-ai,2026-01-06 17:30:00+0000,AI‑native organizations increasingly face scaling challenges as agentic AI workflows drive context windows to millions of tokens and models scale toward...
NVIDIA Technical Blog,Open-Source AI Tool Upgrades Speed Up LLM and Diffusion Models on NVIDIA RTX PCs,https://developer.nvidia.com/blog/open-source-ai-tool-upgrades-speed-up-llm-and-diffusion-models-on-nvidia-rtx-pcs,2026-01-06 05:30:00+0000,"AI developer activity on PCs is exploding, driven by the rising quality of small language models (SLMs) and diffusion models, such as FLUX.2, GPT-OSS-20B, and..."
NVIDIA Technical Blog,"Inside the NVIDIA Rubin Platform: Six New Chips, One AI Supercomputer",https://developer.nvidia.com/blog/inside-the-nvidia-rubin-platform-six-new-chips-one-ai-supercomputer,2026-01-05 22:20:12+0000,AI has entered an industrial phase. What began as systems performing discrete AI model training and human-facing inference has evolved into always-on AI...
NVIDIA Technical Blog,Accelerate AI Inference for Edge and Robotics with NVIDIA Jetson T4000 and NVIDIA JetPack 7.1,https://developer.nvidia.com/blog/accelerate-ai-inference-for-edge-and-robotics-with-nvidia-jetson-t4000-and-nvidia-jetpack-7-1,2026-01-05 22:10:52+0000,"NVIDIA is introducing the NVIDIA Jetson T4000, bringing high-performance AI and real-time reasoning to a wider range of robotics and edge AI applications...."
鹿島建設 プレス,米国森林ファンドへの出資を通じて、脱炭素および自然再興の実現を加速,202512/24e1-j.htm,2025-12-24 22:38:45,
Sony AI News,Learn More,https://ai.sony/blog/Sony-AI-2025-Year-in-Review,2025-12-22 22:39:51,
NVIDIA Technical Blog,Accelerating AI-Powered Chemistry and Materials Science Simulations with NVIDIA ALCHEMI Toolkit-Ops,https://developer.nvidia.com/blog/accelerating-ai-powered-chemistry-and-materials-science-simulations-with-nvidia-alchemi-toolkit-ops,2025-12-19 17:00:00+0000,Machine learning interatomic potentials (MLIPs) are transforming the landscape of computational chemistry and materials science. MLIPs enable atomistic...
鹿島建設 プレス,ユニバーサル・スタジオ・ジャパン オフィシャルホテル唯一の外資系ホテル 「Osaka Sakurajima Resort」プロジェクトが本格着工,202512/18a1-j.htm,2025-12-18 22:39:19,
Anthropic News,"Dec 18, 2025 Announcements Protecting the well-being of our users",https://www.anthropic.com/news/protecting-well-being-of-users,2025-12-18 22:39:11,
Anthropic News,"Dec 18, 2025 Announcements Working with the US Department of Energy to unlock the next era of scientific discovery",https://www.anthropic.com/news/genesis-mission-partnership,2025-12-18 22:39:11,
NVIDIA Technical Blog,"Real-Time Decoding, Algorithmic GPU Decoders, and AI Inference Enhancements in NVIDIA CUDA-Q QEC",https://developer.nvidia.com/blog/real-time-decoding-algorithmic-gpu-decoders-and-ai-inference-enhancements-in-nvidia-cuda-q-qec,2025-12-17 21:32:50+0000,Real-time decoding is crucial to fault-tolerant quantum computers. By enabling decoders to operate with low latency concurrently with a quantum processing unit...
NVIDIA Technical Blog,Using AI Physics for Technology Computer-Aided Design Simulations,https://developer.nvidia.com/blog/using-ai-physics-for-technology-computer-aided-design-simulations,2025-12-17 16:00:00+0000,"Technology Computer-Aided Design (TCAD) simulations, encompassing both process and device simulations, are crucial for modern semiconductor manufacturing. They..."
NVIDIA Technical Blog,Optimizing Semiconductor Defect Classification with Generative AI and Vision Foundation Models,https://developer.nvidia.com/blog/optimizing-semiconductor-defect-classification-with-generative-ai-and-vision-foundation-models,2025-12-17 02:00:00+0000,"In the heart of every modern electronic device lies a silicon chip, built through a manufacturing process so precise that even a microscopic defect can..."
NVIDIA Technical Blog,Accelerating Long-Context Inference with Skip Softmax in NVIDIA TensorRT-LLM,https://developer.nvidia.com/blog/accelerating-long-context-inference-with-skip-softmax-in-nvidia-tensorrt-llm,2025-12-16 21:00:00+0000,"For machine learning engineers deploying LLMs at scale, the equation is familiar and unforgiving: as context length increases, attention computation costs..."
NVIDIA Technical Blog,"AI Factories, Physical AI, and Advances in Models, Agents, and Infrastructure That Shaped 2025",https://developer.nvidia.com/blog/ai-factories-physical-ai-and-advances-in-models-agents-and-infrastructure-that-shaped-2025,2025-12-16 17:30:00+0000,"2025 was another milestone year for developers and researchers working with NVIDIA technologies. Progress in data center power and compute design, AI..."
Sony AI News,"December 15, 2025 | Sony AI Protecting Creator窶冱 Rights in the Age of AI",https://ai.sony/blog/Protecting-Creator窶冱-Rights-in-the-Age-of-AI,2025-12-15 22:39:50,
Sony AI News,Learn More,https://ai.sony/blog/Protecting-Creator%E2%80%99s-Rights-in-the-Age-of-AI,2025-12-15 22:39:50,
NVIDIA Technical Blog,Delivering Flexible Performance for Future-Ready Data Centers with NVIDIA MGX,https://developer.nvidia.com/blog/delivering-flexible-performance-for-future-ready-data-centers-with-nvidia-mgx,2025-12-15 18:25:18+0000,The AI boom reshaping the computing landscape is poised to scale even faster in 2026. As breakthroughs in model capability and computing power drive rapid...
NVIDIA Technical Blog,"Inside NVIDIA Nemotron 3: Techniques, Tools, and Data That Make It Efficient and Accurate",https://developer.nvidia.com/blog/inside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate,2025-12-15 14:00:00+0000,"Agentic AI systems increasingly rely on collections of cooperating agents—retrievers, planners, tool executors, verifiers—working together across large..."
NVIDIA Technical Blog,How to Train Scientific Agents with Reinforcement Learning,https://developer.nvidia.com/blog/how-to-train-scientific-agents-with-reinforcement-learning,2025-12-15 14:00:00+0000,"The scientific process can be repetitive and tedious, with researchers spending hours digging through papers, managing experiment workflows, or wrangling..."
NVIDIA Technical Blog,Enabling Horizontal Autoscaling of Enterprise RAG Components on Kubernetes,https://developer.nvidia.com/blog/enabling-horizontal-autoscaling-of-enterprise-rag-components-on-kubernetes,2025-12-12 21:00:00+0000,Today’s best AI agents rely on retrieval-augmented generation (RAG) to enable more accurate results. A RAG system facilitates the use of a knowledge base to...
NVIDIA Technical Blog,NVIDIA Blackwell Enables 3x Faster Training and Nearly 2x Training Performance Per Dollar than Previous-Gen Architecture,https://developer.nvidia.com/blog/nvidia-blackwell-enables-3x-faster-training-and-nearly-2x-training-performance-per-dollar-than-previous-gen-architecture,2025-12-11 19:20:31+0000,"AI innovation continues to be driven by three scaling laws: pre-training, post-training, and test-time scaling. Training is foundational to building smarter..."
NVIDIA Technical Blog,Next-Generation AI Factory Telemetry with NVIDIA Spectrum-X Ethernet,https://developer.nvidia.com/blog/next-generation-ai-factory-telemetry-with-nvidia-spectrum-x-ethernet,2025-12-11 19:03:51+0000,"As AI data centers rapidly evolve into AI factories, traditional network monitoring methods are no longer sufficient. Workloads continue to grow in complexity..."
NVIDIA Technical Blog,"Getting Started with Edge AI on NVIDIA Jetson: LLMs, VLMs, and Foundation Models for Robotics",https://developer.nvidia.com/blog/getting-started-with-edge-ai-on-nvidia-jetson-llms-vlms-and-foundation-models-for-robotics,2025-12-11 16:00:00+0000,"Running advanced AI and computer vision workloads on small, power-efficient devices at the edge is a growing challenge. Robots, smart cameras, and autonomous..."
NVIDIA Technical Blog,Enhancing Communication Observability of AI Workloads with NCCL Inspector,https://developer.nvidia.com/blog/enhancing-communication-observability-of-ai-workloads-with-nccl-inspector,2025-12-10 21:45:34+0000,When using the NVIDIA Collective Communication Library (NCCL) to run a deep learning training or inference workload that uses collective operations (such as...
Anthropic News,"Dec 9, 2025 Announcements Donating the Model Context Protocol and establishing the Agentic AI Foundation",https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation,2025-12-09 22:36:31,
Anthropic News,"Dec 9, 2025 Announcements Accenture and Anthropic launch multi-year partnership to move enterprises from AI pilots to production",https://www.anthropic.com/news/anthropic-accenture-partnership,2025-12-09 22:36:31,
NVIDIA Technical Blog,"Top 5 AI Model Optimization Techniques for Faster, Smarter Inference",https://developer.nvidia.com/blog/top-5-ai-model-optimization-techniques-for-faster-smarter-inference,2025-12-09 18:00:00+0000,"As AI models get larger and architectures more complex, researchers and engineers are continuously finding new techniques to optimize the performance and..."
NVIDIA Technical Blog,Improve AI-Native 6G Design with the NVIDIA Aerial Omniverse Digital Twin,https://developer.nvidia.com/blog/improve-ai-native-6g-design-with-the-nvidia-aerial-omniverse-digital-twin,2025-12-09 17:00:00+0000,"AI-native 6G networks will serve billions of intelligent devices, agents, and machines. As the industry moves into new spectrums like FR3 (7–24 GHz), radio..."
NVIDIA Technical Blog,Automate Kubernetes AI Cluster Health with NVSentinel,https://developer.nvidia.com/blog/automate-kubernetes-ai-cluster-health-with-nvsentinel,2025-12-08 18:00:00+0000,"Kubernetes underpins a large portion of all AI workloads in production. Yet, maintaining GPU nodes and ensuring that applications are running, training jobs are..."
renue ニュース,2025.12.04 Findy アーキテクチャConference 2025 に参加しました エンジニアのための情報共有コミュニティ「Zenn」にて配信されました。,https://renue.co.jp/posts/article-10,2025-12-05 22:37:39,
NVIDIA Technical Blog,NVIDIA CUDA 13.1 Powers Next-Gen GPU Programming with NVIDIA CUDA Tile and Performance Gains,https://developer.nvidia.com/blog/nvidia-cuda-13-1-powers-next-gen-gpu-programming-with-nvidia-cuda-tile-and-performance-gains,2025-12-04 22:20:56+0000,"NVIDIA CUDA 13.1 introduces the largest and most comprehensive update to the CUDA platform since it was invented two decades ago.  In this release,..."
Anthropic News,"Dec 3, 2025 Announcements Snowflake and Anthropic announce $200 million partnership to bring agentic AI to global enterprises",https://www.anthropic.com/news/snowflake-anthropic-expanded-partnership,2025-12-03 22:38:46,
Anthropic News,"Dec 2, 2025 Announcements Claude for Nonprofits",https://www.anthropic.com/news/claude-for-nonprofits,2025-12-02 22:35:59,
NVIDIA Technical Blog,AWS Integrates AI Infrastructure with NVIDIA NVLink Fusion for Trainium4 Deployment,https://developer.nvidia.com/blog/aws-integrates-ai-infrastructure-with-nvidia-nvlink-fusion-for-trainium4-deployment,2025-12-02 16:00:00+0000,"As demand for AI continues to grow, hyperscalers are looking for ways to accelerate deployment of specialized AI infrastructure with the highest performance...."
NVIDIA Technical Blog,Train Small Orchestration Agents to Solve Big Problems,https://developer.nvidia.com/blog/train-small-orchestration-agents-to-solve-big-problems,2025-12-01 23:25:36+0000,"Using the right tool and model for a task is a challenging and ever-present engineering problem in agent design. At NVIDIA Research, we're making fast progress..."
鹿島建設 プレス,『Yard miyakojima』2026年4月1日 開業予定,202512/pdf/1a1-j.pdf,2025-12-01 22:37:56,
Sony AI News,Learn More,https://ai.sony/blog/NeurIPS%202025-Sony-AI窶冱-Latest-Contributions,2025-12-01 22:37:52,
Sony AI News,"December 1, 2025 | Events NeurIPS 2025: Sony AI窶冱 Latest Contributions",https://ai.sony/blog/NeurIPS 2025-Sony-AI窶冱-Latest-Contributions,2025-12-01 22:37:52,
Sony AI News,Learn More,https://ai.sony/blog/Advancing-AI-Highlights-from-November,2025-12-01 22:37:52,
NVIDIA Technical Blog,Build Efficient Financial Data Workflows with AI Model Distillation,https://developer.nvidia.com/blog/build-efficient-financial-data-workflows-with-ai-model-distillation,2025-12-01 22:00:17+0000,"Large language models (LLMs) in quantitative finance are increasingly being used for alpha generation, automated report analysis, and risk prediction. Yet..."
NVIDIA Technical Blog,Making GPU Clusters More Efficient with NVIDIA Data Center Monitoring,https://developer.nvidia.com/blog/making-gpu-clusters-more-efficient-with-nvidia-data-center-monitoring,2025-11-25 21:00:00+0000,"High-performance computing (HPC) customers continue to scale rapidly, with generative AI, large language models (LLMs), computer vision, and other uses leading..."
Anthropic News,"Introducing Claude Opus 4.5 Announcements Nov 24, 2025 The best model in the world for coding, agents, and computer use, with meaningful improvements to everyday tasks like slides and spreadsheets. Claude Opus 4.5 delivers frontier performance and dramatically improved token efficiency.",https://www.anthropic.com/news/claude-opus-4-5,2025-11-24 22:37:29,
NVIDIA Technical Blog,"Model Quantization: Concepts, Methods, and Why It Matters",https://developer.nvidia.com/blog/model-quantization-concepts-methods-and-why-it-matters,2025-11-24 19:23:48+0000,"AI models are becoming increasingly complex, often exceeding the capabilities of available hardware. Quantization has emerged as a crucial technique to address..."
Apple ML Research,Neural Information Processing Systems (NeurIPS) 2025,https://machinelearning.apple.com/updates/apple-at-neurips-2025,2025-11-21 00:00:00+0000,"Apple is presenting new research at the annual conference on Neural Information Processing Systems (NeurIPS) , which takes place in person in San Diego, California, from December 2 – 7. We are proud to again sponsor the multi-track interdisciplinary conference, which brings together the scientific and industrial research communities surrounding Machine Learning. Below is an overview of Apple’s participation at NeurIPS 2025."
Anthropic News,Availability,https://www.anthropic.com/supported-countries,2025-11-20 22:34:15,
Anthropic News,Economic Futures,https://www.anthropic.com/economic-index,2025-11-20 22:34:15,
NVIDIA Technical Blog,Breaking Through Reinforcement Learning Training Limits with Scaling Rollouts in BroRL,https://developer.nvidia.com/blog/breaking-through-rl-training-limits-with-scaling-rollouts-in-brorl,2025-11-19 21:51:12+0000,"When training large language models (LLMs) with reinforcement learning from verifiable rewards (RLVR), one of the most compelling questions is how to overcome..."
Anthropic News,"Announcements Microsoft, NVIDIA, and Anthropic announce strategic partnerships Nov 18, 2025",https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships,2025-11-18 22:37:57,
Anthropic News,"Product Claude now available in Microsoft Foundry and Microsoft 365 Copilot Nov 18, 2025",https://www.anthropic.com/news/claude-in-microsoft-foundry,2025-11-18 22:37:57,
NVIDIA Technical Blog,Building Scalable AI on Enterprise Data with NVIDIA Nemotron RAG and Microsoft SQL Server 2025,https://developer.nvidia.com/blog/building-scalable-ai-on-enterprise-data-with-nvidia-nemotron-rag-and-microsoft-sql-server-2025,2025-11-18 20:00:00+0000,"At Microsoft Ignite 2025, the vision for an AI-ready enterprise database becomes a reality with the announcement of Microsoft SQL Server 2025, giving developers..."
NVIDIA Technical Blog,Faster Chemistry and Materials Discovery with AI-Powered Simulations Using NVIDIA ALCHEMI,https://developer.nvidia.com/blog/faster-chemistry-and-materials-discovery-with-ai-powered-simulations-using-nvidia-alchemi,2025-11-18 17:00:00+0000,"Almost all manufactured products are enabled by chemistry and materials science. However, new discoveries are costly and time-consuming and often hindered by..."
鹿島建設 プレス,橋梁の損傷・健全度診断を支援するWebシステム「BMStar ® _AI」を開発・運用,202511/17c1-j.htm,2025-11-17 22:37:26,
Anthropic News,"Announcements Anthropic partners with Rwandan Government and ALX to bring AI education to hundreds of thousands of learners across Africa Nov 18, 2025",https://www.anthropic.com/news/rwandan-government-partnership-ai-education,2025-11-17 22:37:17,
Cohere Blog,Modern Slavery Act,https://cohere.com/modern-slavery-statement,2025-11-14 22:36:54,
安藤ハザマ ニュース,メタバース技術展示 当社の注目技術や技術研究所の最新施設を紹介する展示会場を、メタバース空間に開設しました!,https://www.ad-hzm.co.jp/lp/exhibition/2025,2025-11-13 22:37:23,
鹿島建設 プレス,「建設現場から排出される廃プラのケミカルリサイクル実証事業」に着手,202511/13e1-j.htm,2025-11-13 22:37:22,
Anthropic News,"Product Measuring political bias in Claude Nov 13, 2025",https://www.anthropic.com/news/political-even-handedness,2025-11-13 22:37:12,
Anthropic News,"Announcements The state of Maryland partners with Anthropic to better serve residents Nov 13, 2025",https://www.anthropic.com/news/maryland-partnership,2025-11-13 22:37:12,
鹿島建設 プレス,「日本橋本町 M-SQUARE」竣工 緑豊かな共用空間を整備し環境に配慮したオフィスが日本橋本町に誕生,202511/pdf/12a1-j.pdf,2025-11-12 22:35:02,
Anthropic News,"Announcements Anthropic invests $50 billion in American AI infrastructure Nov 12, 2025",https://www.anthropic.com/news/anthropic-invests-50-billion-in-american-ai-infrastructure,2025-11-12 22:34:57,
NVIDIA Technical Blog,NVIDIA Blackwell Architecture Sweeps MLPerf Training v5.1 Benchmarks,https://developer.nvidia.com/blog/nvidia-blackwell-architecture-sweeps-mlperf-training-v5-1-benchmarks,2025-11-12 16:00:00+0000,"The NVIDIA Blackwell architecture powered the fastest time to train across every MLPerf Training v5.1 benchmark, marking a clean sweep in the latest round of..."
NVIDIA Technical Blog,Upcoming Livestream: Build Visual AI Agents with NVIDIA Cosmos Reason and Metropolis,https://www.addevent.com/event/kffjqsqb67nq,2025-11-10 22:22:56+0000,"On November 18, learn how to fine-tune the NVIDIA Cosmos Reason VLM with your own data to create visual AI agents."
NVIDIA Technical Blog,Building Scalable and Fault-Tolerant NCCL Applications,https://developer.nvidia.com/blog/building-scalable-and-fault-tolerant-nccl-applications,2025-11-10 21:29:37+0000,"The NVIDIA Collective Communications Library (NCCL) provides communication APIs for low-latency and high-bandwidth collectives, enabling AI workloads to scale..."
NVIDIA Technical Blog,Training XGBoost Models with GPU-Accelerated Polars DataFrames,https://developer.nvidia.com/blog/training-xgboost-models-with-gpu-accelerated-polars-dataframes,2025-11-10 19:30:00+0000,"One of the many strengths of the PyData ecosystem is interoperability, which enables seamlessly moving data between libraries that specialize in exploratory..."
NVIDIA Technical Blog,"Gen AI Super-resolution Accelerates Weather Prediction with Scalable, Low-Compute Models",https://developer.nvidia.com/blog/gen-ai-super-resolution-accelerates-weather-prediction-with-scalable-low-compute-models,2025-11-10 19:29:53+0000,"As AI weather and climate prediction models rapidly gain adoption, the NVIDIA Earth-2 platform provides libraries and tools for accelerating solutions using a..."
NVIDIA Technical Blog,Streamline Complex AI Inference on Kubernetes with NVIDIA Grove,https://developer.nvidia.com/blog/streamline-complex-ai-inference-on-kubernetes-with-nvidia-grove,2025-11-10 14:00:00+0000,"Over the past few years, AI inference has evolved from single-model, single-pod deployments into complex, multicomponent systems. A model deployment may now..."
NVIDIA Technical Blog,Enabling Multi-Node NVLink on Kubernetes for NVIDIA GB200 NVL72 and Beyond,https://developer.nvidia.com/blog/enabling-multi-node-nvlink-on-kubernetes-for-gb200-and-beyond,2025-11-10 14:00:00+0000,"The NVIDIA GB200 NVL72 pushes AI infrastructure to new limits, enabling breakthroughs in training large-language models and running scalable, low-latency..."
Sony AI News,Learn More,https://ai.sony/blog/The-FHIBE-Team-Data-Dignity-and-the-People-Who-Made-It-Possible,2025-11-07 22:35:52,
Anthropic News,"Announcements New offices in Paris and Munich expand Anthropic窶冱 European presence Nov 07, 2025",https://www.anthropic.com/news/new-offices-in-paris-and-munich-expand-european-presence,2025-11-07 22:35:50,
Anthropic News,"Announcements Cognizant will make Claude available to 350,000 employees, accelerating enterprise AI adoption and internal transformation Nov 04, 2025",https://www.anthropic.com/news/cognizant-partnership,2025-11-06 22:35:47,
NVIDIA Technical Blog,Accelerating Large-Scale Mixture-of-Experts Training in PyTorch,https://developer.nvidia.com/blog/accelerating-large-scale-mixture-of-experts-training-in-pytorch,2025-11-06 17:00:00+0000,Training massive mixture-of-experts (MoE) models has long been the domain of a few advanced users with deep infrastructure and distributed-systems expertise....
NVIDIA Technical Blog,Scale Biology Transformer Models with PyTorch and NVIDIA BioNeMo Recipes,https://developer.nvidia.com/blog/scale-biology-transformer-models-with-pytorch-and-nvidia-bionemo-recipes,2025-11-05 16:00:00+0000,"Training models with billions or trillions of parameters demands advanced parallel computing. Researchers must decide how to combine parallelism strategies,..."
鹿島建設 プレス,ハイグレードオフィス「名古屋伏見Kフロンティア」が竣工,202511/4a1-j.htm,2025-11-04 22:35:56,
NVIDIA Technical Blog,Make Sense of Video Analytics by Integrating NVIDIA AI Blueprints,https://developer.nvidia.com/blog/make-sense-of-video-analytics-by-integrating-nvidia-ai-blueprints,2025-11-03 21:48:11+0000,"Organizations are increasingly seeking ways to extract insights from video, audio, and other complex data sources. Retrieval-augmented generation (RAG) enables..."
NVIDIA Technical Blog,How Code Execution Drives Key Risks in Agentic AI Systems,https://developer.nvidia.com/blog/how-code-execution-drives-key-risks-in-agentic-ai-systems,2025-11-03 17:54:01+0000,"AI-driven applications are evolving from passive tools to agentic systems that generate code, make decisions, and take autonomous actions. This shift introduces..."
Sony AI News,Learn More,https://ai.sony/blog/Advancing-AI-Highlights-from-October,2025-10-31 22:35:15,
鹿島建設 プレス,ソフトウェアの標準化技術を活用した建設ロボットシステムの研究開発に着手,202510/pdf/30a1-j.pdf,2025-10-30 22:34:34,
鹿島建設 プレス,ポップカルチャーとテクノロジーの未来を体験できるイベント『ちょっと先のおもしろい未来 -CHANGE TOMORROW-』を開催,202510/pdf/29a1-j.pdf,2025-10-29 22:36:43,
Anthropic News,"Announcements Anthropic officially opens Tokyo office, signs Memorandum of Cooperation with the Japan AI Safety Institute Oct 29, 2025",https://www.anthropic.com/news/opening-our-tokyo-office,2025-10-29 22:36:34,
鹿島建設 プレス,「湯西川ダム新水力発電所設置・運営事業」の事業候補者に特定,202510/pdf/28c1-j.pdf,2025-10-28 22:35:34,
NVIDIA Technical Blog,Introducing the CodonFM Open Model for RNA Design and Analysis,https://developer.nvidia.com/blog/introducing-the-codonfm-open-model-for-rna-design-and-analysis,2025-10-28 20:00:00+0000,"Open research is critical for driving innovation, and many breakthroughs in AI and science are achieved through open collaboration. In the field of digital..."
NVIDIA Technical Blog,"Develop Specialized AI Agents with New NVIDIA Nemotron Vision, RAG, and Guardrail Models",https://developer.nvidia.com/blog/develop-specialized-ai-agents-with-new-nvidia-nemotron-vision-rag-and-guardrail-models,2025-10-28 17:32:45+0000,"Agentic AI is an ecosystem where specialized language and vision models work together. They handle planning, reasoning, retrieval, and safety guardrailing...."
鹿島建設 プレス,世界最高レベルの制震効率を発揮する電気不要の環境配慮型オイルダンパー「HiDAX ® -Re」を開発,202510/27a1-j.htm,2025-10-27 22:34:17,
Anthropic News,"Announcements Advancing Claude for Financial Services Oct 27, 2025",https://www.anthropic.com/news/advancing-claude-for-financial-services,2025-10-27 22:34:07,
Mistral AI News,AI Studio,https://mistral.ai/products/ai-studio,2025-10-24 22:35:03,
Mistral AI News,"Introducing Mistral AI Studio. Product October 24, 2025 Mistral AI The Production AI Platform.",https://mistral.ai/news/ai-studio,2025-10-24 22:35:03,
鹿島建設 プレス,東京証券取引所ビル本館で耐震バリューアップを実施,202510/pdf/23a1-j.pdf,2025-10-23 22:34:05,
Sony AI News,Learn More,https://ai.sony/blog/Sights%20on%20AI:%20Expanding-Human-Perception-Through-AI-A-Conversation-with-Daisuke-Iso,2025-10-23 22:34:01,
Sony AI News,"October 23, 2025 | Imaging & Sensing Sony AI Sights on AI: Expanding Human Perception Through AI – A Conversation with Daisuke Iso",https://ai.sony/blog/Sights on AI: Expanding-Human-Perception-Through-AI-A-Conversation-with-Daisuke-Iso,2025-10-23 22:34:01,
Anthropic News,"Announcements Expanding our use of Google Cloud TPUs and Services Oct 23, 2025",https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services,2025-10-23 22:34:00,
Anthropic News,"Announcements A statement from Dario Amodei on Anthropic's commitment to American AI leadership Oct 21, 2025",https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership,2025-10-21 22:31:47,
NVIDIA Technical Blog,Build Practical Deep-Learning Skills for Real-World AI Applications with the New NVIDIA Learning Path,https://www.nvidia.com/en-us/learn/learning-path/deep-learning,2025-10-21 20:05:06+0000,"Check out the learning path page and sign up for courses, workshops, and certifications to help develop your skills."
Anthropic News,"Announcements Claude for Life Sciences Oct 20, 2025",https://www.anthropic.com/news/claude-for-life-sciences,2025-10-20 22:34:07,
Anthropic News,"Product Claude Code on the web Oct 20, 2025",https://www.anthropic.com/news/claude-code-on-the-web,2025-10-20 22:34:07,
NVIDIA Technical Blog,Build an AI Agent to Analyze IT Tickets with NVIDIA Nemotron,https://developer.nvidia.com/blog/build-an-ai-agent-to-analyze-it-tickets-with-nvidia-nemotron,2025-10-20 17:00:00+0000,"Modern organizations generate a massive volume of operational data through ticketing systems, incident reports, service requests, support escalations, and more...."
NVIDIA Technical Blog,Enabling Scalable AI-Driven Molecular Dynamics Simulations,https://developer.nvidia.com/blog/enabling-scalable-ai-driven-molecular-dynamics-simulations,2025-10-20 16:30:00+0000,"Molecular dynamics (MD) simulations are a powerful tool in computational chemistry and materials science, and they’re essential for studying chemical..."
NVIDIA Technical Blog,Scaling Large MoE Models with Wide Expert Parallelism on NVL72 Rack Scale Systems,https://developer.nvidia.com/blog/scaling-large-moe-models-with-wide-expert-parallelism-on-nvl72-rack-scale-systems,2025-10-20 16:00:00+0000,"Modern AI workloads have moved well beyond single-GPU inference serving. Model parallelism, which efficiently splits computation across many GPUs, is now the..."
鹿島建設 プレス,現場見学会「鹿島サマースクール」に82名が参加,202510/17m1-j.htm,2025-10-17 22:33:45,
Anthropic News,"Product Introducing Claude Skills Oct 16, 2025",https://www.anthropic.com/news/skills,2025-10-16 22:31:58,
Anthropic News,"Product Claude and your productivity platforms Oct 16, 2025",https://www.anthropic.com/news/productivity-platforms,2025-10-16 22:31:58,
Anthropic News,"Product Introducing Claude Haiku 4.5 Oct 15, 2025",https://www.anthropic.com/news/claude-haiku-4-5,2025-10-15 22:33:06,
NVIDIA Technical Blog,Agentic AI Unleashed: Join the AWS & NVIDIA Hackathon,https://nvidia-aws.devpost.com/,2025-10-15 19:39:20+0000,"Build the next generation of intelligent, autonomous applications. This isn't just a hackathon—it's your chance to unleash the power of agentic AI and show..."
NVIDIA Technical Blog,"Unlock Faster, Smarter Edge Models with 7x Gen AI Performance on NVIDIA Jetson AGX Thor",https://developer.nvidia.com/blog/unlock-faster-smarter-edge-models-with-7x-gen-ai-performance-on-nvidia-jetson-agx-thor,2025-10-15 18:25:01+0000,"A defining strength of the NVIDIA software ecosystem is its commitment to continuous optimization. In August, NVIDIA Jetson AGX Thor launched, with up to a 5x..."
NVIDIA Technical Blog,Accelerated and Distributed UPF for the Era of Agentic AI and 6G,https://developer.nvidia.com/blog/accelerated-and-distributed-upf-for-the-era-of-agentic-ai-and-6g,2025-10-15 18:06:57+0000,The telecommunications industry is innovating rapidly toward 6G for both AI-native Radio Access Networks (AI-RAN) and AI-Core. The distributed User Plane...
Anthropic News,"Announcements Anthropic and Salesforce expand partnership to bring Claude to regulated industries Oct 14, 2025",https://www.anthropic.com/news/salesforce-anthropic-expanded-partnership,2025-10-14 22:33:45,
NVIDIA Technical Blog,"Building the 800 VDC Ecosystem for Efficient, Scalable AI Factories",https://developer.nvidia.com/blog/building-the-800-vdc-ecosystem-for-efficient-scalable-ai-factories,2025-10-13 15:00:00+0000,"For decades, traditional data centers have been vast halls of servers with power and cooling as secondary considerations. The rise of generative AI has changed..."
Apple ML Research,International Conference on Computer Vision (ICCV) 2025,https://machinelearning.apple.com/updates/apple-at-iccv-2025,2025-10-13 00:00:00+0000,"Apple is presenting new work at the biennial International Conference on Computer Vision (ICCV) , which takes place in person from October 19 to 23, in Honolulu, Hawai’i. The conference alternates each year with the European Conference on Computer Vision (ECCV), and focuses on important topics the field of computer vision."
NVIDIA Technical Blog,Build a Log Analysis Multi-Agent Self-Corrective RAG System with NVIDIA Nemotron,https://developer.nvidia.com/blog/build-a-log-analysis-multi-agent-self-corrective-rag-system-with-nvidia-nemotron,2025-10-10 16:00:00+0000,"Logs are the lifeblood of modern systems. But as applications scale, logs often grow into endless walls of text—noisy, repetitive, and overwhelming. Hunting..."
鹿島建設 プレス,CO 2 -SUICOM製の大型ブロック擁壁を高速道路工事に初適用,202510/9c1-j.htm,2025-10-09 22:40:02,
Anthropic News,"Product Customize Claude Code with plugins Oct 09, 2025",https://www.anthropic.com/news/claude-code-plugins,2025-10-09 22:39:57,
NVIDIA Technical Blog,From Assistant to Adversary: Exploiting Agentic AI Developer Tools,https://developer.nvidia.com/blog/from-assistant-to-adversary-exploiting-agentic-ai-developer-tools,2025-10-09 16:00:00+0000,"Developers are increasingly turning to AI-enabled tools for coding, including Cursor, OpenAI Codex, Claude Code, and GitHub Copilot. While these automation..."
Anthropic News,"Announcements Expanding our global operations to India with our second Asia Pacific office Oct 07, 2025",https://www.anthropic.com/news/expanding-global-operations-to-india,2025-10-08 22:40:41,
NVIDIA Technical Blog,Training Federated AI Models to Predict Protein Properties,https://developer.nvidia.com/blog/training-federated-ai-models-to-predict-protein-properties,2025-10-08 16:58:05+0000,Predicting where proteins are located inside a cell is critical in biology and drug discovery. This process is known as subcellular localization. The location...
鹿島建設 プレス,施工延長が短い床版取替工事に適した「シングルSDR」を実工事に初導入,202510/7c1-j.htm,2025-10-07 22:39:31,
Anthropic News,"Announcements Rahul Patil joins Anthropic as Chief Technology Officer Oct 7, 2025",https://www.anthropic.com/news/rahul-patil-joins-anthropic,2025-10-07 22:39:22,
Anthropic News,"Announcements Deloitte will make Claude available to 470,000 people across its global network Oct 06, 2025",https://www.anthropic.com/news/deloitte-anthropic-partnership,2025-10-06 22:37:27,
NVIDIA Technical Blog,Speeding Up Data Decompression with nvCOMP and the NVIDIA Blackwell Decompression Engine,https://developer.nvidia.com/blog/speeding-up-data-decompression-with-nvcomp-and-the-nvidia-blackwell-decompression-engine,2025-10-06 16:00:00+0000,"Compression is a common technique to reduce storage costs and accelerate input/output transfer times across databases, data-center communications,..."
鹿島建設 プレス,クールな日本がここにある。“JAPAN”な夜を楽しむ「ハネダ夜街」イベント詳細決定,202510/pdf/3a1-j.pdf,2025-10-03 22:35:42,
鹿島建設 プレス,鹿島の社有林が地域生物多様性増進法に基づく自然共生サイトの第一弾に認定,202510/2e1-j.htm,2025-10-02 22:37:43,
Sony AI News,"September 9, 2025 | Sony AI Advancing Analog Design with AI: Sony AI’s Contributions at MLCAD 2025",https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI’s-Contributions-at-MLCAD-2025,2025-10-02 22:37:35,
Sony AI News,Learn More,https://ai.sony/blog/Advancing-AI-Highlights-from-September,2025-10-02 22:37:35,
鹿島建設 プレス,無垢の杉材を用いた木質耐火被覆工法「Tie-KaSOLID ® 」を実適用,202510/1a1-j.htm,2025-10-01 22:40:04,
Anthropic News,"Announcements How enterprises are driving AI transformation with Claude Oct 01, 2025",https://www.anthropic.com/news/driving-ai-transformation-with-claude,2025-10-01 22:39:54,
Anthropic News,"Product Claude and Slack Oct 01, 2025",https://www.anthropic.com/news/claude-and-slack,2025-10-01 22:39:54,
Anthropic News,"Product Enabling Claude Code to work more autonomously Sep 29, 2025",https://www.anthropic.com/news/enabling-claude-code-to-work-more-autonomously,2025-09-29 22:33:02,
Anthropic News,"Product Managing context on the Claude Developer Platform Sep 29, 2025",https://www.anthropic.com/news/context-management,2025-09-29 22:33:02,
Anthropic News,"Announcements Introducing Claude Sonnet 4.5 Sep 29, 2025",https://www.anthropic.com/news/claude-sonnet-4-5,2025-09-29 22:33:02,
NVIDIA Technical Blog,Smart Multi-Node Scheduling for Fast and Efficient LLM Inference with NVIDIA Run:ai and NVIDIA Dynamo,https://developer.nvidia.com/blog/smart-multi-node-scheduling-for-fast-and-efficient-llm-inference-with-nvidia-runai-and-nvidia-dynamo,2025-09-29 15:00:00+0000,"The exponential growth in large language model complexity has created challenges, such as models too large for single GPUs, workloads that demand high..."
NVIDIA Technical Blog,Upcoming Digital Event: Open Accelerated Computing Summit,https://events.zoom.us/ev/Ag9h43l88Btk65TlD9a2oZD5gLWhBD4HPbnApXEgazabeggG1Amq~Ah35JdKFc3kjnPkJVjccd7ubm35Av5p_vKJviCDFm-OnTsouYuioDrkaYg,2025-09-28 15:00:00+0000,Join the OAC Summit on October 7-8 and dive into recent research at the crossroads of AI and HPC.
NVIDIA Technical Blog,"Why CVEs Belong in Frameworks and Apps, Not AI Models",https://developer.nvidia.com/blog/why-cves-belong-in-frameworks-and-apps-not-ai-models,2025-09-26 16:31:23+0000,"The Common Vulnerabilities and Exposures (CVE) system is the global standard for cataloging security flaws in software. Maintained by MITRE and backed by CISA,..."
NVIDIA Technical Blog,How to Integrate Computer Vision Pipelines with Generative AI and Reasoning,https://developer.nvidia.com/blog/how-to-integrate-computer-vision-pipelines-with-generative-ai-and-reasoning,2025-09-25 16:42:53+0000,Generative AI is opening new possibilities for analyzing existing video streams. Video analytics are evolving from counting objects to turning raw video content...
NVIDIA Technical Blog,How to GPU-Accelerate Model Training with CUDA-X Data Science,https://developer.nvidia.com/blog/how-to-gpu-accelerate-model-training-with-cuda-x-data-science,2025-09-25 16:30:00+0000,"In previous posts on AI in manufacturing and operations, we covered the unique data challenges in the supply chain and how smart feature engineering can..."
鹿島建設 プレス,JR「関内」駅前 大規模ミクストユース型プロジェクト 「BASEGATE 横浜関内」2026年3月19日グランドオープン 入居テナント55店舗の詳細と小割飲食ゾーンの名称を発表,202509/pdf/24a1-j.pdf,2025-09-24 22:35:56,
Anthropic News,"Announcements Claude is now available in Microsoft 365 Copilot Sep 24, 2025",https://www.anthropic.com/news/claude-now-available-in-microsoft-365-copilot,2025-09-24 22:35:50,
NVIDIA Technical Blog,NVIDIA Open Sources Audio2Face Animation Model,https://developer.nvidia.com/blog/nvidia-open-sources-audio2face-animation-model,2025-09-24 17:00:00+0000,"By leveraging large language and speech models, generative AI is creating intelligent 3D avatars that can engage users in natural conversation, from video games..."
NVIDIA Technical Blog,Deploy High-Performance AI Models in Windows Applications on NVIDIA RTX AI PCs,https://developer.nvidia.com/blog/deploy-ai-models-faster-with-windows-ml-on-rtx-pcs,2025-09-23 19:20:46+0000,"Today, Microsoft is making Windows ML available to developers. Windows ML enables C#, C++ and Python developers to optimally run AI models locally across PC..."
NVIDIA Technical Blog,Faster Training Throughput in FP8 Precision with NVIDIA NeMo,https://developer.nvidia.com/blog/faster-training-throughput-in-fp8-precision-with-nvidia-nemo,2025-09-23 16:36:21+0000,"In previous posts on FP8 training, we explored the fundamentals of FP8 precision and took a deep dive into the various scaling recipes for practical large-scale..."
NVIDIA Technical Blog,Reasoning Through Molecular Synthetic Pathways with Generative AI,https://developer.nvidia.com/blog/reasoning-through-molecular-synthetic-pathways-with-generative-ai,2025-09-23 15:30:00+0000,"A recurring challenge in molecular design, whether for pharmaceutical, chemical, or material applications, is creating synthesizable molecules. Synthesizability..."
Anthropic News,Economic Futures,https://www.anthropic.com/economic-futures,2025-09-22 22:39:57,
安藤ハザマ ニュース,ZEB・ZEH 快適な省エネ建築物の設計・提案、技術開発に取り組んでいます。当社のZEB・ZEH取組方針や実績を紹介しています。,https://www.ad-hzm.co.jp/solution/zeb,2025-09-22 08:02:27,
安藤ハザマ ニュース,海外進出サポート,https://www.ad-hzm.co.jp/solution/overseas,2025-09-22 08:02:27,
安藤ハザマ ニュース,技術研究所 本館と幅広い分野の実験施設を備えた技術研究所では「人間と自然環境を結ぶ技術の創出」をコンセプトに掲げ、現在そして将来に向けた研究開発に取り組んでいます。,https://www.ad-hzm.co.jp/solution/laboratory,2025-09-22 08:02:27,
安藤ハザマ ニュース,技術・ ソリューション,https://www.ad-hzm.co.jp/solution,2025-09-22 08:02:27,
安藤ハザマ ニュース,第44回明治神宮薪能へのご招待 今年で第44回を迎える明治神宮薪能開催のお知らせです。,https://www.ad-hzm.co.jp/lp/takiginou/2025,2025-09-22 08:02:27,
安藤ハザマ ニュース,非財務データ,https://www.ad-hzm.co.jp/assets/pdf/sustainability/nd/non-financialdata.pdf,2025-09-22 08:02:27,
鹿島建設 プレス,KAJIMA MONTHLY REPORT - 月報KAJIMA,https://www.kajima.co.jp/news/digest/index-j.html,2025-09-22 08:02:26,
鹿島建設 プレス,“これぞ日本!”な食・遊・知のコンテンツがHICity ® に大集結 ナイトタイムイベント「ハネダ夜街」開催決定,202509/pdf/16a1-j.pdf,2025-09-22 08:02:26,
鹿島建設 プレス,リアルタイム3Dスキャンにより現場状況の”今”を3次元で見える化,202509/9c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,高速道路高架橋の耐震補強にUHPFRCを初適用,202509/4c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,南海トラフ地震「半割れ」を想定した広域連携BCP 訓練を実施,202509/2m1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,エレクタ付き2ノズル自動吹付け機を実工事に初導入,202509/1c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,「ANAホリデイ・インリゾート軽井沢」 9月12日(金)開業,202509/18a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,有害物質が付着した金属廃棄物の無害化・再資源化により、サーキュラーエコノミーを実現,202508/pdf/27e1-j.pdf,2025-09-22 08:02:26,
鹿島建設 プレス,仙台駅至近のビジネスエリアに高機能オフィスビル「NANT仙台南町」が開業,202508/7a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,ZEB Ready取得オフィスビル「芝御成門タワー」が竣工,202508/28a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,植物を用いた有用タンパク質生産のための研究開発拠点を設置しました,202507/pdf/9e1-j.pdf,2025-09-22 08:02:26,
鹿島建設 プレス,大規模複合施設「HANEDA INNOVATION CITY ® 」「NO BORDER BONODORI×台湾好包miniフェス」開催決定,202507/pdf/8a1-j.pdf,2025-09-22 08:02:26,
鹿島建設 プレス,「関内駅前北口地区第一種市街地再開発事業」関内駅前北口地区市街地再開発組合を設立,202507/pdf/7a1-j.pdf,2025-09-22 08:02:26,
鹿島建設 プレス,札幌4丁目プレイスの商業施設「4PLA」の全テナントが決定!地上2階・3階は8月7日、地下1階は10月9日に開業,202507/24a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,斜杭式桟橋・ドルフィン上部工のフルプレキャスト化の実現により、海上作業を大幅に省力化,202506/2c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,鹿島建設、SUBARU 光ファイバセンシング技術を用いた路車協調型自動運転の実証実験を開始,202506/24c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,カジマ・オーストラリア社が賃貸集合住宅(BTR)ファンドマネジメント事業に着手,202506/16m1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,「水災害トータルエンジニアリングサービス」による対策工事を自社技術研究所にて完了,202506/11a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,下水道光ファイバを活用した地中空洞化調査技術の開発を開始,202505/29c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,鹿島が「東北支店ビル」を新たな木造フラッグシップビルに建替え,202505/27a1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,バックホウ作業による既設構造物への接触や衝突を防止,202505/22c1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,棚田を未来へとつなぐ提案を開始,202505/21e1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,第32回鹿島美術財団 財団賞・優秀賞を決定,202505/16m1-j.htm,2025-09-22 08:02:26,
鹿島建設 プレス,赤坂一丁目で「三会堂ビル新築工事」が本格着工,202505/12a1-j.htm,2025-09-22 08:02:26,
Sakana AI News,corporate info,https://sakana.ai/company-info,2025-09-22 08:02:23,
Sony AI News,"August 26, 2025 | Game AI Gaming Life at Sony AI Robotics Sony AI Sony AI窶冱 Deep RL Team on Why the Hardest Problems Still Matter",https://ai.sony/blog/Sony-AI窶冱-Deep-RL-Team-on-Why-the-Hardest-Problems-Still-Matter,2025-09-22 08:02:23,
Sony AI News,"September 9, 2025 | Sony AI Advancing Analog Design with AI: Sony AI窶冱 Contributions at MLCAD 2025",https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI窶冱-Contributions-at-MLCAD-2025,2025-09-22 08:02:23,
Sony AI News,Learn More,https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI%e2%80%99s-Contributions-at-MLCAD-2025,2025-09-22 08:02:23,
Sony AI News,Learn More,https://ai.sony/blog/Advancing-AI-Highlights-from-August,2025-09-22 08:02:23,
Anthropic News,"Product Token-saving updates on the Anthropic API Mar 13, 2025",https://www.anthropic.com/news/token-saving-updates,2025-09-22 08:02:21,
Anthropic News,"Announcements Testing our safety defenses with a new bug bounty program May 14, 2025",https://www.anthropic.com/news/testing-our-safety-defenses-with-a-new-bug-bounty-program,2025-09-22 08:02:21,
Anthropic News,"Product Introducing the Max Plan Apr 09, 2025",https://www.anthropic.com/news/max-plan,2025-09-22 08:02:21,
Anthropic News,"Announcements Introducing the Anthropic Economic Advisory Council Apr 28, 2025",https://www.anthropic.com/news/introducing-the-anthropic-economic-advisory-council,2025-09-22 08:02:21,
Anthropic News,"Announcements Anthropic appoints Guillaume Princen as Head of EMEA and announces 100+ new roles across the region Apr 8, 2025",https://www.anthropic.com/news/head-of-EMEA-new-roles,2025-09-22 08:02:21,
NVIDIA Technical Blog,How to Reduce KV Cache Bottlenecks with NVIDIA Dynamo,https://developer.nvidia.com/blog/how-to-reduce-kv-cache-bottlenecks-with-nvidia-dynamo/,2025-09-18 16:30:00+0000,"As AI models grow larger and more sophisticated, inference, the process by which a model generates responses, is becoming a major challenge. Large language..."
NVIDIA Technical Blog,How to Reduce KV Cache Bottlenecks with NVIDIA Dynamo,https://developer.nvidia.com/blog/how-to-reduce-kv-cache-bottlenecks-with-nvidia-dynamo,2025-09-18 16:30:00+0000,"As AI models grow larger and more sophisticated, inference, the process by which a model generates responses, is becoming a major challenge. Large language..."
NVIDIA Technical Blog,An Introduction to Speculative Decoding for Reducing Latency in AI Inference,https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference/,2025-09-17 18:09:12+0000,"Generating text with large language models (LLMs) often involves running into a fundamental bottleneck. GPUs offer massive compute, yet much of that power sits..."
NVIDIA Technical Blog,An Introduction to Speculative Decoding for Reducing Latency in AI Inference,https://developer.nvidia.com/blog/an-introduction-to-speculative-decoding-for-reducing-latency-in-ai-inference,2025-09-17 18:09:12+0000,"Generating text with large language models (LLMs) often involves running into a fundamental bottleneck. GPUs offer massive compute, yet much of that power sits..."
NVIDIA Technical Blog,Reducing Cold Start Latency for LLM Inference with NVIDIA Run:ai Model Streamer,https://developer.nvidia.com/blog/reducing-cold-start-latency-for-llm-inference-with-nvidia-runai-model-streamer/,2025-09-16 17:35:13+0000,"Deploying large language models (LLMs) poses a challenge in optimizing inference efficiency. In particular, cold start delays—where models take significant..."
NVIDIA Technical Blog,Reducing Cold Start Latency for LLM Inference with NVIDIA Run:ai Model Streamer,https://developer.nvidia.com/blog/reducing-cold-start-latency-for-llm-inference-with-nvidia-runai-model-streamer,2025-09-16 17:35:13+0000,"Deploying large language models (LLMs) poses a challenge in optimizing inference efficiency. In particular, cold start delays—where models take significant..."
Anthropic News,"Societal Impacts Anthropic Economic Index: Tracking AI's role in the US and global economy Sep 15, 2025",https://www.anthropic.com/research/economic-index-geography,2025-09-15 22:38:16,
Anthropic News,"Societal Impacts Anthropic Economic Index report: Uneven geographic and enterprise AI adoption Sep 15, 2025",https://www.anthropic.com/research/anthropic-economic-index-september-2025-report,2025-09-15 22:38:16,
Anthropic News,"Product Claude is now generally available in Xcode Sep 15, 2025",https://www.anthropic.com/news/claude-in-xcode,2025-09-15 22:38:16,
NVIDIA Technical Blog,Build a Report Generator AI Agent with NVIDIA Nemotron on OpenRouter,https://developer.nvidia.com/blog/build-a-report-generator-ai-agent-with-nvidia-nemotron-on-openrouter/,2025-09-15 19:31:45+0000,"Unlike traditional systems that follow predefined paths, AI agents are autonomous systems that use large language models (LLMs) to make decisions, adapt to..."
NVIDIA Technical Blog,Build a Report Generator AI Agent with NVIDIA Nemotron on OpenRouter,https://developer.nvidia.com/blog/build-a-report-generator-ai-agent-with-nvidia-nemotron-on-openrouter,2025-09-15 19:31:45+0000,"Unlike traditional systems that follow predefined paths, AI agents are autonomous systems that use large language models (LLMs) to make decisions, adapt to..."
NVIDIA Technical Blog,New Open Source Qwen3-Next Models Preview Hybrid MoE Architecture Delivering Improved Accuracy and Accelerated Parallel Processing across NVIDIA Platform,https://developer.nvidia.com/blog/new-open-source-qwen3-next-models-preview-hybrid-moe-architecture-delivering-improved-accuracy-and-accelerated-parallel-processing-across-nvidia-platform/,2025-09-15 13:00:00+0000,"As AI models grow larger and process longer sequences of text, efficiency becomes just as important as scale.   To showcase what’s next, Alibaba released..."
NVIDIA Technical Blog,New Open Source Qwen3-Next Models Preview Hybrid MoE Architecture Delivering Improved Accuracy and Accelerated Parallel Processing across NVIDIA Platform,https://developer.nvidia.com/blog/new-open-source-qwen3-next-models-preview-hybrid-moe-architecture-delivering-improved-accuracy-and-accelerated-parallel-processing-across-nvidia-platform,2025-09-15 13:00:00+0000,"As AI models grow larger and process longer sequences of text, efficiency becomes just as important as scale.   To showcase what’s next, Alibaba..."
Anthropic News,"Announcements Strengthening our safeguards through collaboration with US CAISI and UK AISI Sep 12, 2025",https://www.anthropic.com/news/strengthening-our-safeguards-through-collaboration-with-us-caisi-and-uk-aisi,2025-09-12 22:36:32,
Anthropic News,"Product Bringing memory to teams at work Sep 11, 2025",https://www.anthropic.com/news/memory,2025-09-11 22:36:32,
NVIDIA Technical Blog,Modeling Attacks on AI-Powered Apps with the AI Kill Chain Framework,https://developer.nvidia.com/blog/modeling-attacks-on-ai-powered-apps-with-the-ai-kill-chain-framework/,2025-09-11 16:00:00+0000,"AI-powered applications are introducing new attack surfaces that traditional security models don’t fully capture, especially as these agentic systems gain..."
NVIDIA Technical Blog,Modeling Attacks on AI-Powered Apps with the AI Kill Chain Framework,https://developer.nvidia.com/blog/modeling-attacks-on-ai-powered-apps-with-the-ai-kill-chain-framework,2025-09-11 16:00:00+0000,"AI-powered applications are introducing new attack surfaces that traditional security models don’t fully capture, especially as these agentic systems gain..."
NVIDIA Technical Blog,Build High-Performance Vision AI Pipelines with NVIDIA CUDA-Accelerated VC-6,https://developer.nvidia.com/blog/build-high-performance-vision-ai-pipelines-with-nvidia-cuda-accelerated-vc-6/,2025-09-11 16:00:00+0000,The constantly increasing compute throughput of NVIDIA GPUs presents a new opportunity for optimizing vision AI workloads: keeping the hardware fed with data....
NVIDIA Technical Blog,Build High-Performance Vision AI Pipelines with NVIDIA CUDA-Accelerated VC-6,https://developer.nvidia.com/blog/build-high-performance-vision-ai-pipelines-with-nvidia-cuda-accelerated-vc-6,2025-09-11 16:00:00+0000,The constantly increasing compute throughput of NVIDIA GPUs presents a new opportunity for optimizing vision AI workloads: keeping the hardware fed with data....
NVIDIA Technical Blog,How Quantization Aware Training Enables Low-Precision Accuracy Recovery,https://developer.nvidia.com/blog/how-quantization-aware-training-enables-low-precision-accuracy-recovery/,2025-09-11 15:00:00+0000,"After training AI models, a variety of compression techniques can be used to optimize them for deployment. The most common is post-training quantization (PTQ),..."
NVIDIA Technical Blog,How Quantization Aware Training Enables Low-Precision Accuracy Recovery,https://developer.nvidia.com/blog/how-quantization-aware-training-enables-low-precision-accuracy-recovery,2025-09-11 15:00:00+0000,"After training AI models, a variety of compression techniques can be used to optimize them for deployment. The most common is post-training quantization (PTQ),..."
ミライト（Mirait One）ニュース,サイトマップから探す,sitemap/index.html,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,トップページから探す,index.html,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,グループ事業紹介スペシャルコンテンツ,https://www.mirait-one.com/special/group-business/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,ICTソリューション,https://www.mirait-one.com/solution/top-category/ict/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,エネルギーマネジメント,https://www.mirait-one.com/solution/top-category/energy-managiment/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,先端的取り組み,https://www.mirait-one.com/solution/top-category/cutting-edge/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,カテゴリーから探す,https://www.mirait-one.com/solution/top-category/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,Wi-Fi・無線エリア構築,https://www.mirait-one.com/solution/issue/wireless-communications/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,設備の信頼性確保,https://www.mirait-one.com/solution/issue/equipment-reliability/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,省エネ・脱炭素,https://www.mirait-one.com/solution/issue/decarbonation/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,クラウド活用,https://www.mirait-one.com/solution/issue/cloud-application/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,目的・課題から探す,https://www.mirait-one.com/solution/issue/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,建設・不動産,https://www.mirait-one.com/solution/industry/real-estate/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,ホテル・観光,https://www.mirait-one.com/solution/industry/hotel-tourism/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,医療・ヘルスケア,https://www.mirait-one.com/solution/industry/healthcare/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,官公庁・自治体,https://www.mirait-one.com/solution/industry/government/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,製造・エネルギー,https://www.mirait-one.com/solution/industry/energy/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,お客様の業種から探す,https://www.mirait-one.com/solution/industry/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,サービス・ソリューション,https://www.mirait-one.com/solution/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,SNS利用規約,https://www.mirait-one.com/sns-terms-of-use/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,サイトポリシー,https://www.mirait-one.com/sitepolicy/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,サイトマップ,https://www.mirait-one.com/sitemap/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,個人情報保護方針,https://www.mirait-one.com/privacypolicy/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,トップメッセージ,https://www.mirait-one.com/esg/message/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,健康経営の推進,https://www.mirait-one.com/esg/health-management/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,コーポレートガバナンス,https://www.mirait-one.com/esg/governance/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,ダイバーシティ&インクルージョンの推進,https://www.mirait-one.com/esg/diversity-inclusion/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,データ・報告書,https://www.mirait-one.com/esg/data/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,ESG経営推進の取り組み,https://www.mirait-one.com/esg/activities/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,english,https://www.mirait-one.com/english/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,パーパス・ミッション・ビジョン,https://www.mirait-one.com/corporate/philosophy/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,拠点・アクセス,https://www.mirait-one.com/corporate/offices/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,数字で見るミライト・ワン グループ,https://www.mirait-one.com/corporate/numbers/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,トップメッセージ,https://www.mirait-one.com/corporate/message/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,中期経営計画,https://www.mirait-one.com/corporate/management/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,統合マネジメントシステム,https://www.mirait-one.com/corporate/integrated-management-system/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,グループ情報,https://www.mirait-one.com/corporate/group-companies/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,広告ギャラリー,https://www.mirait-one.com/corporate/gallery/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,Cookieポリシー,https://www.mirait-one.com/cookiepolicy/,2025-09-11 12:46:32,
ミライト（Mirait One）ニュース,お問い合わせ,https://www.mirait-one.com/contact/,2025-09-11 12:46:32,
renue ニュース,03-4500-7154,tel:03-4500-7154,2025-09-11 12:46:31,
renue ニュース,PM・ITデューデリジェンス,https://renue.co.jp/services/pm-due-diligence,2025-09-11 12:46:31,
renue ニュース,情報セキュリティ基本方針,https://renue.co.jp/security,2025-09-11 12:46:31,
renue ニュース,採用情報を詳しく見る,https://renue.co.jp/recruit,2025-09-11 12:46:31,
renue ニュース,プライバシーポリシー,https://renue.co.jp/privacy,2025-09-11 12:46:31,
renue ニュース,2025.05.26 Forbes JAPAN様内に特設ページが公開されました。 |株式会社renue(リノイ) Forbes JAPAN様内に弊社特設ページが公開されております。ご興味がありましたら是非ご一読ください。,https://renue.co.jp/posts/ufELTRky,2025-09-11 12:46:31,
renue ニュース,2025.05.26 高卒お笑い芸人からITコンサルタントに?異色の経歴のrenueコンサルタントに聞く、renueジョインの決め手とは? 新しい記事がNoteに掲載されました。異色の経歴を持つ社員が、なぜITコンサルタントというキャリア、そしてなぜrenueを選んだのか語っています。,https://renue.co.jp/posts/recruit,2025-09-11 12:46:31,
renue ニュース,2025.04.25 ENILNO様にて「SubFi」をご紹介いただきました。 |株式会社renue 様々なオンラインサービスを紹介し、新しいライフスタイルを伝えるメディアであるENILNO様に弊社運営サービスであるSubFiをご紹介頂きました。,https://renue.co.jp/posts/elnino-subfi,2025-09-11 12:46:31,
renue ニュース,2025.05.27 ベンチャー通信様に取材頂きました。 |株式会社renue(リノイ) 弊社代表の山本より、renueの取り組みや今後のビジョンについてお話をさせて頂いております。ご興味がありましたら是非ご一読ください。,https://renue.co.jp/posts/Z1E2qbxz,2025-09-11 12:46:31,
renue ニュース,2025.05.26 Forbes JAPAN様に取材頂きました。 |株式会社renue(リノイ) 弊社代表の山本より、「レベニューシェアで成果にコミット──新鋭コンサルファームrenue CEOの覚悟」,https://renue.co.jp/posts/K7KHrohG,2025-09-11 12:46:31,
renue ニュース,2025.04.25 【ベルギー初】スタイリッシュなクラフトジン「The Drunken Horse GIN」を日本先行販売! |株式会社renue(リノイ) この記事はPRTimesにて配信されました,https://renue.co.jp/posts/4wuvksCd,2025-09-11 12:46:31,
renue ニュース,2025.06.17 Pythonで創る!!究極の3D航空機シミュレーター エンジニアのための情報共有コミュニティ「Zenn」にて配信されました。飛行をリアルにシミュレーションする3D航空機シミュレーターの構築について解説します。,https://renue.co.jp/posts/3D-simulator,2025-09-11 12:46:31,
renue ニュース,2025.05.26 ForbesJAPAN様に取材頂きました。 |株式会社renue(リノイ) 弊社代表の山本より、「廃棄端末に新たな価値を――住友商事×renue共創イノベーションへの挑戦」としてお話をさせて頂いております。,https://renue.co.jp/posts/-jFTbLG-,2025-09-11 12:46:31,
renue ニュース,CONTACT,https://renue.co.jp/contact,2025-09-11 12:46:31,
安藤ハザマ ニュース,By安藤ハザマ,https://www.ad-hzm.co.jp/works/projectstory/,2025-09-11 12:46:30,
安藤ハザマ ニュース,施工実績トップ,https://www.ad-hzm.co.jp/works/,2025-09-11 12:46:30,
安藤ハザマ ニュース,技術・工法の開発,https://www.ad-hzm.co.jp/sustainability/technology/,2025-09-11 12:46:30,
安藤ハザマ ニュース,社会貢献活動,https://www.ad-hzm.co.jp/sustainability/social/,2025-09-11 12:46:30,
安藤ハザマ ニュース,情報セキュリティ,https://www.ad-hzm.co.jp/sustainability/security/,2025-09-11 12:46:30,
安藤ハザマ ニュース,労働安全衛生,https://www.ad-hzm.co.jp/sustainability/safety/,2025-09-11 12:46:30,
安藤ハザマ ニュース,コーポレートレポート等,https://www.ad-hzm.co.jp/sustainability/report_2024/,2025-09-11 12:46:30,
安藤ハザマ ニュース,品質管理・向上,https://www.ad-hzm.co.jp/sustainability/quality/,2025-09-11 12:46:30,
安藤ハザマ ニュース,サプライチェーン,https://www.ad-hzm.co.jp/sustainability/procurement/,2025-09-11 12:46:30,
安藤ハザマ ニュース,トップメッセージ,https://www.ad-hzm.co.jp/sustainability/message/,2025-09-11 12:46:30,
安藤ハザマ ニュース,コーポレート・ガバナンス,https://www.ad-hzm.co.jp/sustainability/governance/,2025-09-11 12:46:30,
安藤ハザマ ニュース,環境への取り組み,https://www.ad-hzm.co.jp/sustainability/environment/,2025-09-11 12:46:30,
安藤ハザマ ニュース,ダイバーシティ,https://www.ad-hzm.co.jp/sustainability/diversity/,2025-09-11 12:46:30,
安藤ハザマ ニュース,脱炭素・循環型社会,https://www.ad-hzm.co.jp/sustainability/decarbonization/,2025-09-11 12:46:30,
安藤ハザマ ニュース,文化貢献活動,https://www.ad-hzm.co.jp/sustainability/culture/,2025-09-11 12:46:30,
安藤ハザマ ニュース,コンプライアンス,https://www.ad-hzm.co.jp/sustainability/compliance/,2025-09-11 12:46:30,
安藤ハザマ ニュース,サステナビリティトップ,https://www.ad-hzm.co.jp/sustainability/,2025-09-11 12:46:30,
安藤ハザマ ニュース,ZEB・ZEH 快適な省エネ建築物の設計・提案、技術開発に取り組んでいます。当社のZEB・ZEH取組方針や実績を紹介しています。,https://www.ad-hzm.co.jp/solution/zeb/,2025-09-11 12:46:30,
安藤ハザマ ニュース,海外進出サポート,https://www.ad-hzm.co.jp/solution/overseas/,2025-09-11 12:46:30,
安藤ハザマ ニュース,技術研究所 本館と幅広い分野の実験施設を備えた技術研究所では「人間と自然環境を結ぶ技術の創出」をコンセプトに掲げ、現在そして将来に向けた研究開発に取り組んでいます。,https://www.ad-hzm.co.jp/solution/laboratory/,2025-09-11 12:46:30,
安藤ハザマ ニュース,不動産事業 インフラ運営事業,https://www.ad-hzm.co.jp/solution/#real_estate,2025-09-11 12:46:30,
安藤ハザマ ニュース,技術・ ソリューション,https://www.ad-hzm.co.jp/solution/,2025-09-11 12:46:30,
安藤ハザマ ニュース,サイトマップ,https://www.ad-hzm.co.jp/sitemap/,2025-09-11 12:46:30,
安藤ハザマ ニュース,協力会社の皆様へ,https://www.ad-hzm.co.jp/purch/,2025-09-11 12:46:30,
安藤ハザマ ニュース,第44回明治神宮薪能へのご招待 今年で第44回を迎える明治神宮薪能開催のお知らせです。,https://www.ad-hzm.co.jp/lp/takiginou/2025/,2025-09-11 12:46:30,
安藤ハザマ ニュース,次世代エネルギープロジェクト 水素も利用可能なプラントを技術研究所に設置し、省CO2エネルギーを広域に届ける統合エネルギーマネジメントシステムを構築しています。本プロジェクトを通じて脱炭素・循環型社会の実現を目指します。,https://www.ad-hzm.co.jp/lp/new_energy/,2025-09-11 12:46:30,
安藤ハザマ ニュース,スポンサーシップ 安藤ハザマは若手アスリートの活動のサポートを通じて、次世代を担う若者の挑戦を支援していきます。,https://www.ad-hzm.co.jp/lp/library/,2025-09-11 12:46:30,
安藤ハザマ ニュース,CMギャラリー ケンチくん・ドボくん・ミライちゃん 安藤ハザマのTVCMをご紹介しています。,https://www.ad-hzm.co.jp/lp/cm/,2025-09-11 12:46:30,
安藤ハザマ ニュース,安藤ハザマ建築設計 安藤ハザマ建築設計のコンテンツです。設計施工実績集の他、特集記事や各部門の紹介を掲載しています。,https://www.ad-hzm.co.jp/lp/ahad/,2025-09-11 12:46:30,
安藤ハザマ ニュース,個人株主・投資家の皆様へ(よくあるご質問),https://www.ad-hzm.co.jp/ir/qa/,2025-09-11 12:46:30,
安藤ハザマ ニュース,有価証券報告書,https://www.ad-hzm.co.jp/ir/profitloss/,2025-09-11 12:46:30,
安藤ハザマ ニュース,長期ビジョン・中期経営計画,https://www.ad-hzm.co.jp/ir/plan/,2025-09-11 12:46:30,
安藤ハザマ ニュース,トップメッセージ,https://www.ad-hzm.co.jp/ir/message/,2025-09-11 12:46:30,
安藤ハザマ ニュース,IRニュース,https://www.ad-hzm.co.jp/ir/ir_news/,2025-09-11 12:46:30,
安藤ハザマ ニュース,業績ハイライト,https://www.ad-hzm.co.jp/ir/highlight/,2025-09-11 12:46:30,
安藤ハザマ ニュース,ファクトブック,https://www.ad-hzm.co.jp/ir/factbook/,2025-09-11 12:46:30,
安藤ハザマ ニュース,ディスクロージャーポリシー,https://www.ad-hzm.co.jp/ir/disclosure/,2025-09-11 12:46:30,
安藤ハザマ ニュース,IRカレンダー,https://www.ad-hzm.co.jp/ir/calendar/,2025-09-11 12:46:30,
安藤ハザマ ニュース,報告書(ビジネスレポート),https://www.ad-hzm.co.jp/ir/business/,2025-09-11 12:46:30,
安藤ハザマ ニュース,決算説明資料,https://www.ad-hzm.co.jp/ir/archives/,2025-09-11 12:46:30,
安藤ハザマ ニュース,株主・投資家情報トップ,https://www.ad-hzm.co.jp/ir/,2025-09-11 12:46:30,
安藤ハザマ ニュース,株主総会資料の書面交付をご希望の株主様へ,https://www.ad-hzm.co.jp/info/2025/20250214_01.php,2025-09-11 12:46:30,
安藤ハザマ ニュース,ニュース一覧,https://www.ad-hzm.co.jp/info/,2025-09-11 12:46:30,
安藤ハザマ ニュース,採用情報トップ,https://www.ad-hzm.co.jp/corporate/recruit/,2025-09-11 12:46:30,
安藤ハザマ ニュース,企業理念・行動規範,https://www.ad-hzm.co.jp/corporate/philosophy/,2025-09-11 12:46:30,
安藤ハザマ ニュース,海外ネットワーク,https://www.ad-hzm.co.jp/corporate/network_foreign/,2025-09-11 12:46:30,
安藤ハザマ ニュース,国内ネットワーク,https://www.ad-hzm.co.jp/corporate/network_domestic/,2025-09-11 12:46:30,
安藤ハザマ ニュース,グループ会社一覧,https://www.ad-hzm.co.jp/corporate/group/,2025-09-11 12:46:30,
安藤ハザマ ニュース,ライブラリー,https://www.ad-hzm.co.jp/corporate/#library,2025-09-11 12:46:30,
安藤ハザマ ニュース,会社情報トップ,https://www.ad-hzm.co.jp/corporate/,2025-09-11 12:46:30,
鹿島建設 プレス,鹿島グループ,https://www.kajima.co.jp/tech/kajima_group/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,ニーズから探す,https://www.kajima.co.jp/tech/index-j.html#tab02,2025-09-11 12:46:28,
鹿島建設 プレス,技術とサービス,https://www.kajima.co.jp/tech/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,エンジニアリング事業,https://www.kajima.co.jp/tech/engineering/index.html#anc_tech_menu_all,2025-09-11 12:46:28,
鹿島建設 プレス,サステナビリティ推進体制,https://www.kajima.co.jp/sustainability/system/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,サステナブルファイナンス,https://www.kajima.co.jp/sustainability/sustainable_finance/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,サステナビリティニュース,https://www.kajima.co.jp/sustainability/sustainability_topics/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,ステークホルダー (方針・エンゲージメント),https://www.kajima.co.jp/sustainability/stake_holder/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,社会貢献トピックス,https://www.kajima.co.jp/sustainability/social_topics/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,社会貢献活動,https://www.kajima.co.jp/sustainability/social_contribution/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,SDGsと鹿島の事業活動,https://www.kajima.co.jp/sustainability/sdgs/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,鹿島グループのマテリアリティ (重要課題),https://www.kajima.co.jp/sustainability/materiality/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,イニシアティブへの参画,https://www.kajima.co.jp/sustainability/initiative/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,サステナビリティ,https://www.kajima.co.jp/sustainability/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,鹿島グループの森林,https://www.kajima.co.jp/sustainability/forest/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,社外からの評価,https://www.kajima.co.jp/sustainability/evaluation/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,サステナビリティデータ・ GRI内容索引,https://www.kajima.co.jp/sustainability/data/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,現場ホームページリンク集,https://www.kajima.co.jp/site/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,採用・インターンシップ,https://www.kajima.co.jp/recruit/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,THE SITE:現場レポート,https://www.kajima.co.jp/project/site_repo/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,鹿島の実績集,https://www.kajima.co.jp/project/projects_portal/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,新卒採用・インターンシップ,https://www.kajima.co.jp/prof/recruit/new/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,国内グループ会社採用,https://www.kajima.co.jp/prof/recruit/group/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,留学生の皆様へ,https://www.kajima.co.jp/prof/recruit/global/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,基本方針と 安全衛生・環境・品質方針,https://www.kajima.co.jp/prof/policy/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,社長ごあいさつ,https://www.kajima.co.jp/prof/message/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,企業情報のトップページへ,https://www.kajima.co.jp/prof/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,コーポレート・ガバナンス,https://www.kajima.co.jp/prof/governance/corporate_governance/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,協力会社の皆様へ,https://www.kajima.co.jp/partner/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,プレスリリース,https://www.kajima.co.jp/news/press/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,学生向けイベント情報,https://www.kajima.co.jp/news/observe/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,国内グループ会社,https://www.kajima.co.jp/network/group/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,グローバルネットワーク,https://www.kajima.co.jp/network/global.html,2025-09-11 12:46:28,
鹿島建設 プレス,国内主要拠点,https://www.kajima.co.jp/network/base/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,サステナビリティ経営,https://www.kajima.co.jp/ir/sustainability/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,株主・株式情報,https://www.kajima.co.jp/ir/stockholder/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,IRニュース,https://www.kajima.co.jp/ir/news/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,中期経営計画,https://www.kajima.co.jp/ir/newplan/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,社長メッセージ: 株主・投資家の皆様へ,https://www.kajima.co.jp/ir/message/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,IRライブラリー,https://www.kajima.co.jp/ir/library/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,個人投資家の皆様へ,https://www.kajima.co.jp/ir/individual/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,株主・投資家情報,https://www.kajima.co.jp/ir/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,業績ハイライト,https://www.kajima.co.jp/ir/highlight/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,IRカレンダー,https://www.kajima.co.jp/ir/calendar/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,動画でみる鹿島の技術,https://www.kajima.co.jp/gallery/movie_archives/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,広告・CMライブラリ,https://www.kajima.co.jp/gallery/cm_library/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,知る・楽しむ,https://www.kajima.co.jp/enjoy/index-j.html,2025-09-11 12:46:28,
鹿島建設 プレス,English,https://www.kajima.co.jp/english/welcome.html,2025-09-11 12:46:28,
鹿島建設 プレス,KAJIMA彫刻コンクール,https://www.kajima.co.jp/csr/culture/sculpture/index.html,2025-09-11 12:46:28,
鹿島建設 プレス,お問い合わせ,https://www.kajima.co.jp/contact/index-j.html,2025-09-11 12:46:28,
Sakana AI News,corporate info,https://sakana.ai/company-info/,2025-09-11 12:46:25,
Sakana AI News,careers,https://sakana.ai/careers/,2025-09-11 12:46:25,
Sony AI News,Terms of Use,https://ai.sony/terms-of-use/,2025-09-11 12:46:25,
Sony AI News,Publications,https://ai.sony/publications/,2025-09-11 12:46:25,
Sony AI News,Projects,https://ai.sony/projects/,2025-09-11 12:46:25,
Sony AI News,Privacy Policy,https://ai.sony/privacy-policy/,2025-09-11 12:46:25,
Sony AI News,People,https://ai.sony/people/,2025-09-11 12:46:25,
Sony AI News,Join Us,https://ai.sony/joinus/,2025-09-11 12:46:25,
Sony AI News,Conferences,https://ai.sony/events/,2025-09-11 12:46:25,
Sony AI News,CONTACT US,https://ai.sony/contact/,2025-09-11 12:46:25,
Sony AI News,"August 26, 2025 | Game AI Gaming Life at Sony AI Robotics Sony AI Sony AI窶冱 Deep RL Team on Why the Hardest Problems Still Matter",https://ai.sony/blog/Sony-AI窶冱-Deep-RL-Team-on-Why-the-Hardest-Problems-Still-Matter/,2025-09-11 12:46:25,
Sony AI News,"September 9, 2025 | Sony AI Advancing Analog Design with AI: Sony AI窶冱 Contributions at MLCAD 2025",https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI窶冱-Contributions-at-MLCAD-2025/,2025-09-11 12:46:25,
Sony AI News,Learn More,https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI%e2%80%99s-Contributions-at-MLCAD-2025/,2025-09-11 12:46:25,
Sony AI News,Overview,https://ai.sony/about/#overview,2025-09-11 12:46:25,
Sony AI News,Management Team,https://ai.sony/about/#management_team,2025-09-11 12:46:25,
Sony AI News,View all,https://ai.sony/about/#labs_and_offices,2025-09-11 12:46:25,
Sony AI News,Labs & Offices,https://ai.sony/about/#lab_and_office,2025-09-11 12:46:25,
Sony AI News,Learn More,https://ai.sony/about/,2025-09-11 12:46:25,
Cohere Blog,Terms of Use,https://cohere.com/terms-of-use,2025-09-11 12:46:24,
Cohere Blog,Technology,https://cohere.com/solutions/technology,2025-09-11 12:46:24,
Cohere Blog,Public Sector,https://cohere.com/solutions/public-sector,2025-09-11 12:46:24,
Cohere Blog,Manufacturing,https://cohere.com/solutions/manufacturing,2025-09-11 12:46:24,
Cohere Blog,Healthcare and Life Sciences,https://cohere.com/solutions/healthcare-and-life-sciences,2025-09-11 12:46:24,
Cohere Blog,Financial Services,https://cohere.com/solutions/financial-services,2025-09-11 12:46:24,
Cohere Blog,Energy and Utilities,https://cohere.com/solutions/energy-and-utilities,2025-09-11 12:46:24,
Cohere Blog,Scholars Program,https://cohere.com/research/scholars-program,2025-09-11 12:46:24,
Cohere Blog,Papers,https://cohere.com/research/papers,2025-09-11 12:46:24,
Cohere Blog,Open Science Community,https://cohere.com/research/open-science,2025-09-11 12:46:24,
Cohere Blog,The Leaderboard Illusion,https://cohere.com/research/lmarena,2025-09-11 12:46:24,
Cohere Blog,Catalyst Grant Program,https://cohere.com/research/grants,2025-09-11 12:46:24,
Cohere Blog,Aya Expanse Leading multilingual models that excel across 23 different languages,https://cohere.com/research/aya,2025-09-11 12:46:24,
Cohere Blog,Cohere Labs Cohere's research lab that seeks to solve complex ML problems,https://cohere.com/research,2025-09-11 12:46:24,
Cohere Blog,Rerank A powerful model that provides a semantic boost to search quality,https://cohere.com/rerank,2025-09-11 12:46:24,
Cohere Blog,Products,https://cohere.com/products,2025-09-11 12:46:24,
Cohere Blog,Private Deployments,https://cohere.com/private-deployments,2025-09-11 12:46:24,
Cohere Blog,privacy policy,https://cohere.com/privacy,2025-09-11 12:46:24,
Cohere Blog,Pricing,https://cohere.com/pricing,2025-09-11 12:46:24,
Cohere Blog,Partners,https://cohere.com/partners,2025-09-11 12:46:24,
Cohere Blog,Newsroom,https://cohere.com/newsroom,2025-09-11 12:46:24,
Cohere Blog,Events,https://cohere.com/events?eventTypes=research,2025-09-11 12:46:24,
Cohere Blog,Events,https://cohere.com/events,2025-09-11 12:46:24,
Cohere Blog,Embed A leading multimodal search and retrieval tool,https://cohere.com/embed,2025-09-11 12:46:24,
Cohere Blog,Developers,https://cohere.com/developers,2025-09-11 12:46:24,
Cohere Blog,Deployment Options,https://cohere.com/deployment-options,2025-09-11 12:46:24,
Cohere Blog,Customization,https://cohere.com/customization,2025-09-11 12:46:24,
Cohere Blog,Oracle,https://cohere.com/customer-stories/oracle,2025-09-11 12:46:24,
Cohere Blog,Notion,https://cohere.com/customer-stories/notion,2025-09-11 12:46:24,
Cohere Blog,Johnson Lambert,https://cohere.com/customer-stories/johnson-lambert,2025-09-11 12:46:24,
Cohere Blog,Fujitsu,https://cohere.com/customer-stories/fujitsu,2025-09-11 12:46:24,
Cohere Blog,Draftwise,https://cohere.com/customer-stories/draftwise,2025-09-11 12:46:24,
Cohere Blog,BambooHR,https://cohere.com/customer-stories/bamboohr,2025-09-11 12:46:24,
Cohere Blog,Atomicwork,https://cohere.com/customer-stories/atomicwork,2025-09-11 12:46:24,
Cohere Blog,Request a demo,https://cohere.com/contact-sales,2025-09-11 12:46:24,
Cohere Blog,Compass An intelligent search and discovery system to surface business insights,https://cohere.com/compass,2025-09-11 12:46:24,
Cohere Blog,"Command A family of high-performance, scalable language models",https://cohere.com/command,2025-09-11 12:46:24,
Cohere Blog,Careers,https://cohere.com/careers,2025-09-11 12:46:24,
Cohere Blog,Learn more on the blog,https://cohere.com/blog/north-ga,2025-09-11 12:46:24,
Cohere Blog,Solutions,https://cohere.com/,2025-09-11 12:46:24,
Anthropic News,support@anthropic.com,mailto:support@anthropic.com,2025-09-11 12:46:23,
Anthropic News,press@anthropic.com,mailto:press@anthropic.com,2025-09-11 12:46:23,
Anthropic News,"Policy Usage policy update Aug 15, 2025",https://www.anthropic.com/news/usage-policy-update,2025-09-11 12:46:23,
Anthropic News,"Announcements Updating restrictions of sales to unsupported regions Sep 04, 2025",https://www.anthropic.com/news/updating-restrictions-of-sales-to-unsupported-regions,2025-09-11 12:46:23,
Anthropic News,"Product Updates to Consumer Terms and Privacy Policy Aug 28, 2025",https://www.anthropic.com/news/updates-to-our-consumer-terms,2025-09-11 12:46:23,
Anthropic News,"Announcements Reed Hastings appointed to Anthropic窶冱 board of directors May 28, 2025",https://www.anthropic.com/news/reed-hastings,2025-09-11 12:46:23,
Anthropic News,"Announcements Paul Smith to join Anthropic as Chief Commercial Officer Jul 15, 2025",https://www.anthropic.com/news/paul-smith-to-join-anthropic,2025-09-11 12:46:23,
Anthropic News,"Policy Our framework for developing safe and trustworthy agents Aug 04, 2025",https://www.anthropic.com/news/our-framework-for-developing-safe-and-trustworthy-agents,2025-09-11 12:46:23,
Anthropic News,"Announcements Introducing the Anthropic National Security and Public Sector Advisory Council Aug 27, 2025",https://www.anthropic.com/news/introducing-the-anthropic-national-security-and-public-sector-advisory-council,2025-09-11 12:46:23,
Anthropic News,"Announcements Introducing the Anthropic Economic Futures Program Jun 27, 2025",https://www.anthropic.com/news/introducing-the-anthropic-economic-futures-program,2025-09-11 12:46:23,
Anthropic News,"Announcements Anthropic appoints Hidetoshi Tojo as Head of Japan and announces hiring plans Aug 6, 2025",https://www.anthropic.com/news/head-of-japan-hiring-plans,2025-09-11 12:46:23,
Anthropic News,"Policy Anthropic to sign the EU Code of Practice Jul 21, 2025",https://www.anthropic.com/news/eu-code-practice,2025-09-11 12:46:23,
Anthropic News,"Policy Anthropic Signs CMS Health Tech Ecosystem Pledge to Advance Healthcare Interoperability Jul 30, 2025",https://www.anthropic.com/news/anthropic-signs-cms-health-tech-ecosystem-pledge-to-advance-healthcare-interoperability,2025-09-11 12:46:23,
Anthropic News,"Announcements Anthropic is endorsing SB 53 Sep 08, 2025",https://www.anthropic.com/news/anthropic-is-endorsing-sb-53,2025-09-11 12:46:23,
Anthropic News,"Product New capabilities for building agents on the Anthropic API May 22, 2025",https://www.anthropic.com/news/agent-capabilities-api,2025-09-11 12:46:23,
Mistral AI News,Privacy policy,https://mistral.ai/terms#privacy-policy,2025-09-11 12:46:23,
Mistral AI News,Data processing agreement,https://mistral.ai/terms#data-processing-agreement,2025-09-11 12:46:23,
Mistral AI News,Terms of service,https://mistral.ai/terms,2025-09-11 12:46:23,
Mistral AI News,Mistral Compute,https://mistral.ai/products/mistral-compute,2025-09-11 12:46:23,
Mistral AI News,Mistral Code,https://mistral.ai/products/mistral-code,2025-09-11 12:46:23,
Mistral AI News,Le Chat,https://mistral.ai/products/le-chat,2025-09-11 12:46:23,
Mistral AI News,La Plateforme,https://mistral.ai/products/la-plateforme,2025-09-11 12:46:23,
Mistral AI News,Pricing,https://mistral.ai/pricing,2025-09-11 12:46:23,
Mistral AI News,Partners,https://mistral.ai/partners,2025-09-11 12:46:23,
Mistral AI News,Research,https://mistral.ai/news?category=research,2025-09-11 12:46:23,
Mistral AI News,Legal notice,https://mistral.ai/legal,2025-09-11 12:46:23,
Mistral AI News,Our customers,https://mistral.ai/customers,2025-09-11 12:46:23,
Mistral AI News,Talk to sales,https://mistral.ai/contact,2025-09-11 12:46:23,
Mistral AI News,Careers,https://mistral.ai/careers,2025-09-11 12:46:23,
Mistral AI News,About us,https://mistral.ai/about,2025-09-11 12:46:23,
NVIDIA Technical Blog,Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0,https://developer.nvidia.com/blog/deploy-scalable-ai-inference-with-nvidia-nim-operator-3-0-0/,2025-09-10 16:30:00+0000,"AI models, inference engine backends, and distributed inference frameworks continue to evolve in architecture, complexity, and scale. With the rapid pace of..."
NVIDIA Technical Blog,Deploy Scalable AI Inference with NVIDIA NIM Operator 3.0.0,https://developer.nvidia.com/blog/deploy-scalable-ai-inference-with-nvidia-nim-operator-3-0-0,2025-09-10 16:30:00+0000,"AI models, inference engine backends, and distributed inference frameworks continue to evolve in architecture, complexity, and scale. With the rapid pace of..."
Anthropic News,"Announcements Claude and Alexa+ Feb 26, 2025",https://www.anthropic.com/news/claude-and-alexa-plus,2025-09-10 07:41:53,
Anthropic News,"Announcements Claude 3.7 Sonnet and Claude Code Feb 24, 2025",https://www.anthropic.com/news/claude-3-7-sonnet,2025-09-10 07:41:53,
Anthropic News,"Societal Impacts Anthropic窶冱 recommendations to OSTP for the U.S. AI action plan Mar 06, 2025",https://www.anthropic.com/news/anthropic-s-recommendations-ostp-u-s-ai-action-plan,2025-09-10 07:41:52,
Anthropic News,"Announcements Anthropic raises Series E at $61.5B post-money valuation Mar 03, 2025",https://www.anthropic.com/news/anthropic-raises-series-e-at-usd61-5b-post-money-valuation,2025-09-10 07:41:52,
Anthropic News,"Societal Impacts Anthropic窶冱 response to Governor Newsom窶冱 AI working group draft report Mar 19, 2025",https://www.anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report,2025-09-10 07:41:51,
Anthropic News,"Announcements Introducing computer use, a new Claude 3.5 Sonnet, and Claude 3.5 Haiku Oct 22, 2024",https://www.anthropic.com/news/3-5-models-and-computer-use,2025-09-10 06:49:42,
Anthropic News,"Announcements Claude 3.5 Sonnet on GitHub Copilot Oct 29, 2024",https://www.anthropic.com/news/github-copilot,2025-09-10 06:49:41,
Anthropic News,"Announcements Powering the next generation of AI development with AWS Nov 22, 2024",https://www.anthropic.com/news/anthropic-amazon-trainium,2025-09-10 06:49:41,
Anthropic News,"Product Claude 3.5 Haiku on AWS Trainium2 and model distillation in Amazon Bedrock Dec 3, 2024",https://www.anthropic.com/news/trainium2-and-distillation,2025-09-10 06:49:40,
Anthropic News,"Product Tailor Claude’s responses to your personal style Nov 26, 2024",https://www.anthropic.com/news/styles,2025-09-10 06:49:40,
Anthropic News,"Announcements Lyft to bring Claude to more than 40 million riders and over 1 million drivers Feb 6, 2025",https://www.anthropic.com/news/lyft-announcement,2025-09-10 06:49:40,
Anthropic News,"Announcements Anthropic achieves ISO 42001 certification for responsible AI Jan 13, 2025",https://www.anthropic.com/news/anthropic-achieves-iso-42001-certification-for-responsible-ai,2025-09-10 06:49:40,
Anthropic News,"Announcements Anthropic partners with U.S. National Labs for first 1,000 Scientist AI Jam Feb 28, 2025",https://www.anthropic.com/news/anthropic-partners-with-u-s-national-labs-for-first-1-000-scientist-ai-jam,2025-09-10 06:49:39,
Anthropic News,"Product Claude can now search the web Mar 20, 2025",https://www.anthropic.com/news/web-search,2025-09-10 06:49:38,
ミライト（Mirait One）ニュース,安心安全な社会インフラ,https://www.mirait-one.com/solution/top-category/infrastructure/,2025-09-10 06:14:29,
ミライト（Mirait One）ニュース,老朽インフラ・BCP・災害対策,https://www.mirait-one.com/solution/issue/disaster/,2025-09-10 06:14:18,
Sony AI News,"August 26, 2025 | Game AI Gaming Life at Sony AI Robotics Sony AI Sony AI’s Deep RL Team on Why the Hardest Problems Still Matter",https://ai.sony/blog/Sony-AI’s-Deep-RL-Team-on-Why-the-Hardest-Problems-Still-Matter/,2025-09-10 06:09:16,
Sony AI News,"September 9, 2025 | Sony AI Advancing Analog Design with AI: Sony AI’s Contributions at MLCAD 2025",https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AI’s-Contributions-at-MLCAD-2025/,2025-09-10 06:09:16,
Anthropic News,"Announcements Anthropic Economic Index: Insights from Claude 3.7 Sonnet Mar 27, 2025",https://www.anthropic.com/news/anthropic-economic-index-insights-from-claude-sonnet-3-7,2025-09-10 05:49:51,
Anthropic News,"Education Introducing Claude for Education Apr 02, 2025",https://www.anthropic.com/news/introducing-claude-for-education,2025-09-10 05:49:50,
ミライト（Mirait One）ニュース,ãã¸ã¿ã«ãã©ã³ã¹ ãã©ã¼ã¡ã¼ã·ã§ã³ï¼DXï¼,https://www.mirait-one.com/solution/top-category/dx/,2025-09-10 05:29:04,
ミライト（Mirait One）ニュース,æ°´éDX,https://www.mirait-one.com/solution/issue/water-dx/,2025-09-10 05:29:04,
ミライト（Mirait One）ニュース,èªæ²»ä½DXæ¨é²,https://www.mirait-one.com/solution/issue/government-dx/,2025-09-10 05:29:04,
ミライト（Mirait One）ニュース,DXæ¨é²,https://www.mirait-one.com/solution/issue/dx-implementation/,2025-09-10 05:29:04,
renue ニュース,新規事業・AI開発,https://renue.co.jp/services/new-business-ai,2025-09-10 05:29:02,
renue ニュース,図面AI/積算AI,https://renue.co.jp/services/drawing-ai,2025-09-10 05:29:02,
renue ニュース,AI人材育成・常駐派遣,https://renue.co.jp/services/ai-training,2025-09-10 05:29:02,
renue ニュース,2025.04.30 「Japan IT Week 春 2025」に図面AI・積算AIを出展いたしました 2025年4月に東京ビッグサイトで開催された「Japan IT Week 春 2025」に出展いたしました。,https://renue.co.jp/posts/japan-it-week,2025-09-10 05:29:02,
renue ニュース,2025.07.14 AIと一緒に作る！農薬散布ドローン自律航行システムの開発体験記 エンジニアのための情報共有コミュニティ「Zenn」にて配信されました。AIの力を借りた、農薬散布ドローンの自律航行システムの開発体験を紹介します。,https://renue.co.jp/posts/drone,2025-09-10 05:29:02,
renue ニュース,2025.05.27 【製造・建設業界向け】図面読み取り〜活用を一気通貫「renue 図面管理・活用AIソリューション」提供開始 ｜株式会社renue（リノイ） この記事はPRTimesにて配信されました,https://renue.co.jp/posts/cZCbiLbd,2025-09-10 05:29:02,
renue ニュース,2025.05.26 Forbes JAPAN様に取材頂きました。 ｜株式会社renue 弊社代表の山本より、「若き起業家が提供するCAD生成AIが日本のものづくりに風穴をあける」としてお話をさせて頂いております。,https://renue.co.jp/posts/Z_Kwijti,2025-09-10 05:29:02,
renue ニュース,2025.06.09 【第5回】デジタル化・DX推進展に図面AI・積算AI等を出展いたしました 2025年6月に東京ビッグサイトで開催された「【第5回】デジタル化・DX推進展」に出展いたしました。,https://renue.co.jp/posts/DX,2025-09-10 05:29:02,
renue ニュース,2025.06.17 AIと創る鉄道の未来：東海道新幹線運行シミュレーション開発の全貌とAIとのペアプログラミング道 エンジニアのための情報共有コミュニティ「Zenn」にて配信されました。AI搭載開発ツールCursorとペアプログラミングを行う上での対話術についてご紹介します。,https://renue.co.jp/posts/Cursor,2025-09-10 05:29:02,
renue ニュース,2025.06.20 Python×AI×交通ナビで社会貢献！SmoothNav開発ストーリー 〜未経験から始めるAIエンジニアへの道〜 エンジニアのための情報共有コミュニティ「Zenn」にて配信されました。社会に役立つ交通ナビの開発体験を、未経験からAIエンジニアを目指す方に向けてご紹介します。,https://renue.co.jp/posts/AI-engineer,2025-09-10 05:29:02,
鹿島建設 プレス,自動化施工システム「A 4 CSEL」　4機種連携により盛土の一連作業を自動化,202506/20c1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,自動化施工システム「A 4 CSEL ® 」の普及展開を見据え、建設会社との連携を試行,202502/6c1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,道路橋の床版更新における設計業務時間を10分の1に　3Dモデル自動生成システムを開発,202502/27c1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,羽田イノベーションシティにて到達範囲の広い電波規格「Wi-SUN FAN」によるロボット遠隔誘導の実証実験に成功,202501/22a1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,車や人との衝突を未然に防ぐ　道路横断におけるロボットの自動制御に成功,202501/10a1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,資機材自動搬送ロボットを開発,202412/pdf/17a1-j.pdf,2025-09-10 05:29:00,
鹿島建設 プレス,自動化施工システム「A 4 CSEL」　造成工事への本格適用を開始,202412/24c1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,CSGの締固め品質管理手法「Geo-DX Compaction TM 」を成瀬ダムに導入し、試験要員を7割削減,202412/19c1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,柱一本を全自動で溶接　新型のマニピュレータ型現場溶接ロボットを実導入,202411/11a1-j.htm,2025-09-10 05:29:00,
鹿島建設 プレス,大規模複合施設「HANEDA INNOVATION CITY ® 」グランドオープン1 周年記念イベント「あわい-awai 2024-」詳細決定,202410/pdf/18a1-j.pdf,2025-09-10 05:29:00,
鹿島建設 プレス,大規模複合施設「HANEDA INNOVATION CITY ® 」グランドオープン1 周年記念イベント「あわい-awai 2024-」開催決定,202409/pdf/27a1-j.pdf,2025-09-10 05:29:00,
Sony AI News,"The Team Behind GT Sophy - Part3 All of the training and preparation comes to a head in the third and final installment of Sony AIâs new video series,
                âThe Team Behind GT Sophy.â In this episode, the AI racing agent GT Sophy gets a rematch against the worldâs best
                esports champions in a rematch after falling short in its initial face off.",https://www.youtube.com/watch?v=zdMz-lDh-QE,2025-09-10 05:28:52,
Sony AI News,"The Team Behind GT Sophy - Part2 Sony AI is proud to share the second installment of our new video series, âThe Team Behind GT Sophy.â
                  In this episode
                  the team at Sony AI take the racing agent they have trained to play âGran Turismoâ and put it the
                  ultimate test. At the
                  April 2021 Race Together event, GT Sophy would face off against some of the finest human âGran
                  Turismoâ players in the
                  world. Had the team taught their AI racer to master the skills required to hold their own against the
                  champions of
                  esports?",https://www.youtube.com/watch?v=hsp7v5FC_6s,2025-09-10 05:28:52,
Sony AI News,People Learn more about Sony AI and the type of people we are looking for to join our team,https://www.youtube.com/watch?v=NhaDzRmyTHg,2025-09-10 05:28:52,
Cohere Blog,Security Best-in-class AI security and data protection,https://cohere.com/security,2025-09-10 05:28:52,
Cohere Blog,North NEW An enterprise-ready AI platform that powers modern workplace productivity,https://cohere.com/north,2025-09-10 05:28:52,
Cohere Blog,LLM University,https://cohere.com/llmu,2025-09-10 05:28:52,
Cohere Blog,Borderless AI,https://cohere.com/customer-stories/borderless-ai,2025-09-10 05:28:52,
Sony AI News,"August 26, 2025 | Game AI Gaming Life at Sony AI Robotics Sony AI Sony AIâs Deep RL Team on Why the Hardest Problems Still Matter",https://ai.sony/blog/Sony-AIâs-Deep-RL-Team-on-Why-the-Hardest-Problems-Still-Matter/,2025-09-10 05:28:52,
Sony AI News,"September  9, 2025 | Sony AI Advancing Analog Design with AI: Sony AIâs Contributions at MLCAD 2025",https://ai.sony/blog/Advancing-Analog-Design-with-AI-Sony-AIâs-Contributions-at-MLCAD-2025/,2025-09-10 05:28:52,
Sony AI News,"September  5, 2025 | Sony AI Advancing AI: Highlights from August",https://ai.sony/blog/Advancing-AI-Highlights-from-August/,2025-09-10 05:28:52,
Anthropic News,"Societal Impacts Anthropic Economic Index: AI’s impact on software development Apr 28, 2025",https://www.anthropic.com/research/impact-software-development,2025-09-10 05:28:51,
Anthropic News,"Policy Thoughts on America’s AI Action Plan Jul 23, 2025",https://www.anthropic.com/news/thoughts-on-america-s-ai-action-plan,2025-09-10 05:28:51,
Anthropic News,"Policy The need for transparency in Frontier AI Jul 07, 2025",https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai,2025-09-10 05:28:51,
Anthropic News,"Product Claude takes research to new places Apr 15, 2025",https://www.anthropic.com/news/research,2025-09-10 05:28:51,
Anthropic News,"Policy Our approach to understanding and addressing AI harms Apr 21, 2025",https://www.anthropic.com/news/our-approach-to-understanding-and-addressing-ai-harms,2025-09-10 05:28:51,
Anthropic News,"Announcements Offering expanded Claude access across all three branches of the U.S. government Aug 12, 2025",https://www.anthropic.com/news/offering-expanded-claude-access-across-all-three-branches-of-government,2025-09-10 05:28:51,
Anthropic News,"Announcements National security expert Richard Fontaine appointed to Anthropic’s long-term benefit trust Jun 7, 2025",https://www.anthropic.com/news/national-security-expert-richard-fontaine-appointed-to-anthropic-s-long-term-benefit-trust,2025-09-10 05:28:51,
Anthropic News,"Announcements Lawrence Livermore National Laboratory expands Claude for Enterprise use to empower scientists and researchers Jul 09, 2025",https://www.anthropic.com/news/lawrence-livermore-national-laboratory-expands-claude-for-enterprise-to-empower-scientists-and,2025-09-10 05:28:51,
Anthropic News,"Alignment Investing in energy to secure America's AI future Jul 15, 2025",https://www.anthropic.com/news/investing-in-energy-to-secure-america-s-ai-future,2025-09-10 05:28:51,
Anthropic News,"Product Claude can now connect to your world May 01, 2025",https://www.anthropic.com/news/integrations,2025-09-10 05:28:51,
Anthropic News,"How people use Claude for support, advice, and companionship Jun 27, 2025",https://www.anthropic.com/news/how-people-use-claude-for-support-advice-and-companionship,2025-09-10 05:28:51,
Anthropic News,"Case Study How Anthropic teams use Claude Code Jul 24, 2025",https://www.anthropic.com/news/how-anthropic-teams-use-claude-code,2025-09-10 05:28:51,
Anthropic News,"Announcements Federal government departments and agencies can now purchase Claude through the GSA schedule Aug 05, 2025",https://www.anthropic.com/news/federal-government-departments-and-agencies-can-now-purchase-claude-through-the-gsa-schedule,2025-09-10 05:28:51,
Anthropic News,"Announcements Developing nuclear safeguards for AI through public-private partnership Aug 21, 2025",https://www.anthropic.com/news/developing-nuclear-safeguards-for-ai-through-public-private-partnership,2025-09-10 05:28:51,
Anthropic News,"Announcements Detecting and countering misuse of AI: August 2025 Aug 27, 2025",https://www.anthropic.com/news/detecting-countering-misuse-aug-2025,2025-09-10 05:28:51,
Anthropic News,"Societal Impacts Detecting and countering malicious uses of Claude: March 2025 Apr 23, 2025",https://www.anthropic.com/news/detecting-and-countering-malicious-uses-of-claude-march-2025,2025-09-10 05:28:51,
Anthropic News,"Product Claude can now create and edit files Sep 09, 2025",https://www.anthropic.com/news/create-files,2025-09-10 05:28:51,
Anthropic News,"Product Discover tools that work with Claude Jul 14, 2025",https://www.anthropic.com/news/connectors-directory,2025-09-10 05:28:51,
Anthropic News,"Product Build and share AI-powered apps with Claude Jun 25, 2025",https://www.anthropic.com/news/claude-powered-artifacts,2025-09-10 05:28:51,
Anthropic News,"Announcements Claude Opus 4.1 Our most powerful model for handling complex agent and coding tasks Aug 05, 2025",https://www.anthropic.com/news/claude-opus-4-1,2025-09-10 05:28:51,
Anthropic News,"Product Claude on Google Cloud’s Vertex AI: FedRAMP High and IL2 Authorized Apr 02, 2025",https://www.anthropic.com/news/claude-on-google-cloud-fedramp-high,2025-09-10 05:28:51,
Anthropic News,"Announcements Claude in Amazon Bedrock: Approved for use in FedRAMP High and DoD IL4/5 workloads Jun 11, 2025",https://www.anthropic.com/news/claude-in-amazon-bedrock-fedramp-high,2025-09-10 05:28:51,
Anthropic News,"Announcements Claude Gov models for U.S. national security customers Jun 06, 2025",https://www.anthropic.com/news/claude-gov-models-for-u-s-national-security-customers,2025-09-10 05:28:51,
Anthropic News,"Product Claude for Financial Services Helping finance professionals analyze markets, conduct research, and make investment decisions. Jul 15, 2025",https://www.anthropic.com/news/claude-for-financial-services,2025-09-10 05:28:51,
Anthropic News,"Product Piloting Claude for Chrome Aug 26, 2025",https://www.anthropic.com/news/claude-for-chrome,2025-09-10 05:28:51,
Anthropic News,"Product Remote MCP support in Claude Code Jun 18, 2025",https://www.anthropic.com/news/claude-code-remote-mcp,2025-09-10 05:28:51,
Anthropic News,"Product Claude Code and new admin controls for business plans Aug 20, 2025",https://www.anthropic.com/news/claude-code-on-team-and-enterprise,2025-09-10 05:28:51,
Anthropic News,"Announcements Introducing Claude 4 May 22, 2025",https://www.anthropic.com/news/claude-4,2025-09-10 05:28:51,
Anthropic News,"Product Building safeguards for Claude Aug 12, 2025",https://www.anthropic.com/news/building-safeguards-for-claude,2025-09-10 05:28:51,
Anthropic News,"Product Turn ideas into interactive AI-powered apps Jun 25, 2025",https://www.anthropic.com/news/build-artifacts,2025-09-10 05:28:51,
Anthropic News,"Policy Build AI in America Jul 21, 2025",https://www.anthropic.com/news/build-ai-in-america,2025-09-10 05:28:51,
Anthropic News,"Announcements Automate security reviews with Claude Code Aug 6, 2025",https://www.anthropic.com/news/automate-security-reviews-with-claude-code,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic Signs White House Pledge to America's Youth: Investing in AI Education Sep 04, 2025",https://www.anthropic.com/news/anthropic-signs-pledge-to-americas-youth-investing-in-ai-education,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic raises $13B Series F at $183B post-money valuation Sep 02, 2025",https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic partners with the University of Chicago’s Becker Friedman Institute on AI economic research Jul 23, 2025",https://www.anthropic.com/news/anthropic-partners-with-the-university-of-chicago-s-becker-friedman-institute-on-ai-economic,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic launches higher education advisory board and AI Fluency courses Aug 21, 2025",https://www.anthropic.com/news/anthropic-higher-education-initiatives,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic Education Report: How university students use Claude Apr 08, 2025",https://www.anthropic.com/news/anthropic-education-report-how-university-students-use-claude,2025-09-10 05:28:51,
Anthropic News,"Societal Impacts Anthropic Education Report: How educators use Claude Aug 27, 2025",https://www.anthropic.com/news/anthropic-education-report-how-educators-use-claude,2025-09-10 05:28:51,
Anthropic News,"Announcements Anthropic and the Department of Defense to advance responsible AI in defense operations Jul 14, 2025",https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations,2025-09-10 05:28:51,
Anthropic News,"Announcements Introducing Anthropic's AI for Science Program May 05, 2025",https://www.anthropic.com/news/ai-for-science-program,2025-09-10 05:28:51,
Anthropic News,"Product Advancing Claude for Education Jul 09, 2025",https://www.anthropic.com/news/advancing-claude-for-education,2025-09-10 05:28:51,
Anthropic News,"Policy Activating AI Safety Level 3 protections May 22, 2025",https://www.anthropic.com/news/activating-asl3-protections,2025-09-10 05:28:51,
Anthropic News,"Event Introducing Anthropic's first developer conference: Code with Claude Apr 3, 2025",https://www.anthropic.com/news/Introducing-code-with-claude,2025-09-10 05:28:51,
Anthropic News,"Product Claude Sonnet 4 now supports 1M tokens of context Aug 12, 2025",https://www.anthropic.com/news/1m-context,2025-09-10 05:28:51,
Mistral AI News,AI solutions,https://mistral.ai/solutions,2025-09-10 05:28:51,
Mistral AI News,"Le Chat. Custom MCP connectors. Memories. Product September 2, 2025 Mistral AI Le Chat now integrates with 20+ enterprise platforms—powered by MCP—and remembers what matters with Memories.",https://mistral.ai/news/le-chat-mcp-connectors-memories,2025-09-10 05:28:51,
Anthropic News,Try Claude,https://claude.ai/,2025-09-10 05:28:51,
Anthropic News,Skip to main content,#main-content,2025-09-10 05:28:51,
NVIDIA Technical Blog,How to Connect Distributed Data Centers Into Large AI Factories with Scale-Across Networking,https://developer.nvidia.com/blog/how-to-connect-distributed-data-centers-into-large-ai-factories-with-scale-across-networking/,2025-09-09 17:00:00+0000,"AI scaling is incredibly complex, and new techniques in training and inference are continually demanding more out of the data center. While data center..."
NVIDIA Technical Blog,How to Connect Distributed Data Centers Into Large AI Factories with Scale-Across Networking,https://developer.nvidia.com/blog/how-to-connect-distributed-data-centers-into-large-ai-factories-with-scale-across-networking,2025-09-09 17:00:00+0000,"AI scaling is incredibly complex, and new techniques in training and inference are continually demanding more out of the data center. While data center..."
MIT Technology Review (All),Adapting to new threats with proactive risk management,https://www.technologyreview.com/2025/09/09/1123083/adapting-to-new-threats-with-proactive-risk-management/,2025-09-09 15:00:00+0000,"In July 2024, a botched update to the software defenses managed by cybersecurity firm CrowdStrike caused more than 8 million Windows systems to fail. From hospitals to manufacturers, stock markets to retail stores, the outage caused parts of the global economy to grind to a halt. Payment systems were disrupted, broadcasters went off the air,…"
NVIDIA Technical Blog,NVIDIA Rubin CPX Accelerates Inference Performance and Efficiency for 1M+ Token Context Workloads,https://developer.nvidia.com/blog/nvidia-rubin-cpx-accelerates-inference-performance-and-efficiency-for-1m-token-context-workloads/,2025-09-09 15:00:00+0000,"Inference has emerged as the new frontier of complexity in AI. Modern models are evolving into agentic systems capable of multi-step reasoning, persistent..."
NVIDIA Technical Blog,NVIDIA Rubin CPX Accelerates Inference Performance and Efficiency for 1M+ Token Context Workloads,https://developer.nvidia.com/blog/nvidia-rubin-cpx-accelerates-inference-performance-and-efficiency-for-1m-token-context-workloads,2025-09-09 15:00:00+0000,"Inference has emerged as the new frontier of complexity in AI. Modern models are evolving into agentic systems capable of multi-step reasoning, persistent..."
NVIDIA Technical Blog,NVIDIA Blackwell Ultra Sets New Inference Records in MLPerf Debut,https://developer.nvidia.com/blog/nvidia-blackwell-ultra-sets-new-inference-records-in-mlperf-debut/,2025-09-09 15:00:00+0000,"As large language models (LLMs) grow larger, they get smarter, with open models from leading developers now featuring hundreds of billions of parameters. At the..."
NVIDIA Technical Blog,NVIDIA Blackwell Ultra Sets New Inference Records in MLPerf Debut,https://developer.nvidia.com/blog/nvidia-blackwell-ultra-sets-new-inference-records-in-mlperf-debut,2025-09-09 15:00:00+0000,"As large language models (LLMs) grow larger, they get smarter, with open models from leading developers now featuring hundreds of billions of parameters. At the..."
MIT Technology Review (All),"The Download: meet our AI innovators, and what happens when therapists use AI covertly",https://www.technologyreview.com/2025/09/09/1123447/the-download-meet-our-ai-innovators-and-what-happens-when-therapists-use-ai-covertly/,2025-09-09 12:10:00+0000,"This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Meet the AI honorees on our 35 Innovators Under 35 list for 2025 Each year, we select 35 outstanding individuals under the age of 35 who are using technology to tackle tough problems…"
MIT Technology Review (All),Three big things we still don’t know about AI’s energy burden,https://www.technologyreview.com/2025/09/09/1123408/three-big-things-we-still-dont-know-about-ais-energy-burden/,2025-09-09 09:00:00+0000,"Earlier this year, when my colleague Casey Crownhart and I spent six months researching the climate and energy burden of AI, we came to see one number in particular as our white whale: how much energy the leading AI models, like ChatGPT or Gemini, use up when generating a single response.  This fundamental number remained…"
MIT Technology Review (All),AI is changing the grid. Could it help more than it harms?,https://www.technologyreview.com/2025/09/09/1123404/ai-grid-help/,2025-09-09 09:00:00+0000,"The rising popularity of AI is driving an increase in electricity demand so significant it has the potential to reshape our grid. Energy consumption by data centers has gone up by 80% from 2020 to 2025 and is likely to keep growing. Electricity prices are already rising, especially in places where data centers are most…"
MIT Technology Review (All),Help! My therapist is secretly using ChatGPT,https://www.technologyreview.com/2025/09/09/1123386/help-my-therapist-is-secretly-using-chatgpt/,2025-09-09 09:00:00+0000,"In Silicon Valley’s imagined future, AI models are so empathetic that we’ll use them as therapists. They’ll provide mental-health care for millions, unimpeded by the pesky requirements for human counselors, like the need for graduate degrees, malpractice insurance, and sleep. Down here on Earth, something very different has been happening.  Last week, we published a…"
arXiv cs.CL,On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts,https://arxiv.org/abs/2509.06952,2025-09-09 04:00:00+0000,"arXiv:2509.06952v1 Announce Type: new 
Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative goals and norms in context. As language models (LMs) are increasingly used as conversational agents, it becomes ever more important to understand their pragmatic reasoning abilities. We propose an evaluation framework derived from Wavelength, a popular communication game where a speaker and a listener communicate about a broad range of concepts in a granular manner. We study a range of LMs on both language comprehension and language production using direct and Chain-of-Thought (CoT) prompting, and further explore a Rational Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM inference. We find that state-of-the-art LMs, but not smaller ones, achieve strong performance on language comprehension, obtaining similar-to-human accuracy and exhibiting high correlations with human judgments even without CoT prompting or RSA. On language production, CoT can outperform direct prompting, and using RSA provides significant improvements over both approaches. Our study helps identify the strengths and limitations in LMs' pragmatic reasoning abilities and demonstrates the potential for improving them with RSA, opening up future avenues for understanding conceptual representation, language understanding, and social reasoning in LMs and humans."
arXiv cs.CL,Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models,https://arxiv.org/abs/2509.06949,2025-09-09 04:00:00+0000,"arXiv:2509.06949v1 Announce Type: new 
Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training, and is applicable across different architectures. Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks. Besides, it can also be applied to adapt block-specific models to larger blocks, which improves sampling flexibility. Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still consistently outperforms them across complex math reasoning tasks. TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical reasoning benchmarks. Through curriculum learning, we also derive the first long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1% relative accuracy gain. To facilitate reproducible research and practical applications, we release a comprehensive open-source framework for building, training, and deploying diffusion LLMs across diverse architectures. The framework integrates accelerated KV-cache techniques and inference engines for both inference and reinforcement learning, and includes implementations of various supervised fine-tuning and RL methods for mathematics, coding, and general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL"
arXiv cs.CL,Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning,https://arxiv.org/abs/2509.06948,2025-09-09 04:00:00+0000,"arXiv:2509.06948v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has proven effective in incentivizing the reasoning abilities of large language models (LLMs), but suffers from severe efficiency challenges due to its trial-and-error nature. While the common practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this decoupled two-stage approach limits interaction between SFT and RL, thereby constraining overall effectiveness. This study introduces a novel method for learning reasoning models that employs bilevel optimization to facilitate better cooperation between these training paradigms. By conditioning the SFT objective on the optimal RL policy, our approach enables SFT to meta-learn how to guide RL's optimization process. During training, the lower level performs RL updates while simultaneously receiving SFT supervision, and the upper level explicitly maximizes the cooperative gain-the performance advantage of joint SFT-RL training over RL alone. Empirical evaluations on five reasoning benchmarks demonstrate that our method consistently outperforms baselines and achieves a better balance between effectiveness and efficiency."
arXiv cs.CL,Interleaving Reasoning for Better Text-to-Image Generation,https://arxiv.org/abs/2509.06945,2025-09-09 04:00:00+0000,"arXiv:2509.06945v1 Announce Type: cross 
Abstract: Unified multimodal understanding and generation models recently have achieve significant improvement in image generation capability, yet a large gap remains in instruction following and detail preservation compared to systems that tightly couple comprehension with generation such as GPT-4o. Motivated by recent advances in interleaving reasoning, we explore whether such reasoning can further improve Text-to-Image (T2I) generation. We introduce Interleaving Reasoning Generation (IRG), a framework that alternates between text-based thinking and image synthesis: the model first produces a text-based thinking to guide an initial image, then reflects on the result to refine fine-grained details, visual quality, and aesthetics while preserving semantics. To train IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL), which targets two sub-goals: (1) strengthening the initial think-and-generate stage to establish core content and base quality, and (2) enabling high-quality textual reflection and faithful implementation of those refinements in a subsequent image. We curate IRGL-300K, a dataset organized into six decomposed learning modes that jointly cover learning text-based thinking, and full thinking-image trajectories. Starting from a unified foundation model that natively emits interleaved text-image outputs, our two-stage training first builds robust thinking and reflection, then efficiently tunes the IRG pipeline in the full thinking-image trajectory data. Extensive experiments show SoTA performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF, GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality and fine-grained fidelity. The code, model weights and datasets will be released in: https://github.com/Osilly/Interleaving-Reasoning-Generation ."
arXiv cs.CL,Outcome-based Exploration for LLM Reasoning,https://arxiv.org/abs/2509.06941,2025-09-09 04:00:00+0000,"arXiv:2509.06941v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has emerged as a powerful method for improving the reasoning abilities of large language models (LLMs). Outcome-based RL, which rewards policies solely for the correctness of the final answer, yields substantial accuracy gains but also induces a systematic loss in generation diversity. This collapse undermines real-world performance, where diversity is critical for test-time scaling. We analyze this phenomenon by viewing RL post-training as a sampling process and show that, strikingly, RL can reduce effective diversity even on the training set relative to the base model. Our study highlights two central findings: (i) a transfer of diversity degradation, where reduced diversity on solved problems propagates to unsolved ones, and (ii) the tractability of the outcome space, since reasoning tasks admit only a limited set of distinct answers. Motivated by these insights, we propose outcome-based exploration, which assigns exploration bonuses according to final outcomes. We introduce two complementary algorithms: historical exploration, which encourages rarely observed answers via UCB-style bonuses, and batch exploration, which penalizes within-batch repetition to promote test-time diversity. Experiments on standard competition math with Llama and Qwen models demonstrate that both methods improve accuracy while mitigating diversity collapse. On the theoretical side, we formalize the benefit of outcome-based exploration through a new model of outcome-based bandits. Together, these contributions chart a practical path toward RL methods that enhance reasoning without sacrificing the diversity essential for scalable deployment."
arXiv cs.CL,An Ethically Grounded LLM-Based Approach to Insider Threat Synthesis and Detection,https://arxiv.org/abs/2509.06920,2025-09-09 04:00:00+0000,"arXiv:2509.06920v1 Announce Type: cross 
Abstract: Insider threats are a growing organizational problem due to the complexity of identifying their technical and behavioral elements. A large research body is dedicated to the study of insider threats from technological, psychological, and educational perspectives. However, research in this domain has been generally dependent on datasets that are static and limited access which restricts the development of adaptive detection models. This study introduces a novel, ethically grounded approach that uses the large language model (LLM) Claude Sonnet 3.7 to dynamically synthesize syslog messages, some of which contain indicators of insider threat scenarios. The messages reflect real-world data distributions by being highly imbalanced (1% insider threats). The syslogs were analyzed for insider threats by both Claude Sonnet 3.7 and GPT-4o, with their performance evaluated through statistical metrics including precision, recall, MCC, and ROC AUC. Sonnet 3.7 consistently outperformed GPT-4o across nearly all metrics, particularly in reducing false alarms and improving detection accuracy. The results show strong promise for the use of LLMs in synthetic dataset generation and insider threat detection."
arXiv cs.CL,Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents,https://arxiv.org/abs/2509.06917,2025-09-09 04:00:00+0000,"arXiv:2509.06917v1 Announce Type: cross 
Abstract: We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a paper's code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agent's effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original paper's results and can correctly carry out novel user queries. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists."
arXiv cs.CL,Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification,https://arxiv.org/abs/2509.06902,2025-09-09 04:00:00+0000,"arXiv:2509.06902v1 Announce Type: new 
Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that deviate from available data, a failure known as \emph{numeric hallucination}. Existing safeguards -- retrieval-augmented generation, citations, and uncertainty estimation -- improve transparency but cannot guarantee fidelity: fabricated or misquoted values may still be displayed as if correct. We propose \textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that enforces numeric fidelity through mechanical verification. Under PCN, numeric spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a verifier checks each token under a declared policy (e.g., exact equality, rounding, aliases, or tolerance with qualifiers). Crucially, PCN places verification in the \emph{renderer}, not the model: only claim-checked numbers are marked as verified, and all others default to unverified. This separation prevents spoofing and guarantees fail-closed behavior. We formalize PCN and prove soundness, completeness under honest tokens, fail-closed behavior, and monotonicity under policy refinement. PCN is lightweight and model-agnostic, integrates seamlessly into existing applications, and can be extended with cryptographic commitments. By enforcing verification as a mandatory step before display, PCN establishes a simple contract for numerically sensitive settings: \emph{trust is earned only by proof}, while the absence of a mark communicates uncertainty."
arXiv cs.CL,mmBERT: A Modern Multilingual Encoder with Annealed Language Learning,https://arxiv.org/abs/2509.06888,2025-09-09 04:00:00+0000,"arXiv:2509.06888v1 Announce Type: new 
Abstract: Encoder-only languages models are frequently used for a variety of standard machine learning tasks, including classification and retrieval. However, there has been a lack of recent research for encoder models, especially with respect to multilingual models. We introduce mmBERT, an encoder-only language model pretrained on 3T tokens of multilingual text in over 1800 languages. To build mmBERT we introduce several novel elements, including an inverse mask ratio schedule and an inverse temperature sampling ratio. We add over 1700 low-resource languages to the data mix only during the decay phase, showing that it boosts performance dramatically and maximizes the gains from the relatively small amount of training data. Despite only including these low-resource languages in the short decay phase we achieve similar classification performance to models like OpenAI's o3 and Google's Gemini 2.5 Pro. Overall, we show that mmBERT significantly outperforms the previous generation of models on classification and retrieval tasks -- on both high and low-resource languages."
arXiv cs.CL,UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction,https://arxiv.org/abs/2509.06883,2025-09-09 04:00:00+0000,"arXiv:2509.06883v1 Announce Type: new 
Abstract: We participate in CheckThat! Task 2 English and explore various methods of prompting and in-context learning, including few-shot prompting and fine-tuning with different LLM families, with the goal of extracting check-worthy claims from social media passages. Our best METEOR score is achieved by fine-tuning a FLAN-T5 model. However, we observe that higher-quality claims can sometimes be extracted using other methods, even when their METEOR scores are lower."
arXiv cs.CL,The Majority is not always right: RL training for solution aggregation,https://arxiv.org/abs/2509.06870,2025-09-09 04:00:00+0000,"arXiv:2509.06870v1 Announce Type: new 
Abstract: Scaling up test-time compute, by generating multiple independent solutions and selecting or aggregating among them, has become a central paradigm for improving large language models (LLMs) on challenging reasoning tasks. While most prior work relies on simple majority voting or reward model ranking to aggregate solutions, these approaches may only yield limited benefits. In this work, we propose to learn aggregation as an explicit reasoning skill: given a set of candidate solutions, we train an aggregator model to review, reconcile, and synthesize a final, correct answer using reinforcement learning from verifiable rewards. A key ingredient is careful balancing of easy and hard training examples, allowing the model to learn both to recover minority-but-correct answers as well as easy majority-correct answers. Empirically, we find our method, AggLM, outperforms both strong rule-based and reward-model baselines, across multiple benchmarks. Furthermore, it generalizes effectively to solutions from differing models, including stronger ones than contained in the training data, all while requiring substantially fewer tokens than majority voting with larger numbers of solutions."
arXiv cs.CL,Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet,https://arxiv.org/abs/2509.06861,2025-09-09 04:00:00+0000,"arXiv:2509.06861v1 Announce Type: cross 
Abstract: Test-time scaling increases inference-time computation by allowing models to generate long reasoning chains, and has shown strong performance across many domains. However, in this work, we show that this approach is not yet effective for knowledge-intensive tasks, where high factual accuracy and low hallucination rates are essential. We conduct a comprehensive evaluation of test-time scaling using 12 reasoning models on two knowledge-intensive benchmarks. Our results reveal that increasing test-time computation does not consistently improve accuracy and, in many cases, it even leads to more hallucinations. We then analyze how extended reasoning affects hallucination behavior. We find that reduced hallucinations often result from the model choosing to abstain after thinking more, rather than from improved factual recall. Conversely, for some models, longer reasoning encourages attempts on previously unanswered questions, many of which result in hallucinations. Case studies show that extended reasoning can induce confirmation bias, leading to overconfident hallucinations. Despite these limitations, we observe that compared to non-thinking, enabling thinking remains beneficial. Code and data are available at https://github.com/XuZhao0/tts-knowledge"
arXiv cs.CL,EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models,https://arxiv.org/abs/2509.06838,2025-09-09 04:00:00+0000,"arXiv:2509.06838v1 Announce Type: new 
Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark."
arXiv cs.CL,COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens,https://arxiv.org/abs/2509.06836,2025-09-09 04:00:00+0000,"arXiv:2509.06836v1 Announce Type: new 
Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial for edge deployment, interactive applications, and sustainable inference at scale. Pruning is a key technique toward this goal. However, prior pruning methods are limited: width pruning often breaks the standard transformer layout or requires custom inference code, while depth pruning removes entire layers and can cause abrupt accuracy drops. In this work, we propose COMPACT, which jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii) prunes FFN intermediate channels using common-token-weighted activations, aligning importance with the post-pruning token distribution. COMPACT enjoys merits of both depth and width pruning, such as: deployment-friendliness (keeps a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN pruning), training-free operation with competitive pruning time, and strong memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and Gemma families (0.5B-70B) show state-of-the-art downstream task performance at similar or higher pruning ratios, with substantial reductions in parameters, GPU memory, and end-to-end latency."
arXiv cs.CL,RAFFLES: Reasoning-based Attribution of Faults for LLM Systems,https://arxiv.org/abs/2509.06822,2025-09-09 04:00:00+0000,"arXiv:2509.06822v1 Announce Type: cross 
Abstract: We have reached a critical roadblock in the development and enhancement of long-horizon, multi-component LLM agentic systems: it is incredibly tricky to identify where these systems break down and why. Evaluation capabilities that currently exist today (e.g., single pass LLM-as-a-judge) are limited in that they often focus on individual metrics or capabilities, end-to-end outcomes, and are narrowly grounded on the preferences of humans. We argue that to match the agentic capabilities, evaluation frameworks must also be able to reason, probe, iterate, and understand the complex logic passing through these systems over long horizons. In this paper, we present RAFFLES - an evaluation architecture that incorporates reasoning and iterative refinement. Specifically, RAFFLES operates as an iterative, multi-component pipeline, using a central Judge to systematically investigate faults and a set of specialized Evaluators to assess not only the system's components but also the quality of the reasoning by the Judge itself, thereby building a history of hypotheses. We tested RAFFLES against several baselines on the Who&When dataset, a benchmark designed to diagnose the ""who"" (agent) and ""when"" (step) of a system's failure. RAFFLES outperforms these baselines, achieving an agent-step fault pair accuracy of over 43% on the Algorithmically-Generated dataset (a substantial increase from the previously published best of 16.6%) and over 20% on the Hand-Crafted dataset (surpassing the previously published best of 8.8%). These results demonstrate a key step towards introducing automated fault detection for autonomous systems over labor-intensive manual human review."
arXiv cs.CL,A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs,https://arxiv.org/abs/2509.06813,2025-09-09 04:00:00+0000,"arXiv:2509.06813v1 Announce Type: new 
Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the Levelised Cost of Energy (LCOE) from wind power, yet the unstructured, free-text nature of turbine maintenance logs presents a significant barrier to automated analysis. Our paper addresses this by presenting a novel and reproducible framework for benchmarking Large Language Models (LLMs) on the task of classifying these complex industrial records. To promote transparency and encourage further research, this framework has been made publicly available as an open-source tool. We systematically evaluate a diverse suite of state-of-the-art proprietary and open-source LLMs, providing a foundational assessment of their trade-offs in reliability, operational efficiency, and model calibration. Our results quantify a clear performance hierarchy, identifying top models that exhibit high alignment with a benchmark standard and trustworthy, well-calibrated confidence scores. We also demonstrate that classification performance is highly dependent on the task's semantic ambiguity, with all models showing higher consensus on objective component identification than on interpretive maintenance actions. Given that no model achieves perfect accuracy and that calibration varies dramatically, we conclude that the most effective and responsible near-term application is a Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate and standardise data labelling for human experts, thereby enhancing O&M data quality and downstream reliability analysis."
arXiv cs.CL,Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem,https://arxiv.org/abs/2509.06809,2025-09-09 04:00:00+0000,"arXiv:2509.06809v1 Announce Type: new 
Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck for advancing the mathematical reasoning of Large Language Models (LLMs). Our work confronts this challenge by turning decades of automated theorem proving research into a scalable data engine. Rather than relying on error-prone LLMs or complex proof-assistant syntax like Lean and Isabelle, our framework leverages E-prover's saturation capabilities on the vast TPTP axiom library to derive a massive, guaranteed-valid corpus of theorems. Our pipeline is principled and simple: saturate axioms, filter for ""interesting"" theorems, and generate tasks. With no LLMs in the loop, we eliminate factual errors by construction. This purely symbolic data is then transformed into three difficulty-controlled challenges: entailment verification, premise selection, and proof reconstruction. Our zero-shot experiments on frontier models reveal a clear weakness: performance collapses on tasks requiring deep, structural reasoning. Our framework provides both the diagnostic tool to measure this gap and a scalable source of symbolic training data to address it. We make the code and data publicly available.
  https://github.com/sileod/reasoning_core https://hf.co/datasets/reasoning-core/rc1"
arXiv cs.CL,MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security,https://arxiv.org/abs/2509.06807,2025-09-09 04:00:00+0000,"arXiv:2509.06807v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) increasingly permeate human life, their security has emerged as a critical concern, particularly their ability to maintain harmless responses to malicious instructions. Although extensive methods have improved LLMs' security, they often lead to conservative, rejection-oriented responses that compromise practical usability. This presents a key challenge: how to advance the Pareto frontier between LLMs' usability and security, rather than necessitate a trade-off between them. To address this, we propose the MoGU framework, in which the intra-layer router dynamically allocates weights by sensing hidden states, thereby balancing the contributions of security-optimized and usability-optimized variants. Despite its initial potential, the MoGU framework faces limitations such as parameter redundancy and performance bottlenecks. To overcome these, we further propose an improved MoGU_v2 framework that establishes a tighter coupling between the routers and hidden states. In MoGU_v2, routers are embedded only in layers encoding highly classifiable security features, and backbone modules are activated during router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong adaptability and stable improvements across various series of LLMs, including mainstream LLMs serving as brains in various applications, on-device LLMs optimized for resource-constrained scenarios, and reasoning LLMs tailored for user interpretability. Meanwhile, even facing risks introduced by Instruction Fine-tuning, MoGU_v2 can easily restore security without compromising the task performance gains via a simple data-mix strategy. These comprehensive improvements highlight MoGU_V2 as a robust and versatile solution for mitigating security risks in real-world applications."
arXiv cs.CL,MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML,https://arxiv.org/abs/2509.06806,2025-09-09 04:00:00+0000,"arXiv:2509.06806v1 Announce Type: new 
Abstract: Large language models (LLMs) possess broad world knowledge and strong general-purpose reasoning ability, yet they struggle to learn from many in-context examples on standard machine learning (ML) tasks, that is, to leverage many-shot demonstrations purely via in-context learning (ICL) without gradient descent. We introduce MachineLearningLM, a portable continued-pretraining framework that equips a general-purpose LLM with robust in-context ML capability while preserving its general knowledge and reasoning for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural causal models (SCMs), spanning shot counts up to 1,024. We begin with a random-forest teacher, distilling tree-based decision strategies into the LLM to strengthen robustness in numerical modeling. All tasks are serialized with a token-efficient prompt, enabling 3x to 6x more examples per context window and delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8), MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an average of about 15% on out-of-distribution tabular classification across finance, physics, biology, and healthcare domains. It exhibits a striking many-shot scaling law: accuracy increases monotonically as in-context demonstrations grow from 8 to 1,024. Without any task-specific training, it attains random-forest-level accuracy across hundreds of shots. General chat capabilities, including knowledge and reasoning, are preserved: it achieves 75.4% on MMLU."
arXiv cs.CL,Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint,https://arxiv.org/abs/2509.06795,2025-09-09 04:00:00+0000,"arXiv:2509.06795v1 Announce Type: new 
Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective post-training strategy to enhance various abilities of Large Language Models (LLMs). However, prior studies have shown that IFT can significantly compromise LLMs' safety, particularly their ability to refuse malicious instructions, raising significant concerns. Recent research into the internal mechanisms of LLMs has identified the refusal direction (r-direction) in the hidden states, which plays a pivotal role in governing refusal behavior. Building on this insight, our study reveals that the r-direction tends to drift during training, which we identify as one of the causes of the associated safety risks. To mitigate such drift, our proposed ProCon method introduces a projection-constrained loss term that regularizes the projection magnitude of each training sample's hidden state onto the r-direction. Our initial analysis shows that applying an appropriate constraint can effectively mitigate the refusal direction drift and associated safety risks, but remains limited by overall performance barriers. To overcome this barrier, informed by our observation of early-stage sharp drift and a data-driven perspective, we introduce a warm-up strategy that emphasizes early-stage strong constraints and broaden the data distribution to strengthen constraint signals, leading to an enhanced ProCon method. Experimental results under various datasets, scenarios, and LLMs demonstrate that our method can significantly mitigate safety risks posed by IFT while preserving task performance gains. Even compared with strong baselines, our method consistently delivers superior overall performance. Crucially, our analysis indicates that ProCon can contribute to stabilizing the r-direction during training, while such an interpretability-driven exploration of LLMs' internal mechanisms lays a solid foundation for future safety research."
arXiv cs.CL,VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction,https://arxiv.org/abs/2509.06736,2025-09-09 04:00:00+0000,"arXiv:2509.06736v1 Announce Type: cross 
Abstract: Intelligent vehicle cockpits present unique challenges for API Agents, requiring coordination across tightly-coupled subsystems that exceed typical task environments' complexity. Traditional Function Calling (FC) approaches operate statelessly, requiring multiple exploratory calls to build environmental awareness before execution, leading to inefficiency and limited error recovery. We introduce VehicleWorld, the first comprehensive environment for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties with fully executable implementations that provide real-time state information during agent execution. This environment enables precise evaluation of vehicle agent behaviors across diverse, challenging scenarios. Through systematic analysis, we discovered that direct state prediction outperforms function calling for environmental control. Building on this insight, we propose State-based Function Call (SFC), a novel approach that maintains explicit system state awareness and implements direct state transitions to achieve target conditions. Experimental results demonstrate that SFC significantly outperforms traditional FC approaches, achieving superior execution accuracy and reduced latency. We have made all implementation code publicly available on Github https://github.com/OpenMOSS/VehicleWorld."
arXiv cs.CL,Reinforcement Learning Foundations for Deep Research Systems: A Survey,https://arxiv.org/abs/2509.06733,2025-09-09 04:00:00+0000,"arXiv:2509.06733v1 Announce Type: cross 
Abstract: Deep research systems, agentic AI that solve complex, multi-step tasks by coordinating reasoning, search across the open web and user files, and tool use, are moving toward hierarchical deployments with a Planner, Coordinator, and Executors. In practice, training entire stacks end-to-end remains impractical, so most work trains a single planner connected to core tools such as search, browsing, and code. While SFT imparts protocol fidelity, it suffers from imitation and exposure biases and underuses environment feedback. Preference alignment methods such as DPO are schema and proxy-dependent, off-policy, and weak for long-horizon credit assignment and multi-objective trade-offs. A further limitation of SFT and DPO is their reliance on human defined decision points and subskills through schema design and labeled comparisons. Reinforcement learning aligns with closed-loop, tool-interaction research by optimizing trajectory-level policies, enabling exploration, recovery behaviors, and principled credit assignment, and it reduces dependence on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations of deep research systems. It systematizes work after DeepSeek-R1 along three axes: (i) data synthesis and curation; (ii) RL methods for agentic research covering stability, sample efficiency, long context handling, reward and credit design, multi-objective optimization, and multimodal integration; and (iii) agentic RL training systems and frameworks. We also cover agent architecture and coordination, as well as evaluation and benchmarks, including recent QA, VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We distill recurring patterns, surface infrastructure bottlenecks, and offer practical guidance for training robust, transparent deep research agents with RL."
arXiv cs.CL,Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments,https://arxiv.org/abs/2509.06704,2025-09-09 04:00:00+0000,"arXiv:2509.06704v1 Announce Type: new 
Abstract: Aggregating multiple annotations into a single ground truth label may hide valuable insights into annotator disagreement, particularly in tasks where subjectivity plays a crucial role. In this work, we explore methods for identifying subjectivity in recognizing the human values that motivate arguments. We evaluate two main approaches: inferring subjectivity through value prediction vs. directly identifying subjectivity. Our experiments show that direct subjectivity identification significantly improves the model performance of flagging subjective arguments. Furthermore, combining contrastive loss with binary cross-entropy loss does not improve performance but reduces the dependency on per-label subjectivity. Our proposed methods can help identify arguments that individuals may interpret differently, fostering a more nuanced annotation process."
arXiv cs.CL,ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data,https://arxiv.org/abs/2509.06675,2025-09-09 04:00:00+0000,"arXiv:2509.06675v1 Announce Type: new 
Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0 corpus, targeted at speech modeling tasks with the largest variant containing 2,695 hours. We combined the sound recordings of the Czech parliamentary speeches with the official transcripts. The recordings were processed with WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our processing pipeline improves upon the ParCzech 3.0 speech recognition version by extracting more data with higher alignment reliability. The dataset is offered in three flexible variants: (1) sentence-segmented for automatic speech recognition and speech synthesis tasks with clean boundaries, (2) unsegmented preserving original utterance flow across sentences, and (3) a raw-alignment for further custom refinement for other possible tasks. All variants maintain the original metadata and are released under a permissive CC-BY license. The dataset is available in the LINDAT repository, with the sentence-segmented and unsegmented variants additionally available on Hugging Face."
arXiv cs.CL,IntrEx: A Dataset for Modeling Engagement in Educational Conversations,https://arxiv.org/abs/2509.06652,2025-09-09 04:00:00+0000,"arXiv:2509.06652v1 Announce Type: new 
Abstract: Engagement and motivation are crucial for second-language acquisition, yet maintaining learner interest in educational conversations remains a challenge. While prior research has explored what makes educational texts interesting, still little is known about the linguistic features that drive engagement in conversations. To address this gap, we introduce IntrEx, the first large dataset annotated for interestingness and expected interestingness in teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus (TSCC), IntrEx extends prior work by incorporating sequence-level annotations, allowing for the study of engagement beyond isolated turns to capture how interest evolves over extended dialogues. We employ a rigorous annotation process with over 100 second-language learners, using a comparison-based rating approach inspired by reinforcement learning from human feedback (RLHF) to improve agreement. We investigate whether large language models (LLMs) can predict human interestingness judgments. We find that LLMs (7B/8B parameters) fine-tuned on interestingness ratings outperform larger proprietary models like GPT-4o, demonstrating the potential for specialised datasets to model engagement in educational settings. Finally, we analyze how linguistic and cognitive factors, such as concreteness, comprehensibility (readability), and uptake, influence engagement in educational dialogues."
arXiv cs.CL,Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval,https://arxiv.org/abs/2509.06650,2025-09-09 04:00:00+0000,"arXiv:2509.06650v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval stage, particularly the coarse-ranking process. Existing coarse-ranking optimization approaches often struggle to balance domain-specific knowledge learning with query enhencement, resulting in suboptimal retrieval performance. To address this challenge, we propose MoLER, a domain-aware RAG method that uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of Losses (MoL) to balance domain-specific knowledge with general language capabilities, and a reinforcement learning (RL) phase leveraging Group Relative Policy Optimization (GRPO) to optimize query and passage generation for maximizing document recall. A key innovation is our Multi-query Single-passage Late Fusion (MSLF) strategy, which reduces computational overhead during RL training while maintaining scalable inference via Multi-query Multi-passage Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER achieves state-of-the-art performance, significantly outperforming baseline methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and scalable retrieval in specialized domains."
arXiv cs.CL,Modelling Intertextuality with N-gram Embeddings,https://arxiv.org/abs/2509.06637,2025-09-09 04:00:00+0000,"arXiv:2509.06637v1 Announce Type: new 
Abstract: Intertextuality is a central tenet in literary studies. It refers to the intricate links between literary texts that are created by various types of references. This paper proposes a new quantitative model of intertextuality to enable scalable analysis and network-based insights: perform pairwise comparisons of the embeddings of n-grams from two texts and average their results as the overall intertextuality. Validation on four texts with known degrees of intertextuality, alongside a scalability test on 267 diverse texts, demonstrates the method's effectiveness and efficiency. Network analysis further reveals centrality and community structures, affirming the approach's success in capturing and quantifying intertextual relationships."
arXiv cs.CL,Guided Decoding and Its Critical Role in Retrieval-Augmented Generation,https://arxiv.org/abs/2509.06631,2025-09-09 04:00:00+0000,"arXiv:2509.06631v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into various applications has driven the need for structured and reliable responses. A key challenge in Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align with expected formats while minimizing hallucinations. This study examines the role of guided decoding in RAG systems, comparing three methods, Outlines, XGrammar, and LM Format Enforcer, across different multi-turn prompting setups (0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates, and output quality, we provide insights into their performance and applicability. Our findings reveal how multi-turn interactions influence guided decoding, uncovering unexpected performance variations that can inform method selection for specific use cases. This work advances the understanding of structured output generation in RAG systems, offering both theoretical insights and practical guidance for LLM deployment."
arXiv cs.CL,HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models,https://arxiv.org/abs/2509.06596,2025-09-09 04:00:00+0000,"arXiv:2509.06596v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often produce hallucinations in retrieval-augmented or long-context generation, even when relevant evidence is present. This stems from two issues: head importance is treated as input-agnostic, and raw attention weights poorly reflect each token's true contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a parameter-free decoding framework that directly addresses both challenges. HAVE introduces head-adaptive gating, which performs instance-level soft reweighing of attention heads, and value calibration, which augments attention with the magnitude of value vectors to approximate write-back contribution. Together, these modules construct token-level evidence aligned with model updates and fuse it with the LM distribution through a lightweight uncertainty-scaled policy. HAVE requires no finetuning and operates in a single forward pass, making it efficient and broadly applicable. Experiments across multiple QA benchmarks and LLM families demonstrate that HAVE consistently reduces hallucinations and outperforms strong baselines, including DAGCD, with modest overhead. The framework is transparent, reproducible, and readily integrates with off-the-shelf LLMs, advancing trustworthy generation in real-world settings."
arXiv cs.CL,SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion,https://arxiv.org/abs/2509.06531,2025-09-09 04:00:00+0000,"arXiv:2509.06531v1 Announce Type: new 
Abstract: Link prediction in knowledge graphs requires integrating structural information and semantic context to infer missing entities. While large language models offer strong generative reasoning capabilities, their limited exploitation of structural signals often results in structural sparsity and semantic ambiguity, especially under incomplete or zero-shot settings. To address these challenges, we propose SLiNT (Structure-aware Language model with Injection and coNtrastive Training), a modular framework that injects knowledge-graph-derived structural context into a frozen LLM backbone with lightweight LoRA-based adaptation for robust link prediction. Specifically, Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive Learning (DHCL) introduces fine-grained supervision by interpolating hard positives and negatives to resolve entity-level ambiguity; and Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware intervention while preserving the core LLM parameters. Experiments on WN18RR and FB15k-237 show that SLiNT achieves superior or competitive performance compared with both embedding-based and generation-based baselines, demonstrating the effectiveness of structure-aware representation learning for scalable knowledge graph completion."
arXiv cs.CL,LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection,https://arxiv.org/abs/2509.06524,2025-09-09 04:00:00+0000,"arXiv:2509.06524v1 Announce Type: new 
Abstract: Adapting large language models (LLMs) to specific domains often faces a critical bottleneck: the scarcity of high-quality, human-curated data. While large volumes of unchecked data are readily available, indiscriminately using them for fine-tuning risks introducing noise and degrading performance. Strategic data selection is thus crucial, requiring a method that is both accurate and efficient. Existing approaches, categorized as similarity-based and direct optimization methods, struggle to simultaneously achieve these goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for domain-specific DAta Selection), a novel approach that leverages the pre-trained LLM itself as an implicit classifier, thereby bypassing explicit feature engineering and computationally intensive optimization process. LAMDAS reframes data selection as a one-class classification problem, identifying candidate data that ""belongs"" to the target domain defined by a small reference dataset. Extensive experimental results demonstrate that LAMDAS not only exceeds the performance of full-data training using a fraction of the data but also outperforms nine state-of-the-art (SOTA) baselines under various scenarios. Furthermore, LAMDAS achieves the most compelling balance between performance gains and computational efficiency compared to all evaluated baselines."
arXiv cs.CL,"Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training",https://arxiv.org/abs/2509.06518,2025-09-09 04:00:00+0000,"arXiv:2509.06518v1 Announce Type: new 
Abstract: Transformer-based language models traditionally use uniform (isotropic) layer sizes, yet they ignore the diverse functional roles that different depths can play and their computational capacity needs. Building on Layer-Wise Scaling (LWS) and pruning literature, we introduce three new LWS variants - Framed, Reverse, and Crown - that redistribute FFN widths and attention heads via two or three-point linear interpolation in the pre-training stage. We present the first systematic ablation of LWS and its variants, on a fixed budget of 180M parameters, trained on 5B tokens. All models converge to similar losses and achieve better performance compared to an equal-cost isotropic baseline, without a substantial decrease in training throughput. This work represents an initial step into the design space of layer-wise architectures for pre-training, but future work should scale experiments to orders of magnitude more tokens and parameters to fully assess their potential."
arXiv cs.CL,WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents,https://arxiv.org/abs/2509.06501,2025-09-09 04:00:00+0000,"arXiv:2509.06501v1 Announce Type: new 
Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward agentic applications, where web browsing capabilities are fundamental for retrieving information from diverse online sources. However, existing open-source web agents either demonstrate limited information-seeking abilities on complex tasks or lack transparent implementations. In this work, we identify that the key challenge lies in the scarcity of challenging data for information seeking. To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution. This method creates challenging query-answer pairs that require multi-step reasoning and complex web navigation. By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning. Our model supports 128K context length and up to 100 tool calling turns, enabling long-horizon problem solving. Across diverse information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able to effectively search over an average of 16 turns after RL training, achieving higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best performance among models up to 100B parameters on WebWalkerQA and FRAMES. Beyond these information-seeking tasks, our model also achieves strong generalization on the HLE benchmark even though it is only trained on knowledge-intensive QA data. These results highlight our approach as a practical path toward long-horizon web agents."
arXiv cs.CL,Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models,https://arxiv.org/abs/2509.06415,2025-09-09 04:00:00+0000,"arXiv:2509.06415v1 Announce Type: cross 
Abstract: Recent progress in vision-language models (VLMs) has led to impressive results in document understanding tasks, but their high computational demands remain a challenge. To mitigate the compute burdens, we propose a lightweight token pruning framework that filters out non-informative background regions from document images prior to VLM processing. A binary patch-level classifier removes non-text areas, and a max-pooling refinement step recovers fragmented text regions to enhance spatial coherence. Experiments on real-world document datasets demonstrate that our approach substantially lowers computational costs, while maintaining comparable accuracy."
arXiv cs.CL,Do LLMs exhibit the same commonsense capabilities across languages?,https://arxiv.org/abs/2509.06401,2025-09-09 04:00:00+0000,"arXiv:2509.06401v1 Announce Type: new 
Abstract: This paper explores the multilingual commonsense generation abilities of Large Language Models (LLMs). To facilitate this investigation, we introduce MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four languages: English, Spanish, Dutch, and Valencian. The task involves generating a commonsensical sentence that includes a given triplet of words. We evaluate a range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and Salamandra, on this benchmark. Our evaluation combines automatic metrics, LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human annotations. Results consistently show superior performance in English, with significantly lower performance in less-resourced languages. While contextual support yields mixed results, it tends to benefit underrepresented languages. These findings underscore the current limitations of LLMs in multilingual commonsense generation. The dataset is publicly available at https://huggingface.co/datasets/gplsi/MULTICOM."
arXiv cs.CL,PL-CA: A Parametric Legal Case Augmentation Framework,https://arxiv.org/abs/2509.06356,2025-09-09 04:00:00+0000,"arXiv:2509.06356v1 Announce Type: new 
Abstract: Conventional RAG is considered one of the most effective methods for addressing model knowledge insufficiency and hallucination, particularly in the judicial domain that requires high levels of knowledge rigor, logical consistency, and content integrity. However, the conventional RAG method only injects retrieved documents directly into the model's context, which severely constrains models due to their limited context windows and introduces additional computational overhead through excessively long contexts, thereby disrupting models' attention and degrading performance on downstream tasks. Moreover, many existing benchmarks lack expert annotation and focus solely on individual downstream tasks while real-world legal scenarios consist of multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for reflecting models' true capabilities. To address these limitations, we propose PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data augmentation on corpus knowledge and encode this legal knowledge into parametric vectors, and then integrates this parametric knowledge into the LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context pressure. Additionally, we also construct a multi-task legal dataset comprising more than 2000 training and test instances, which are all expert-annotated and manually verified. We conduct our experiments on our dataset, and the experimental results demonstrate that our method reduces the overhead associated with excessively long contexts while maintaining competitive performance on downstream tasks compared to conventional RAG. Our code and dataset are provided in the appendix."
arXiv cs.CL,Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?,https://arxiv.org/abs/2509.06350,2025-09-09 04:00:00+0000,"arXiv:2509.06350v1 Announce Type: new 
Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various successful methods whereby attackers manipulate models into generating harmful responses that they are designed to avoid. Among these, Greedy Coordinate Gradient (GCG) has emerged as a general and effective approach that optimizes the tokens in a suffix to generate jailbreakable prompts. While several improved variants of GCG have been proposed, they all rely on fixed-length suffixes. However, the potential redundancy within these suffixes remains unexplored. In this work, we propose Mask-GCG, a plug-and-play method that employs learnable token masking to identify impactful tokens within the suffix. Our approach increases the update probability for tokens at high-impact positions while pruning those at low-impact positions. This pruning not only reduces redundancy but also decreases the size of the gradient space, thereby lowering computational overhead and shortening the time required to achieve successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the original GCG and several improved variants. Experimental results show that most tokens in the suffix contribute significantly to attack success, and pruning a minority of low-impact tokens does not affect the loss values or compromise the attack success rate (ASR), thereby revealing token redundancy in LLM prompts. Our findings provide insights for developing efficient and interpretable LLMs from the perspective of jailbreak attacks."
arXiv cs.CL,SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents,https://arxiv.org/abs/2509.06283,2025-09-09 04:00:00+0000,"arXiv:2509.06283v1 Announce Type: cross 
Abstract: Equipping large language models (LLMs) with complex, interleaved reasoning and tool-use capabilities has become a key focus in agentic AI research, especially with recent advances in reasoning-oriented (``thinking'') models. Such capabilities are key to unlocking a number of important applications. One such application is Deep Research (DR), which requires extensive search and reasoning over many sources. Our work in this paper focuses on the development of native Autonomous Single-Agent models for DR featuring minimal web crawling and Python tool integration. Unlike multi-agent systems, where agents take up pre-defined roles and are told what to do at each step in a static workflow, an autonomous single-agent determines its next action dynamically based on context, without manual directive. While prior work has proposed training recipes for base or instruction-tuned LLMs, we focus on continual reinforcement learning (RL) of reasoning-optimized models to further enhance agentic skills while preserving reasoning ability. Towards this end, we propose a simple RL recipe with entirely synthetic data, which we apply to various open-source LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam benchmark. In addition, we conduct key analysis experiments to provide more insights into our methodologies."
arXiv cs.CL,No Encore: Unlearning as Opt-Out in Music Generation,https://arxiv.org/abs/2509.06277,2025-09-09 04:00:00+0000,"arXiv:2509.06277v1 Announce Type: new 
Abstract: AI music generation is rapidly emerging in the creative industries, enabling intuitive music generation from textual descriptions. However, these systems pose risks in exploitation of copyrighted creations, raising ethical and legal concerns. In this paper, we present preliminary results on the first application of machine unlearning techniques from an ongoing research to prevent inadvertent usage of creative content. Particularly, we explore existing methods in machine unlearning to a pre-trained Text-to-Music (TTM) baseline and analyze their efficacy in unlearning pre-trained datasets without harming model performance. Through our experiments, we provide insights into the challenges of applying unlearning in music generation, offering a foundational analysis for future works on the application of unlearning for music generative models."
arXiv cs.CL,"Beamforming-LLM: What, Where and When Did I Miss?",https://arxiv.org/abs/2509.06221,2025-09-09 04:00:00+0000,"arXiv:2509.06221v1 Announce Type: cross 
Abstract: We present Beamforming-LLM, a system that enables users to semantically recall conversations they may have missed in multi-speaker environments. The system combines spatial audio capture using a microphone array with retrieval-augmented generation (RAG) to support natural language queries such as, ""What did I miss when I was following the conversation on dogs?"" Directional audio streams are separated using beamforming, transcribed with Whisper, and embedded into a vector database using sentence encoders. Upon receiving a user query, semantically relevant segments are retrieved, temporally aligned with non-attended segments, and summarized using a lightweight large language model (GPT-4o-mini). The result is a user-friendly interface that provides contrastive summaries, spatial context, and timestamped audio playback. This work lays the foundation for intelligent auditory memory systems and has broad applications in assistive technology, meeting summarization, and context-aware personal spatial computing."
arXiv cs.CL,MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment,https://arxiv.org/abs/2509.06200,2025-09-09 04:00:00+0000,"arXiv:2509.06200v1 Announce Type: new 
Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs LLM fine-tuning to enhance resume parsing in recruitment automation. It integrates fine-tuned Large Language Models (LLMs) using weighted voting, with each model specializing in a specific resume segment to boost accuracy. Building on MLAR , MSLEF introduces a segment-aware architecture that leverages field-specific weighting tailored to each resume part, effectively overcoming the limitations of single-model systems by adapting to diverse formats and structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4 14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score, BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best single model by up to +7% in RS. Its segment-aware design enhances generalization across varied resume layouts, making it highly adaptable to real-world hiring scenarios while ensuring precise and reliable candidate representation."
arXiv cs.CL,Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation,https://arxiv.org/abs/2509.06196,2025-09-09 04:00:00+0000,"arXiv:2509.06196v1 Announce Type: new 
Abstract: This paper presents a novel approach to recruitment automation. Large Language Models (LLMs) were fine-tuned to improve accuracy and efficiency. Building upon our previous work on the Multilayer Large Language Model-Based Robotic Process Automation Applicant Tracking (MLAR) system . This work introduces a novel methodology. Training fine-tuned LLMs specifically tuned for recruitment tasks. The proposed framework addresses the limitations of generic LLMs by creating a synthetic dataset that uses a standardized JSON format. This helps ensure consistency and scalability. In addition to the synthetic data set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes were parsed into the same structured JSON format and placed in the training set. This will help improve data diversity and realism. Through experimentation, we demonstrate significant improvements in performance metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall similarity compared to base models and other state-of-the-art LLMs. In particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%, indicating exceptional precision and recall in recruitment tasks. This study highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize recruitment workflows by providing more accurate candidate-job matching."
arXiv cs.CL,Language Bias in Information Retrieval: The Nature of the Beast and Mitigation Methods,https://arxiv.org/abs/2509.06195,2025-09-09 04:00:00+0000,"arXiv:2509.06195v1 Announce Type: cross 
Abstract: Language fairness in multilingual information retrieval (MLIR) systems is crucial for ensuring equitable access to information across diverse languages. This paper sheds light on the issue, based on the assumption that queries in different languages, but with identical semantics, should yield equivalent ranking lists when retrieving on the same multilingual documents. We evaluate the degree of fairness using both traditional retrieval methods, and a DPR neural ranker based on mBERT and XLM-R. Additionally, we introduce `LaKDA', a novel loss designed to mitigate language biases in neural MLIR approaches. Our analysis exposes intrinsic language biases in current MLIR technologies, with notable disparities across the retrieval methods, and the effectiveness of LaKDA in enhancing language fairness."
arXiv cs.CL,Understanding the Influence of Synthetic Data for Text Embedders,https://arxiv.org/abs/2509.06184,2025-09-09 04:00:00+0000,"arXiv:2509.06184v1 Announce Type: new 
Abstract: Recent progress in developing general purpose text embedders has been driven by training on ever-growing corpora of synthetic LLM-generated data. Nonetheless, no publicly available synthetic dataset exists, posing a barrier to studying its role for generalization. To address this issue, we first reproduce and publicly release the synthetic data proposed by Wang et al. (Mistral-E5). Our synthetic data is high quality and leads to consistent improvements in performance. Next, we critically examine where exactly synthetic data improves model generalization. Our analysis reveals that benefits from synthetic data are sparse and highly localized to individual datasets. Moreover, we observe trade-offs between the performance on different categories and data that benefits one task, degrades performance on another. Our findings highlight the limitations of current synthetic data approaches for building general-purpose embedders and challenge the notion that training on synthetic data leads to more robust embedding models across tasks."
arXiv cs.CL,From Long to Short: LLMs Excel at Trimming Own Reasoning Chains,https://arxiv.org/abs/2509.06174,2025-09-09 04:00:00+0000,"arXiv:2509.06174v1 Announce Type: cross 
Abstract: O1/R1 style large reasoning models (LRMs) signal a substantial leap forward over conventional instruction-following LLMs. By applying test-time scaling to generate extended reasoning paths, they establish many SOTAs across a wide range of complex reasoning tasks. However, recent studies show that LRMs are prone to suffer from overthinking -- the tendency to overcomplicate simple problems, leading to excessive strategy switching and long, convoluted reasoning traces that hinder their interpretability. To mitigate this issue, we conduct a systematic investigation into the reasoning efficiency of a broad set of LRMs and uncover a common dilemma: the difficulty in balancing multiple generation objectives such as correctness and brevity. Based on this discovery, we propose a test-time scaling method, EDIT (Efficient Dynamic Inference Trimming), which efficiently guides LRMs to identify the shortest correct reasoning paths at test time. EDIT employs constraint-guided generation while jointly tracking length and answer distributions under varying constraints, allowing it to select responses that strike an optimal balance between conciseness and correctness. Extensive experiments across diverse models and datasets show that EDIT substantially enhance the reasoning efficiency, producing compact yet informative outputs that improve readability and user experience."
arXiv cs.CL,Benchmarking Gender and Political Bias in Large Language Models,https://arxiv.org/abs/2509.06164,2025-09-09 04:00:00+0000,"arXiv:2509.06164v1 Announce Type: new 
Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language models (LLMs) in politically sensitive contexts. It links European Parliament debate speeches to roll-call vote outcomes and includes rich demographic metadata for each Member of the European Parliament (MEP), such as gender, age, country, and political group. Using EuroParlVote, we evaluate state-of-the-art LLMs on two tasks -- gender classification and vote prediction -- revealing consistent patterns of bias. We find that LLMs frequently misclassify female MEPs as male and demonstrate reduced accuracy when simulating votes for female speakers. Politically, LLMs tend to favor centrist groups while underperforming on both far-left and far-right ones. Proprietary models like GPT-4o outperform open-weight alternatives in terms of both robustness and fairness. We release the EuroParlVote dataset, code, and demo to support future research on fairness and accountability in NLP within political contexts."
arXiv cs.CL,Reverse-Engineered Reasoning for Open-Ended Generation,https://arxiv.org/abs/2509.06160,2025-09-09 04:00:00+0000,"arXiv:2509.06160v1 Announce Type: cross 
Abstract: While the ``deep reasoning'' paradigm has spurred significant advances in verifiable domains like mathematics, its application to open-ended, creative generation remains a critical challenge. The two dominant methods for instilling reasoning -- reinforcement learning (RL) and instruction distillation -- falter in this area; RL struggles with the absence of clear reward signals and high-quality reward models, while distillation is prohibitively expensive and capped by the teacher model's capabilities. To overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a new paradigm that fundamentally shifts the approach. Instead of building a reasoning process ``forwards'' through trial-and-error or imitation, REER works ``backwards'' from known-good solutions to computationally discover the latent, step-by-step deep reasoning process that could have produced them. Using this scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks. Our model, DeepWriter-8B, trained on this data, not only surpasses strong open-source baselines but also achieves performance competitive with, and at times superior to, leading proprietary models like GPT-4o and Claude 3.5."
arXiv cs.CL,Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models,https://arxiv.org/abs/2509.06100,2025-09-09 04:00:00+0000,"arXiv:2509.06100v1 Announce Type: new 
Abstract: Large language models (LLMs) are prone to catastrophic forgetting in sequential multi-task settings. Parameter regularization methods such as O-LoRA and N-LoRA alleviate task interference by enforcing low-rank subspace orthogonality, but they overlook the fact that conventional additive fine-tuning disrupts the intrinsic geometric structure of LLM parameters, limiting performance. Our key insight is that the parameter space of LLMs possesses a geometric structure, which must be preserved in addition to enforcing orthogonality. Based on this, we propose Orthogonal Low-rank Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM fine-tuning: leveraging multiplicative updates to preserve parameter geometry while applying orthogonality constraints to task subspaces. Experiments demonstrate that OLieRA achieves state-of-the-art results on the Standard CL benchmark and remains among the top-performing methods in the Large Number of Tasks setting."
arXiv cs.CL,Language Native Lightly Structured Databases for Large Language Model Driven Composite Materials Research,https://arxiv.org/abs/2509.06093,2025-09-09 04:00:00+0000,"arXiv:2509.06093v1 Announce Type: cross 
Abstract: Chemical and materials research has traditionally relied heavily on knowledge narrative, with progress often driven by language-based descriptions of principles, mechanisms, and experimental experiences, rather than tables, limiting what conventional databases and ML can exploit. We present a language-native database for boron nitride nanosheet (BNNS) polymer thermally conductive composites that captures lightly structured information from papers across preparation, characterization, theory-computation, and mechanistic reasoning, with evidence-linked snippets. Records are organized in a heterogeneous database and queried via composite retrieval with semantics, key words and value filters. The system can synthesizes literature into accurate, verifiable, and expert style guidance. This substrate enables high fidelity efficient Retrieval Augmented Generation (RAG) and tool augmented agents to interleave retrieval with reasoning and deliver actionable SOP. The framework supplies the language rich foundation required for LLM-driven materials discovery."
arXiv cs.CL,Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge,https://arxiv.org/abs/2509.06079,2025-09-09 04:00:00+0000,"arXiv:2509.06079v1 Announce Type: new 
Abstract: Multimodal reasoning remains a fundamental challenge in artificial intelligence. Despite substantial advances in text-based reasoning, even state-of-the-art models such as GPT-o3 struggle to maintain strong performance in multimodal scenarios. To address this gap, we introduce a caption-assisted reasoning framework that effectively bridges visual and textual modalities. Our approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge 2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we validate its generalization on the MathVerse benchmark for geometric reasoning, demonstrating the versatility of our method. Our code is publicly available at https://github.com/OpenDCAI/SciReasoner."
arXiv cs.CL,Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis,https://arxiv.org/abs/2509.06074,2025-09-09 04:00:00+0000,"arXiv:2509.06074v1 Announce Type: new 
Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural prosody by understanding the multimodal dialogue history (MDH). The latest work predicts the accurate prosody expression of the target utterance by modeling the utterance-level interaction characteristics of MDH and the target utterance. However, MDH contains fine-grained semantic and prosody knowledge at the word level. Existing methods overlook the fine-grained semantic and prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our approach constructs two specialized multimodal fine-grained dialogue interaction graphs: a semantic interaction graph and a prosody interaction graph. These two interaction graphs effectively encode interactions between word-level semantics, prosody, and their influence on subsequent utterances in MDH. The encoded interaction features are then leveraged to enhance synthesized speech with natural conversational prosody. Experiments on the DailyTalk dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of prosodic expressiveness. Code and speech samples are available at https://github.com/AI-S2-Lab/MFCIG-CSS."
arXiv cs.CL,KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino,https://arxiv.org/abs/2509.06065,2025-09-09 04:00:00+0000,"arXiv:2509.06065v1 Announce Type: new 
Abstract: Large Language Models (LLMs) achieve remarkable performance across various tasks, but their tendency to produce hallucinations limits reliable adoption. Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet they are primarily available in English, leaving a gap in evaluating LLMs in low-resource languages. To address this, we present KatotohananQA, a Filipino translation of the TruthfulQA benchmark. Seven free-tier proprietary models were assessed using a binary-choice framework. Findings show a significant performance gap between English and Filipino truthfulness, with newer OpenAI models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness. Results also reveal disparities across question characteristics, suggesting that some question types, categories, and topics are less robust to multilingual transfer which highlight the need for broader multilingual evaluation to ensure fairness and reliability in LLM usage."
arXiv cs.CL,TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition,https://arxiv.org/abs/2509.05983,2025-09-09 04:00:00+0000,"arXiv:2509.05983v1 Announce Type: cross 
Abstract: Code-switching (CS) presents a significant challenge for general Auto-Speech Recognition (ASR) systems. Existing methods often fail to capture the subtle phonological shifts inherent in CS scenarios. The challenge is particularly difficult for language pairs like Vietnamese and English, where both distinct phonological features and the ambiguity arising from similar sound recognition are present. In this paper, we propose a novel architecture for Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC employs a phoneme-centric approach, built upon an extended Vietnamese phoneme set as an intermediate representation to facilitate mixed-lingual modeling. Experimental results demonstrate that TSPC consistently outperforms existing baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a significantly lower word error rate of 20.8\% with reduced training resources. Furthermore, the phonetic-based two-stage architecture enables phoneme adaptation and language conversion to enhance ASR performance in complex CS Vietnamese-English ASR scenarios."
arXiv cs.CL,Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance,https://arxiv.org/abs/2509.05978,2025-09-09 04:00:00+0000,"arXiv:2509.05978v1 Announce Type: cross 
Abstract: Vision-language models have demonstrated impressive capabilities in generating 2D images under various conditions; however the impressive performance of these models in 2D is largely enabled by extensive, readily available pretrained foundation models. Critically, comparable pretrained foundation models do not exist for 3D, significantly limiting progress in this domain. As a result, the potential of vision-language models to produce high-resolution 3D counterfactual medical images conditioned solely on natural language descriptions remains completely unexplored. Addressing this gap would enable powerful clinical and research applications, such as personalized counterfactual explanations, simulation of disease progression scenarios, and enhanced medical training by visualizing hypothetical medical conditions in realistic detail. Our work takes a meaningful step toward addressing this challenge by introducing a framework capable of generating high-resolution 3D counterfactual medical images of synthesized patients guided by free-form language prompts. We adapt state-of-the-art 3D diffusion models with enhancements from Simple Diffusion and incorporate augmented conditioning to improve text alignment and image quality. To our knowledge, this represents the first demonstration of a language-guided native-3D diffusion model applied specifically to neurological imaging data, where faithful three-dimensional modeling is essential to represent the brain's three-dimensional structure. Through results on two distinct neurological MRI datasets, our framework successfully simulates varying counterfactual lesion loads in Multiple Sclerosis (MS), and cognitive states in Alzheimer's disease, generating high-quality images while preserving subject fidelity in synthetically generated medical images. Our results lay the groundwork for prompt-driven disease progression analysis within 3D medical imaging."
arXiv cs.CL,Accelerating Large Language Model Inference via Early-Exiting Algorithms,https://arxiv.org/abs/2509.05915,2025-09-09 04:00:00+0000,"arXiv:2509.05915v1 Announce Type: new 
Abstract: Large language models have achieved remarkable capabilities, but their practical deployment is hindered by significant computational costs. While adaptive computation methods like early-exiting promise to reduce these costs, they introduce a fundamental conflict: the per-token dynamism intended to save computation often creates system-level bottlenecks that can paradoxically reduce throughput in batched inference. This dissertation resolves this conflict by co-designing adaptive algorithms and model architectures to strike an optimal balance between dynamism and efficiency. To this end, our work first addresses critical sources of overhead in conventional early-exiting by proposing an efficient parallel decoding mechanism. We then show that deep parameter sharing provides an architectural foundation that not only yields compact, parameter-efficient models but also inherently mitigates the critical synchronization issues affecting dynamic inference. Finally, this work presents a unified framework where lightweight routers are pretrained to dynamically assign an optimal recursion depth for each token. This approach establishes a new Pareto frontier between efficiency and performance by effectively optimizing for both adaptive computation and parameter efficiency within a single model."
arXiv cs.CL,Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling,https://arxiv.org/abs/2509.05908,2025-09-09 04:00:00+0000,"arXiv:2509.05908v1 Announce Type: new 
Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR) models have made notable advancements in recognizing personalized biasing phrases. However, the effectiveness of cross-attention is affected by variations in biasing information volume, especially when the length of the biasing list increases significantly. We find that, regardless of the length of the biasing list, only a limited amount of biasing information is most relevant to a specific ASR intermediate representation. Therefore, by identifying and integrating the most relevant biasing information rather than the entire biasing list, we can alleviate the effects of variations in biasing information volume for contextual ASR. To this end, we propose a purified semantic correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and calculate three semantic correlations between the ASR intermediate representations and biasing information from coarse to fine: list-level, phrase-level, and token-level. Then, the three correlations are jointly modeled to produce their intersection, so that the most relevant biasing information across various granularities is highlighted and integrated for contextual recognition. In addition, to reduce the computational cost introduced by the joint modeling of three semantic correlations, we also propose a purification mechanism based on a grouped-and-competitive strategy to filter out irrelevant biasing phrases. Compared with baselines, our PSC-Joint approach achieves average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46% on KeSpeech, across biasing lists of varying lengths."
arXiv cs.CL,Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues,https://arxiv.org/abs/2509.05882,2025-09-09 04:00:00+0000,"arXiv:2509.05882v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are increasingly being considered ""collaborators"" with humans. If such AI collaborators are to be reliable, their behavior over multiturn interactions must be predictable, validated and verified before deployment. Common alignment techniques are typically developed under simplified single-user settings and do not account for the dynamics of long-horizon multiparty interactions. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multiturn, multiparty collaborations. We study this question through the lens of friction agents that intervene in group dialogues to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Using a roleplay methodology, we evaluate interventions from differently-trained friction agents in collaborative task conversations. We propose a novel counterfactual evaluation framework that quantifies how friction interventions change the trajectory of group collaboration and belief alignment. Our results show that a friction-aware approach significantly outperforms common alignment baselines in helping both convergence to a common ground, or agreed-upon task-relevant propositions, and correctness of task outcomes."
arXiv cs.CL,MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries,https://arxiv.org/abs/2509.05878,2025-09-09 04:00:00+0000,"arXiv:2509.05878v1 Announce Type: new 
Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical text is a critical barrier to adoption, as expert review is unscalable for the continuous quality assurance these systems require. We address this challenge with two complementary contributions. First, we introduce MedFactEval, a framework for scalable, fact-grounded evaluation where clinicians define high-salience key facts and an ""LLM Jury""--a multi-LLM majority vote--assesses their inclusion in generated summaries. Second, we present MedAgentBrief, a model-agnostic, multi-step workflow designed to generate high-quality, factual discharge summaries. To validate our evaluation framework, we established a gold-standard reference using a seven-physician majority vote on clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury achieved almost perfect agreement with this panel (Cohen's kappa=81%), a performance statistically non-inferior to that of a single human expert (kappa=67%, P < 0.001). Our work provides both a robust evaluation framework (MedFactEval) and a high-performing generation workflow (MedAgentBrief), offering a comprehensive approach to advance the responsible deployment of generative AI in clinical workflows."
arXiv cs.CL,ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula,https://arxiv.org/abs/2509.05867,2025-09-09 04:00:00+0000,"arXiv:2509.05867v1 Announce Type: new 
Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in treating epidemics and complex diseases. Existing models for TCM utilize traditional algorithms or deep learning techniques to analyze formula relationships, yet lack comprehensive results, such as complete formula compositions and detailed explanations. Although recent efforts have used TCM instruction datasets to fine-tune Large Language Models (LLMs) for explainable formula generation, existing datasets lack sufficient details, such as the roles of the formula's sovereign, minister, assistant, courier; efficacy; contraindications; tongue and pulse diagnosis-limiting the depth of model outputs. To address these challenges, we propose ZhiFangDanTai, a framework combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured TCM knowledge into concise summaries, while also constructing an enhanced instruction dataset to improve LLMs' ability to integrate retrieved information. Furthermore, we provide novel theoretical proofs demonstrating that integrating GraphRAG with fine-tuning techniques can reduce generalization error and hallucination rates in the TCM formula task. Experimental results on both collected and clinical datasets demonstrate that ZhiFangDanTai achieves significant improvements over state-of-the-art models. Our model is open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0."
arXiv cs.CL,LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization,https://arxiv.org/abs/2509.05863,2025-09-09 04:00:00+0000,"arXiv:2509.05863v1 Announce Type: new 
Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded speech-to-speech translation that preserves the source speaker's identity across languages. LatinX is a 12-layer decoder-only Transformer trained in three stages: (i) pre-training for text-to-audio mapping, (ii) supervised fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct Preference Optimization (DPO) using automatically labeled pairs based on Word Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER and improves objective similarity over the fine-tuned baseline. Human evaluations further indicate stronger perceived speaker similarity than a strong baseline (XTTSv2), revealing gaps between objective and subjective measures. We provide cross-lingual analyses and discuss balanced preference signals and lower-latency architectures as future work."
arXiv cs.CL,Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification,https://arxiv.org/abs/2509.05741,2025-09-09 04:00:00+0000,"arXiv:2509.05741v1 Announce Type: new 
Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a novel method designed to address the pervasive issues of hallucination and the absence of credible citation sources in Large Language Models (LLMs) when generating complex, fact-sensitive content. By incorporating a multi-stage mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT empowers LLMs to critically self-examine and revise their intermediate reasoning steps and final answers. This process significantly enhances the objective accuracy, trustworthiness, and traceability of the generated outputs, making LLMs more reliable for applications demanding high fidelity such as scientific research, news reporting, and legal consultation."
arXiv cs.CL,QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing,https://arxiv.org/abs/2509.05729,2025-09-09 04:00:00+0000,"arXiv:2509.05729v1 Announce Type: new 
Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to encoding and understanding the complexity of natural languages through the power of quantum computation. This paper presents a pretrained quantum context-sensitive embedding model, called QCSE, that captures context-sensitive word embeddings, leveraging the unique properties of quantum systems to learn contextual relationships in languages. The model introduces quantum-native context learning, enabling the utilization of quantum computers for linguistic tasks. Central to the proposed approach are innovative context matrix computation methods, designed to create unique, representations of words based on their surrounding linguistic context. Five distinct methods are proposed and tested for computing the context matrices, incorporating techniques such as exponential decay, sinusoidal modulation, phase shifts, and hash-based transformations. These methods ensure that the quantum embeddings retain context sensitivity, thereby making them suitable for downstream language tasks where the expressibility and properties of quantum systems are valuable resources. To evaluate the effectiveness of the model and the associated context matrix methods, evaluations are conducted on both a Fulani corpus, a low-resource African language, dataset of small size and an English corpus of slightly larger size. The results demonstrate that QCSE not only captures context sensitivity but also leverages the expressibility of quantum systems for representing rich, context-aware language information. The use of Fulani further highlights the potential of QNLP to mitigate the problem of lack of data for this category of languages. This work underscores the power of quantum computation in natural language processing (NLP) and opens new avenues for applying QNLP to real-world linguistic challenges across various tasks and domains."
arXiv cs.CL,Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models,https://arxiv.org/abs/2509.05719,2025-09-09 04:00:00+0000,"arXiv:2509.05719v1 Announce Type: new 
Abstract: Given Farsi's speaker base of over 127 million people and the growing availability of digital text, including more than 1.3 million articles on Wikipedia, it is considered a middle-resource language. However, this label quickly crumbles when the situation is examined more closely. We focus on three subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection) and find significant challenges in data availability and quality, despite the overall increase in data availability. We review 110 publications on subjective tasks in Farsi and observe a lack of publicly available datasets. Furthermore, existing datasets often lack essential demographic factors, such as age and gender, that are crucial for accurately modeling subjectivity in language. When evaluating prediction models using the few available datasets, the results are highly unstable across both datasets and models. Our findings indicate that the volume of data is insufficient to significantly improve a language's prospects in NLP."
arXiv cs.CL,A Survey of the State-of-the-Art in Conversational Question Answering Systems,https://arxiv.org/abs/2509.05716,2025-09-09 04:00:00+0000,"arXiv:2509.05716v1 Announce Type: new 
Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal area within Natural Language Processing (NLP) by driving advancements that enable machines to engage in dynamic and context-aware conversations. These capabilities are increasingly being applied across various domains, i.e., customer support, education, legal, and healthcare where maintaining a coherent and relevant conversation is essential. Building on recent advancements, this survey provides a comprehensive analysis of the state-of-the-art in ConvQA. This survey begins by examining the core components of ConvQA systems, i.e., history selection, question understanding, and answer prediction, highlighting their interplay in ensuring coherence and relevance in multi-turn conversations. It further investigates the use of advanced machine learning techniques, including but not limited to, reinforcement learning, contrastive learning, and transfer learning to improve ConvQA accuracy and efficiency. The pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash, Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact through data scalability and architectural advancements. Additionally, this survey presents a comprehensive analysis of key ConvQA datasets and concludes by outlining open research directions. Overall, this work offers a comprehensive overview of the ConvQA landscape and provides valuable insights to guide future advancements in the field."
arXiv cs.CL,Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models,https://arxiv.org/abs/2509.05691,2025-09-09 04:00:00+0000,"arXiv:2509.05691v1 Announce Type: new 
Abstract: Text embedding models are widely used in natural language processing applications. However, their capability is often benchmarked on tasks that do not require understanding nuanced numerical information in text. As a result, it remains unclear whether current embedding models can precisely encode numerical content, such as numbers, into embeddings. This question is critical because embedding models are increasingly applied in domains where numbers matter, such as finance and healthcare. For example, Company X's market share grew by 2\% should be interpreted very differently from Company X's market share grew by 20\%, even though both indicate growth in market share. This study aims to examine whether text embedding models can capture such nuances. Using synthetic data in a financial context, we evaluate 13 widely used text embedding models and find that they generally struggle to capture numerical details accurately. Our further analyses provide deeper insights into embedding numeracy, informing future research to strengthen embedding model-based NLP systems with improved capacity for handling numerical content."
arXiv cs.CL,"Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian",https://arxiv.org/abs/2509.05668,2025-09-09 04:00:00+0000,"arXiv:2509.05668v1 Announce Type: new 
Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing English-centric bias in large language models. Built on Llama 3.1-8B and scaled to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens (82B English, 82B German, and 80M Bavarian), balancing resources while preventing English dominance. Targeted at the German NLP community, the model also promotes Bavarian as a low-resource language. Development tackled four challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2) creating a unified tokenizer for English, German, and Bavarian, (3) optimizing architecture and language-ratio hyperparameters for cross-lingual transfer, and (4) establishing the first standardized trilingual evaluation suite by translating German benchmarks into Bavarian. Evaluations show that Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing itself as the best model in its class for this language, while also outperforming EuroLLM in English and matching its results in German. Training on the Cerebras CS-2 demonstrated efficient large-scale multilingual pretraining with documented energy use, offering a blueprint for inclusive foundation models that integrate low-resource languages."
arXiv cs.CL,Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning,https://arxiv.org/abs/2509.05660,2025-09-09 04:00:00+0000,"arXiv:2509.05660v1 Announce Type: new 
Abstract: Large language models (LLMs) have been widely applied to assist in finding solutions for diverse questions. Prior work has proposed representing a method as a pair of a question and its corresponding solution, enabling method reuse. However, existing approaches typically require the questions to be highly similar. In this paper, we extend the scope of method reuse to address questions with low similarity or with hidden similarities that are not explicitly observable. For questions that are similar in a general-specific sense (i.e., broader or narrower in scope), we propose to first separate the question and solution, rather than directly feeding the pair to the LLM. The LLM is then guided to adapt the solution to new but related questions, allowing it to focus on solution transfer rather than question recognition. Furthermore, we extend this approach to cases where questions only share partial features or hidden characteristics. This enables cross-question method reuse beyond conventional similarity constraints. Experimental verification shows that our scope-extension approach increases the probability of filtering out reusable solutions, thereby improving the effectiveness of cross-question method reuse."
arXiv cs.CL,LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding,https://arxiv.org/abs/2509.05657,2025-09-09 04:00:00+0000,"arXiv:2509.05657v1 Announce Type: new 
Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for solving complex optimization problems, including Neural Architecture Search (NAS). However, existing LLM-driven NAS approaches rely heavily on prompt engineering and domain-specific tuning, limiting their practicality and scalability across diverse tasks. In this work, we propose LM-Searcher, a novel framework that leverages LLMs for cross-domain neural architecture optimization without the need for extensive domain-specific adaptation. Central to our approach is NCode, a universal numerical string representation for neural architectures, which enables cross-domain architecture encoding and search. We also reformulate the NAS problem as a ranking task, training LLMs to select high-performing architectures from candidate pools using instruction-tuning samples derived from a novel pruning-based subspace sampling strategy. Our curated dataset, encompassing a wide range of architecture-performance pairs, encourages robust and transferable learning. Comprehensive experiments demonstrate that LM-Searcher achieves competitive performance in both in-domain (e.g., CNNs for image classification) and out-of-domain (e.g., LoRA configurations for segmentation and generation) tasks, establishing a new paradigm for flexible and generalizable LLM-based architecture search. The datasets and models will be released at https://github.com/Ashone3/LM-Searcher."
arXiv cs.CL,Few-Shot Query Intent Detection via Relation-Aware Prompt Learning,https://arxiv.org/abs/2509.05635,2025-09-09 04:00:00+0000,"arXiv:2509.05635v1 Announce Type: new 
Abstract: Intent detection is a crucial component of modern conversational systems, since accurately identifying user intent at the beginning of a conversation is essential for generating effective responses. Recent efforts have focused on studying this problem under a challenging few-shot scenario. These approaches primarily leverage large-scale unlabeled dialogue text corpora to pretrain language models through various pretext tasks, followed by fine-tuning for intent detection with very limited annotations. Despite the improvements achieved, existing methods have predominantly focused on textual data, neglecting to effectively capture the crucial structural information inherent in conversational systems, such as the query-query relation and query-answer relation. To address this gap, we propose SAID, a novel framework that integrates both textual and relational structure information in a unified manner for model pretraining for the first time. Building on this framework, we further propose a novel mechanism, the query-adaptive attention network (QueryAdapt), which operates at the relation token level by generating intent-specific relation tokens from well-learned query-query and query-answer relations explicitly, enabling more fine-grained knowledge transfer. Extensive experimental results on two real-world datasets demonstrate that SAID significantly outperforms state-of-the-art methods."
arXiv cs.CL,On the Contribution of Lexical Features to Speech Emotion Recognition,https://arxiv.org/abs/2509.05634,2025-09-09 04:00:00+0000,"arXiv:2509.05634v1 Announce Type: cross 
Abstract: Although paralinguistic cues are often considered the primary drivers of speech emotion recognition (SER), we investigate the role of lexical content extracted from speech and show that it can achieve competitive and in some cases higher performance compared to acoustic models. On the MELD dataset, our lexical-based approach obtains a weighted F1-score (WF1) of 51.5%, compared to 49.3% for an acoustic-only pipeline with a larger parameter count. Furthermore, we analyze different self-supervised (SSL) speech and text representations, conduct a layer-wise study of transformer-based encoders, and evaluate the effect of audio denoising."
arXiv cs.CL,From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics,https://arxiv.org/abs/2509.05617,2025-09-09 04:00:00+0000,"arXiv:2509.05617v1 Announce Type: new 
Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener experiences and influencing musical preferences. This paper investigates the task of multi-label emotional attribution of song lyrics by predicting six emotional intensity scores corresponding to six fundamental emotions. A manually labeled dataset is constructed using a mean opinion score (MOS) approach, which aggregates annotations from multiple human raters to ensure reliable ground-truth labels. Leveraging this dataset, we conduct a comprehensive evaluation of several publicly available large language models (LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model specifically for predicting multi-label emotion scores. Experimental results reveal the relative strengths and limitations of zero-shot and fine-tuned models in capturing the nuanced emotional content of lyrics. Our findings highlight the potential of LLMs for emotion recognition in creative texts, providing insights into model selection strategies for emotion-based music information retrieval applications. The labeled dataset is available at https://github.com/LLM-HITCS25S/LyricsEmotionAttribution."
arXiv cs.CL,New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR,https://arxiv.org/abs/2509.05609,2025-09-09 04:00:00+0000,"arXiv:2509.05609v1 Announce Type: new 
Abstract: Aligning acoustic and linguistic representations is a central challenge to bridge the pre-trained models in knowledge transfer for automatic speech recognition (ASR). This alignment is inherently structured and asymmetric: while multiple consecutive acoustic frames typically correspond to a single linguistic token (many-to-one), certain acoustic transition regions may relate to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often include frames with no linguistic counterpart, such as background noise or silence may lead to imbalanced matching conditions. In this work, we take a new insight to regard alignment and matching as a detection problem, where the goal is to identify meaningful correspondences with high precision and recall ensuring full coverage of linguistic tokens while flexibly handling redundant or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on this new insight, we propose an unbalanced optimal transport-based alignment model that explicitly handles distributional mismatch and structural asymmetries with soft and partial matching between acoustic and linguistic modalities. Our method ensures that every linguistic token is grounded in at least one acoustic observation, while allowing for flexible, probabilistic mappings from acoustic to linguistic units. We evaluate our proposed model with experiments on an CTC-based ASR system with a pre-trained language model for knowledge transfer. Experimental results demonstrate the effectiveness of our approach in flexibly controlling degree of matching and hence to improve ASR performance."
arXiv cs.CL,Cross-Service Threat Intelligence in LLM Services using Privacy-Preserving Fingerprints,https://arxiv.org/abs/2509.05608,2025-09-09 04:00:00+0000,"arXiv:2509.05608v1 Announce Type: cross 
Abstract: The widespread deployment of LLMs across enterprise services has created a critical security blind spot. Organizations operate multiple LLM services handling billions of queries daily, yet regulatory compliance boundaries prevent these services from sharing threat intelligence about prompt injection attacks, the top security risk for LLMs. When an attack is detected in one service, the same threat may persist undetected in others for months, as privacy regulations prohibit sharing user prompts across compliance boundaries.
  We present BinaryShield, the first privacy-preserving threat intelligence system that enables secure sharing of attack fingerprints across compliance boundaries. BinaryShield transforms suspicious prompts through a unique pipeline combining PII redaction, semantic embedding, binary quantization, and randomized response mechanism to potentially generate non-invertible fingerprints that preserve attack patterns while providing privacy. Our evaluations demonstrate that BinaryShield achieves an F1-score of 0.94, significantly outperforming SimHash (0.77), the privacy-preserving baseline, while achieving 64x storage reduction and 38x faster similarity search compared to dense embeddings."
arXiv cs.CL,Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents,https://arxiv.org/abs/2509.05607,2025-09-09 04:00:00+0000,"arXiv:2509.05607v1 Announce Type: new 
Abstract: The paradigm shift from traditional ranked-based search to Generative Search Engines has rendered conventional SEO metrics obsolete, creating an urgent need to understand, measure, and optimize for content influence on synthesized answers. This paper introduces a comprehensive, end-to-end framework for Generative Search Engine Optimization (GSEO) to address this challenge. We make two primary contributions. First, we construct CC-GSEO-Bench, a large-scale, content-centric benchmark, and propose a multi-dimensional evaluation framework that systematically quantifies influence, moving beyond surface-level attribution to assess substantive semantic impact. Second, we design a novel multi-agent system that operationalizes this framework, automating the strategic refinement of content through a collaborative analyze-revise-evaluate workflow. Our empirical analysis using this framework reveals novel insights into the dynamics of content influence, offering actionable strategies for creators and establishing a principled foundation for future GSEO research."
arXiv cs.CL,Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation,https://arxiv.org/abs/2509.05605,2025-09-09 04:00:00+0000,"arXiv:2509.05605v1 Announce Type: new 
Abstract: Large Language Models (LLMs) require high quality preference datasets to align with human preferences. However, conventional methods for constructing such datasets face significant challenges: reliance on pre-collected instructions often leads to distribution mismatches with target models, while the need for sampling multiple stochastic responses introduces substantial computational overhead. In this work, we explore a paradigm shift by leveraging inherent regulation of LLMs' representation space for efficient and tailored preference dataset construction, named Icon$^{2}$. Specifically, it first extracts layer-wise direction vectors to encode sophisticated human preferences and then uses these vectors to filter self-synthesized instructions based on their inherent consistency. During decoding, bidirectional inherent control is applied to steer token representations, enabling the precise generation of response pairs with clear alignment distinctions. Experimental results demonstrate significant improvements in both alignment and efficiency. Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by up to 48.1%."
arXiv cs.CL,Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation,https://arxiv.org/abs/2509.05602,2025-09-09 04:00:00+0000,"arXiv:2509.05602v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated by LLMs to copy LLMs' abilities. However, these CoT data may include noisy rationales that either fail to substantiate the answers or contribute no additional information to support answer prediction, which leads SLMs to capture spurious correlations between questions and answers and compromise the quality of reasoning. In this work, we propose Chain-of-Thought Correctness Perception Distillation (CoPeD), which aims to improve the reasoning quality of the student model from the perspectives of task setting and data utilization. Firstly, we introduce a correctness-aware task setting that encourages the student model to predict answers based on correct rationales and revise them when they are incorrect. This setting improves the faithfulness of reasoning and allows the model to learn from its mistakes. Then, we propose a Correctness-Aware Weighted loss, which dynamically adjusts the contribution of each training instance based on the combined loss of the rationale and the answer. This strategy encourages the model to focus more on samples where the rationale offers stronger support for the correct answer. Experiments have shown that CoPeD is effective on both in-distribution (IND) and out-of-distribution (OOD) benchmark reasoning datasets."
arXiv cs.CL,Ad hoc conventions generalize to new referents,https://arxiv.org/abs/2509.05566,2025-09-09 04:00:00+0000,"arXiv:2509.05566v1 Announce Type: new 
Abstract: How do people talk about things they've never talked about before? One view suggests that a new shared naming system establishes an arbitrary link to a specific target, like proper names that cannot extend beyond their bearers. An alternative view proposes that forming a shared way of describing objects involves broader conceptual alignment, reshaping each individual's semantic space in ways that should generalize to new referents. We test these competing accounts in a dyadic communication study (N=302) leveraging the recently-released KiloGram dataset containing over 1,000 abstract tangram images. After pairs of participants coordinated on referential conventions for one set of images through repeated communication, we measured the extent to which their descriptions aligned for undiscussed images. We found strong evidence for generalization: partners showed increased alignment relative to their pre-test labels. Generalization also decayed nonlinearly with visual similarity (consistent with Shepard's law) and was robust across levels of the images' nameability. These findings suggest that ad hoc conventions are not arbitrary labels but reflect genuine conceptual coordination, with implications for theories of reference and the design of more adaptive language agents."
arXiv cs.CL,Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study,https://arxiv.org/abs/2509.05553,2025-09-09 04:00:00+0000,"arXiv:2509.05553v1 Announce Type: new 
Abstract: This research addresses a fundamental question in AI: whether large language models truly understand concepts or simply recognize patterns. The authors propose bidirectional reasoning,the ability to apply transformations in both directions without being explicitly trained on the reverse direction, as a test for genuine understanding. They argue that true comprehension should naturally allow reversibility. For example, a model that can change a variable name like userIndex to i should also be able to infer that i represents a user index without reverse training. The researchers tested current language models and discovered what they term cognitive specialization: when models are fine-tuned on forward tasks, their performance on those tasks improves, but their ability to reason bidirectionally becomes significantly worse. To address this issue, they developed Contrastive Fine-Tuning (CFT), which trains models using three types of examples: positive examples that maintain semantic meaning, negative examples with different semantics, and forward-direction obfuscation examples. This approach aims to develop deeper understanding rather than surface-level pattern recognition and allows reverse capabilities to develop naturally without explicit reverse training. Their experiments demonstrated that CFT successfully achieved bidirectional reasoning, enabling strong reverse performance while maintaining forward task capabilities. The authors conclude that bidirectional reasoning serves both as a theoretical framework for assessing genuine understanding and as a practical training approach for developing more capable AI systems."
arXiv cs.CL,Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG),https://arxiv.org/abs/2509.05505,2025-09-09 04:00:00+0000,"arXiv:2509.05505v1 Announce Type: new 
Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system based on a Retrieval-Augmented Generation (RAG) architecture, designed to improve access to accurate, evidence-based medical information. Addressing the shortcomings of conventional health search engines and the lag in public access to biomedical research, the system integrates diverse sources, including PubMed articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant information and generate concise, context-aware responses. The retrieval pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model optimized using QLoRA for efficient, low-resource training. The system supports both general medical queries and domain-specific tasks, with a focused evaluation on breast cancer literature demonstrating the value of domain-aligned retrieval. Empirical results, measured using BERTScore (F1), show substantial improvements in factual consistency and semantic relevance compared to baseline models. The findings underscore the potential of RAG-enhanced language models to bridge the gap between complex biomedical literature and accessible public health knowledge, paving the way for future work on multilingual adaptation, privacy-preserving inference, and personalized medical AI systems."
arXiv cs.CL,The Token Tax: Systematic Bias in Multilingual Tokenization,https://arxiv.org/abs/2509.05486,2025-09-09 04:00:00+0000,"arXiv:2509.05486v1 Announce Type: new 
Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically complex, low-resource languages, inflating compute resources and depressing accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA items; 5 subjects; 16 African languages) and show that fertility (tokens/word) reliably predicts accuracy. Higher fertility consistently predicts lower accuracy across all models and subjects. We further find that reasoning models (DeepSeek, o1) consistently outperform non-reasoning peers across high and low resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in prior generations. Finally, translating token inflation to economics, a doubling in tokens results in quadrupled training cost and time, underscoring the token tax faced by many languages. These results motivate morphologically aware tokenization, fair pricing, and multilingual benchmarks for equitable natural language processing (NLP)."
arXiv cs.CL,From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics,https://arxiv.org/abs/2509.05484,2025-09-09 04:00:00+0000,"arXiv:2509.05484v1 Announce Type: new 
Abstract: Hospital call centers serve as the primary contact point for patients within a hospital system. They also generate substantial volumes of staff messages as navigators process patient requests and communicate with the hospital offices following the established protocol restrictions and guidelines. This continuously accumulated large amount of text data can be mined and processed to retrieve insights; however, traditional supervised learning approaches require annotated data, extensive training, and model tuning. Large Language Models (LLMs) offer a paradigm shift toward more computationally efficient methodologies for healthcare analytics. This paper presents a multi-stage LLM-based framework that identifies staff message topics and classifies messages by their reasons in a multi-class fashion. In the process, multiple LLM types, including reasoning, general-purpose, and lightweight models, were evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and 76.2% accuracy). The proposed methodology incorporates data security measures and HIPAA compliance requirements essential for healthcare environments. The processed LLM outputs are integrated into a visualization decision support tool that transforms the staff messages into actionable insights accessible to healthcare professionals. This approach enables more efficient utilization of the collected staff messaging data, identifies navigator training opportunities, and supports improved patient experience and care quality."
arXiv cs.CL,Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too,https://arxiv.org/abs/2509.05440,2025-09-09 04:00:00+0000,"arXiv:2509.05440v1 Announce Type: new 
Abstract: As large-language models have been increasingly used as automatic raters for evaluating free-form content, including document summarization, dialog, and story generation, work has been dedicated to evaluating such models by measuring their correlations with human judgment. For \textit{sample-level} performance, methods which operate by using pairwise comparisons between machine-generated text perform well but often lack the ability to assign absolute scores to individual summaries, an ability crucial for use cases that require thresholding. In this work, we propose a direct-scoring method which uses synthetic summaries to act as pairwise machine rankings at test time. We show that our method performs comparably to state-of-the-art pairwise evaluators in terms of axis-averaged sample-level correlations on the SummEval (\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05}) meta-evaluation benchmarks, and release the synthetic in-context summaries as data to facilitate future work."
arXiv cs.CL,No Translation Needed: Forecasting Quality from Fertility and Metadata,https://arxiv.org/abs/2509.05425,2025-09-09 04:00:00+0000,"arXiv:2509.05425v1 Announce Type: new 
Abstract: We show that translation quality can be predicted with surprising accuracy \textit{without ever running the translation system itself}. Using only a handful of features, token fertility ratios, token counts, and basic linguistic metadata (language family, script, and region), we can forecast ChrF scores for GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient boosting models achieve favorable performance ($R^{2}=0.66$ for XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature importance analyses reveal that typological factors dominate predictions into English, while fertility plays a larger role for translations into diverse target languages. These findings suggest that translation quality is shaped by both token-level fertility and broader linguistic typology, offering new insights for multilingual evaluation and quality estimation."
arXiv cs.CL,Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate,https://arxiv.org/abs/2509.05396,2025-09-09 04:00:00+0000,"arXiv:2509.05396v1 Announce Type: new 
Abstract: While multi-agent debate has been proposed as a promising strategy for improving AI reasoning ability, we find that debate can sometimes be harmful rather than helpful. The prior work has exclusively focused on debates within homogeneous groups of agents, whereas we explore how diversity in model capabilities influences the dynamics and outcomes of multi-agent interactions. Through a series of experiments, we demonstrate that debate can lead to a decrease in accuracy over time -- even in settings where stronger (i.e., more capable) models outnumber their weaker counterparts. Our analysis reveals that models frequently shift from correct to incorrect answers in response to peer reasoning, favoring agreement over challenging flawed reasoning. These results highlight important failure modes in the exchange of reasons during multi-agent debate, suggesting that naive applications of debate may cause performance degradation when agents are neither incentivized nor adequately equipped to resist persuasive but incorrect reasoning."
arXiv cs.CL,Authorship Without Writing: Large Language Models and the Senior Author Analogy,https://arxiv.org/abs/2509.05390,2025-09-09 04:00:00+0000,"arXiv:2509.05390v1 Announce Type: cross 
Abstract: The use of large language models (LLMs) in bioethical, scientific, and medical writing remains controversial. While there is broad agreement in some circles that LLMs cannot count as authors, there is no consensus about whether and how humans using LLMs can count as authors. In many fields, authorship is distributed among large teams of researchers, some of whom, including paradigmatic senior authors who guide and determine the scope of a project and ultimately vouch for its integrity, may not write a single word. In this paper, we argue that LLM use (under specific conditions) is analogous to a form of senior authorship. On this view, the use of LLMs, even to generate complete drafts of research papers, can be considered a legitimate form of authorship according to the accepted criteria in many fields. We conclude that either such use should be recognized as legitimate, or current criteria for authorship require fundamental revision. AI use declaration: GPT-5 was used to help format Box 1. AI was not used for any other part of the preparation or writing of this manuscript."
arXiv cs.CL,A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs,https://arxiv.org/abs/2509.05385,2025-09-09 04:00:00+0000,"arXiv:2509.05385v1 Announce Type: new 
Abstract: Large language models are unable to continuously adapt and learn from new data during reasoning at inference time. To address this limitation, we propose that complex reasoning tasks be decomposed into atomic subtasks and introduce SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive updates during reasoning at inference time. SAGE consists of three key components: (1) a Trigger module that detects reasoning failures through multiple evaluation metrics in real time; (2) a Trigger Buffer module that clusters anomaly samples using a streaming clustering process with HDBSCAN, followed by stability checks and similarity-based merging; and (3) a Lora Store module that dynamically optimizes parameter updates with an adapter pool for knowledge retention. Evaluation results show that SAGE demonstrates excellent accuracy, robustness, and stability on the atomic reasoning subtask through dynamic knowledge updating during test time."
arXiv cs.CL,Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection,https://arxiv.org/abs/2509.05360,2025-09-09 04:00:00+0000,"arXiv:2509.05360v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide variety of tasks involving natural language, however, a fundamental problem of hallucinations still plagues these models, limiting their trustworthiness in generating consistent, truthful information. Detecting hallucinations has quickly become an important topic, with various methods such as uncertainty estimation, LLM Judges, retrieval augmented generation (RAG), and consistency checks showing promise. Many of these methods build upon foundational metrics, such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth necessary to detect hallucinations effectively. In this work, we propose a novel approach inspired by ROUGE that constructs an N-Gram frequency tensor from LLM-generated text. This tensor captures richer semantic structure by encoding co-occurrence patterns, enabling better differentiation between factual and hallucinated content. We demonstrate this by applying tensor decomposition methods to extract singular values from each mode and use these as input features to train a multi-layer perceptron (MLP) binary classifier for hallucinations. Our method is evaluated on the HaluEval dataset and demonstrates significant improvements over traditional baselines, as well as competitive performance against state-of-the-art LLM judges."
arXiv cs.CL,An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training,https://arxiv.org/abs/2509.05359,2025-09-09 04:00:00+0000,"arXiv:2509.05359v1 Announce Type: new 
Abstract: This paper investigates discrete unit representations in Speech Language Models (SLMs), focusing on optimizing speech modeling during continual pre-training. In this paper, we systematically examine how model architecture, data representation, and training robustness influence the pre-training stage in which we adapt existing pre-trained language models to the speech modality. Our experiments highlight the role of speech encoders and clustering granularity across different model scales, showing how optimal discretization strategies vary with model capacity. By examining cluster distribution and phonemic alignments, we investigate the effective use of discrete vocabulary, uncovering both linguistic and paralinguistic patterns. Additionally, we explore the impact of clustering data selection on model robustness, highlighting the importance of domain matching between discretization training and target applications."
arXiv cs.CL,ForensicsData: A Digital Forensics Dataset for Large Language Models,https://arxiv.org/abs/2509.05331,2025-09-09 04:00:00+0000,"arXiv:2509.05331v1 Announce Type: cross 
Abstract: The growing complexity of cyber incidents presents significant challenges for digital forensic investigators, especially in evidence collection and analysis. Public resources are still limited because of ethical, legal, and privacy concerns, even though realistic datasets are necessary to support research and tool developments. To address this gap, we introduce ForensicsData, an extensive Question-Context-Answer (Q-C-A) dataset sourced from actual malware analysis reports. It consists of more than 5,000 Q-C-A triplets. A unique workflow was used to create the dataset, which extracts structured data, uses large language models (LLMs) to transform it into Q-C-A format, and then uses a specialized evaluation process to confirm its quality. Among the models evaluated, Gemini 2 Flash demonstrated the best performance in aligning generated content with forensic terminology. ForensicsData aims to advance digital forensics by enabling reproducible experiments and fostering collaboration within the research community."
arXiv cs.CL,ProtSAE: Disentangling and Interpreting Protein Language Models via Semantically-Guided Sparse Autoencoders,https://arxiv.org/abs/2509.05309,2025-09-09 04:00:00+0000,"arXiv:2509.05309v1 Announce Type: cross 
Abstract: Sparse Autoencoder (SAE) has emerged as a powerful tool for mechanistic interpretability of large language models. Recent works apply SAE to protein language models (PLMs), aiming to extract and analyze biologically meaningful features from their latent spaces. However, SAE suffers from semantic entanglement, where individual neurons often mix multiple nonlinear concepts, making it difficult to reliably interpret or manipulate model behaviors. In this paper, we propose a semantically-guided SAE, called ProtSAE. Unlike existing SAE which requires annotation datasets to filter and interpret activations, we guide semantic disentanglement during training using both annotation datasets and domain knowledge to mitigate the effects of entangled attributes. We design interpretability experiments showing that ProtSAE learns more biologically relevant and interpretable hidden features compared to previous methods. Performance analyses further demonstrate that ProtSAE maintains high reconstruction fidelity while achieving better results in interpretable probing. We also show the potential of ProtSAE in steering PLMs for downstream generation tasks."
arXiv cs.CL,HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models,https://arxiv.org/abs/2509.05218,2025-09-09 04:00:00+0000,"arXiv:2509.05218v2 Announce Type: replace 
Abstract: Positional encoding mechanisms enable Transformers to model sequential structure and long-range dependencies in text. While absolute positional encodings struggle with extrapolation to longer sequences due to fixed positional representations, and relative approaches like Alibi exhibit performance degradation on extremely long contexts, the widely-used Rotary Positional Encoding (RoPE) introduces oscillatory attention patterns that hinder stable long-distance dependency modelling. We address these limitations through a geometric reformulation of positional encoding. Drawing inspiration from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to implement Lorentz rotations on token representations. Theoretical analysis demonstrates that RoPE is a special case of our generalized formulation. HoPE fundamentally resolves RoPE's slation issues by enforcing monotonic decay of attention weights with increasing token distances. Extensive experimental results, including perplexity evaluations under several extended sequence benchmarks, show that HoPE consistently exceeds existing positional encoding methods. These findings underscore HoPE's enhanced capacity for representing and generalizing long-range dependencies. Data and code will be available."
arXiv cs.CL,Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework,https://arxiv.org/abs/2509.05007,2025-09-09 04:00:00+0000,"arXiv:2509.05007v2 Announce Type: replace-cross 
Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex reasoning tasks, with further gains achievable through increased computational budgets at inference. However, current test-time scaling methods predominantly rely on redundant sampling, ignoring the historical experience utilization, thereby limiting computational efficiency. To overcome this limitation, we propose Sticker-TTS, a novel test-time scaling framework that coordinates three collaborative LRMs to iteratively explore and refine solutions guided by historical attempts. At the core of our framework are distilled key conditions-termed stickers-which drive the extraction, refinement, and reuse of critical information across multiple rounds of reasoning. To further enhance the efficiency and performance of our framework, we introduce a two-stage optimization strategy that combines imitation learning with self-improvement, enabling progressive refinement. Extensive evaluations on three challenging mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH, demonstrate that Sticker-TTS consistently surpasses strong baselines, including self-consistency and advanced reinforcement learning approaches, under comparable inference budgets. These results highlight the effectiveness of sticker-guided historical experience utilization. Our code and data are available at https://github.com/RUCAIBox/Sticker-TTS."
arXiv cs.CL,Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety,https://arxiv.org/abs/2509.04650,2025-09-09 04:00:00+0000,"arXiv:2509.04650v2 Announce Type: replace 
Abstract: Twitter and other social media platforms have become vital sources of real time information during disasters and public safety emergencies. Automatically classifying disaster related tweets can help emergency services respond faster and more effectively. Traditional Machine Learning (ML) models such as Logistic Regression, Naive Bayes, and Support Vector Machines have been widely used for this task, but they often fail to understand the context or deeper meaning of words, especially when the language is informal, metaphorical, or ambiguous. We posit that, in this context, transformer based models can perform better than traditional ML models. In this paper, we evaluate the effectiveness of transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for classifying disaster related tweets. These models are compared with traditional ML approaches to highlight the performance gap. Experimental results show that BERT achieved the highest accuracy (91%), significantly outperforming traditional models like Logistic Regression and Naive Bayes (both at 82%). The use of contextual embeddings and attention mechanisms allows transformer models to better understand subtle language in tweets, where traditional ML models fall short. This research demonstrates that transformer architectures are far more suitable for public safety applications, offering improved accuracy, deeper language understanding, and better generalization across real world social media text."
arXiv cs.CL,"The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors",https://arxiv.org/abs/2509.04484,2025-09-09 04:00:00+0000,"arXiv:2509.04484v2 Announce Type: replace 
Abstract: Providing constructive feedback to paper authors is a core component of peer review. With reviewers increasingly having less time to perform reviews, automated support systems are required to ensure high reviewing quality, thus making the feedback in reviews useful for authors. To this end, we identify four key aspects of review comments (individual points in weakness sections of reviews) that drive the utility for authors: Actionability, Grounding & Specificity, Verifiability, and Helpfulness. To enable evaluation and development of models assessing review comments, we introduce the RevUtil dataset. We collect 1,430 human-labeled review comments and scale our data with 10k synthetically labeled comments for training purposes. The synthetic data additionally contains rationales, i.e., explanations for the aspect score of a review comment. Employing the RevUtil dataset, we benchmark fine-tuned models for assessing review comments on these aspects and generating rationales. Our experiments demonstrate that these fine-tuned models achieve agreement levels with humans comparable to, and in some cases exceeding, those of powerful closed models like GPT-4o. Our analysis further reveals that machine-generated reviews generally underperform human reviews on our four aspects."
arXiv cs.CL,Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare,https://arxiv.org/abs/2509.04482,2025-09-09 04:00:00+0000,"arXiv:2509.04482v2 Announce Type: replace 
Abstract: Reliable abstention is critical for retrieval-augmented generation (RAG) systems, particularly in safety-critical domains such as women's health, where incorrect answers can lead to harm. We present an energy-based model (EBM) that learns a smooth energy landscape over a dense semantic corpus of 2.6M guideline-derived questions, enabling the system to decide when to generate or abstain. We benchmark the EBM against a calibrated softmax baseline and a k-nearest neighbour (kNN) density heuristic across both easy and hard abstention splits, where hard cases are semantically challenging near-distribution queries. The EBM achieves superior abstention performance abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives, performance is comparable across methods, but the EBM's advantage becomes most pronounced in safety-critical hard distributions. A comprehensive ablation with controlled negative sampling and fair data exposure shows that robustness stems primarily from the energy scoring head, while the inclusion or exclusion of specific negative types (hard, easy, mixed) sharpens decision boundaries but is not essential for generalisation to hard cases. These results demonstrate that energy-based abstention scoring offers a more reliable confidence signal than probability-based softmax confidence, providing a scalable and interpretable foundation for safe RAG systems."
arXiv cs.CL,ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory,https://arxiv.org/abs/2509.04439,2025-09-09 04:00:00+0000,"arXiv:2509.04439v2 Announce Type: replace-cross 
Abstract: While inference-time scaling enables LLMs to carry out increasingly long and capable reasoning traces, the patterns and insights uncovered during these traces are immediately discarded once the context window is reset for a new query. External memory is a natural way to persist these discoveries, and recent work has shown clear benefits for reasoning-intensive tasks. We see an opportunity to make such memories more broadly reusable and scalable by moving beyond instance-based memory entries (e.g. exact query/response pairs, or summaries tightly coupled with the original problem context) toward concept-level memory: reusable, modular abstractions distilled from solution traces and stored in natural language. For future queries, relevant concepts are selectively retrieved and integrated into the prompt, enabling test-time continual learning without weight updates. Our design introduces new strategies for abstracting takeaways from rollouts and retrieving entries for new queries, promoting reuse and allowing memory to expand with additional experiences. We evaluate on ARC-AGI, a benchmark that stresses compositional generalization and abstract reasoning, making it a natural fit for concept memory. Our method yields a 7.5% relative gain over a strong no-memory baseline with performance continuing to scale with inference compute. We find abstract concepts to be the most consistent memory design, outscoring the baseline at all tested inference compute scales. Moreover, dynamically updating memory during test-time outperforms fixed settings, supporting the hypothesis that accumulating and abstracting patterns enables further solutions in a form of self-improvement. Code is available at https://github.com/matt-seb-ho/arc_memo."
arXiv cs.CL,Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation,https://arxiv.org/abs/2509.03736,2025-09-09 04:00:00+0000,"arXiv:2509.03736v1 Announce Type: cross 
Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the notion that synthetic agents can serve as substitutes for real participants in human-subject research. In an effort to evaluate the merits of this claim, social science researchers have largely focused on whether LLM-generated survey data corresponds to that of a human counterpart whom the LLM is prompted to represent. In contrast, we address a more fundamental question: Do agents maintain internal consistency, retaining similar behaviors when examined under different experimental settings? To this end, we develop a study designed to (a) reveal the agent's internal state and (b) examine agent behavior in a basic dialogue setting. This design enables us to explore a set of behavioral hypotheses to assess whether an agent's conversation behavior is consistent with what we would expect from their revealed internal state. Our findings on these hypotheses show significant internal inconsistencies in LLMs across model families and at differing model sizes. Most importantly, we find that, although agents may generate responses matching those of their human counterparts, they fail to be internally consistent, representing a critical gap in their capabilities to accurately substitute for real participants in human-subject research. Our simulation code and data are publicly accessible."
arXiv cs.CL,Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning,https://arxiv.org/abs/2509.03646,2025-09-09 04:00:00+0000,"arXiv:2509.03646v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the complex reasoning abilities of Large Language Models (LLMs), yet underlying mechanisms driving this success remain largely opaque. Our analysis reveals that puzzling phenomena like ``aha moments"", ``length-scaling'' and entropy dynamics are not disparate occurrences but hallmarks of an emergent reasoning hierarchy, akin to the separation of high-level strategic planning from low-level procedural execution in human cognition. We uncover a compelling two-phase dynamic: initially, a model is constrained by procedural correctness and must improve its low-level skills. The learning bottleneck then decisively shifts, with performance gains being driven by the exploration and mastery of high-level strategic planning. This insight exposes a core inefficiency in prevailing RL algorithms like GRPO, which apply optimization pressure agnostically and dilute the learning signal across all tokens. To address this, we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that concentrates optimization efforts on high-impact planning tokens. HICRA significantly outperforms strong baselines, demonstrating that focusing on this strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we validate semantic entropy as a superior compass for measuring strategic exploration over misleading metrics such as token-level entropy."
arXiv cs.CL,MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds,https://arxiv.org/abs/2509.02499,2025-09-09 04:00:00+0000,"arXiv:2509.02499v3 Announce Type: replace 
Abstract: The rapid advancement of large language models has intensified public concerns about the potential misuse. Therefore, it is important to build trustworthy AI-generated text detection systems. Existing methods neglect stylistic modeling and mostly rely on static thresholds, which greatly limits the detection performance. In this paper, we propose the Mixture of Stylistic Experts (MoSEs) framework that enables stylistics-aware uncertainty quantification through conditional threshold estimation. MoSEs contain three core components, namely, the Stylistics Reference Repository (SRR), the Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE). For input text, SRR can activate the appropriate reference data in SRR and provide them to CTE. Subsequently, CTE jointly models the linguistic statistical properties and semantic features to dynamically determine the optimal threshold. With a discrimination score, MoSEs yields prediction labels with the corresponding confidence level. Our framework achieves an average improvement 11.34% in detection performance compared to baselines. More inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource case. Our code is available at https://github.com/creator-xi/MoSEs."
arXiv cs.CL,DCPO: Dynamic Clipping Policy Optimization,https://arxiv.org/abs/2509.02333,2025-09-09 04:00:00+0000,"arXiv:2509.02333v2 Announce Type: replace 
Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a promising framework for enhancing the reasoning capabilities of large language models. However, existing approaches such as GRPO often suffer from zero gradients. This problem arises primarily due to fixed clipping bounds for token-level probability ratios and the standardization of identical rewards, which can lead to ineffective gradient updates and underutilization of generated responses. In this work, we propose Dynamic Clipping Policy Optimization(DCPO), which introduces a dynamic clipping strategy that adaptively adjusts clipping bounds based on token-specific prior probabilities to enhance token-level exploration, and a smooth advantage standardization technique that standardizes rewards across cumulative training steps to improve the response-level effective utilization of generated responses. DCPO achieved state-of-the-art performance on four benchmarks based on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24 benchmark, surpassing DAPO (36.7/31.6), GRPO (36.7/32.1) and GSPO (40.0/34.9) on the Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5), DAPO (20.0/15.3) and GSPO (16.7/9.9). Furthermore, DCPO achieved an average 28% improvement in the nonzero advantage over GRPO in four models, doubled the training efficiency over DAPO, and significantly reduced the token clipping ratio by an order of magnitude compared to both GRPO and DAPO, while achieving superior performance. These results highlight DCPO's effectiveness in leveraging generated data more efficiently for reinforcement learning in large language models."
arXiv cs.CL,E-THER: A Multimodal Dataset for Empathic AI - Towards Emotional Mismatch Awareness,https://arxiv.org/abs/2509.02100,2025-09-09 04:00:00+0000,"arXiv:2509.02100v2 Announce Type: replace-cross 
Abstract: A prevalent shortfall among current empathic AI systems is their inability to recognize when verbal expressions may not fully reflect underlying emotional states. This is because the existing datasets, used for the training of these systems, focus on surface-level emotion recognition without addressing the complex verbal-visual incongruence (mismatch) patterns useful for empathic understanding. In this paper, we present E-THER, the first Person-Centered Therapy-grounded multimodal dataset with multidimensional annotations for verbal-visual incongruence detection, enabling training of AI systems that develop genuine rather than performative empathic capabilities. The annotations included in the dataset are drawn from humanistic approach, i.e., identifying verbal-visual emotional misalignment in client-counsellor interactions - forming a framework for training and evaluating AI on empathy tasks. Additional engagement scores provide behavioral annotations for research applications. Notable gains in empathic and therapeutic conversational qualities are observed in state-of-the-art vision-language models (VLMs), such as IDEFICS and VideoLLAVA, using evaluation metrics grounded in empathic and therapeutic principles. Empirical findings indicate that our incongruence-trained models outperform general-purpose models in critical traits, such as sustaining therapeutic engagement, minimizing artificial or exaggerated linguistic patterns, and maintaining fidelity to PCT theoretical framework."
arXiv cs.CL,Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models,https://arxiv.org/abs/2509.01909,2025-09-09 04:00:00+0000,"arXiv:2509.01909v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the model's response can strongly influence the user's next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI."
arXiv cs.CL,Efficient Large Language Models with Zero-Shot Adjustable Acceleration,https://arxiv.org/abs/2509.01190,2025-09-09 04:00:00+0000,"arXiv:2509.01190v2 Announce Type: replace 
Abstract: Using Large Language Models (LLMs) in real-world applications presents significant challenges, particularly in balancing computational efficiency with model performance. Optimizing acceleration after fine-tuning and during inference is critical for building efficient architectures. This paper introduces Zero-Shot Adjustable Acceleration, a novel training and inference method that dynamically adjusts hardware utilization during inference without requiring additional fine-tuning. The proposed approach is applied to recent LLMs and evaluated across multiple classification and text generation tasks. Experimental results demonstrate that the method supports a wide range of zero-shot acceleration and achieves up to 11x speedup compared to the baseline."
arXiv cs.CL,Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA,https://arxiv.org/abs/2509.01158,2025-09-09 04:00:00+0000,"arXiv:2509.01158v2 Announce Type: replace 
Abstract: Chinese information extraction (IE) involves multiple tasks across diverse temporal domains, including Classical and Modern documents. Fine-tuning a single model on heterogeneous tasks and across different eras may lead to interference and reduced performance. Therefore, in this paper, we propose Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in different IE tasks and eras, while a task-era-aware router mechanism dynamically allocates expert contributions. Experiments show that Tea-MOELoRA outperforms both single-task and joint LoRA baselines, demonstrating its ability to leverage task and temporal knowledge effectively."
arXiv cs.CL,Probe-Rewrite-Evaluate: A Workflow for Reliable Benchmarks and Quantifying Evaluation Awareness,https://arxiv.org/abs/2509.00591,2025-09-09 04:00:00+0000,"arXiv:2509.00591v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when they perceive a change from a real-world deployment context to a controlled evaluation setting, a phenomenon known as ""evaluation awareness."" This discrepancy poses a critical challenge for AI alignment, as benchmark performance may not accurately reflect a model's true safety and honesty. In this work, we systematically quantify these behavioral changes by manipulating the perceived context of prompts. We introduce a methodology that uses a linear probe to score prompts on a continuous scale from ""test-like"" to ""deploy-like"" and leverage an LLM rewriting strategy to shift these prompts towards a more natural, deployment-style context while preserving the original task. Using this method, we achieved a 30% increase in the average probe score across a strategic role-playing dataset after rewriting. Evaluating a suite of state-of-the-art models on these original and rewritten prompts, we find that rewritten ""deploy-like"" prompts induce a significant and consistent shift in behavior. Across all models, we observed an average increase in honest responses of 5.26% and a corresponding average decrease in deceptive responses of 12.40%. Furthermore, refusal rates increased by an average of 6.38%, indicating heightened safety compliance. Our findings demonstrate that evaluation awareness is a quantifiable and manipulable factor that directly influences LLM behavior, revealing that models are more prone to unsafe or deceptive outputs in perceived test environments. This underscores the urgent need for more realistic evaluation frameworks to accurately gauge true model alignment before deployment."
arXiv cs.CL,CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning,https://arxiv.org/abs/2509.00457,2025-09-09 04:00:00+0000,"arXiv:2509.00457v2 Announce Type: replace 
Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of heirs and calculation of shares, which poses a challenge for AI. In this paper, we present a lightweight framework for solving multiple-choice inheritance questions using a specialised Arabic text encoder and Attentive Relevance Scoring (ARS). The system ranks answer options according to semantic relevance, and enables fast, on-device inference without generative reasoning. We evaluate Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an accuracy of up to 87.6%, they require more resources and are context-dependent. Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling case for efficiency, on-device deployability, and privacy. While this is lower than the 87.6% achieved by the best-performing LLM, our work quantifies a critical trade-off between the peak performance of large models and the practical advantages of smaller, specialized systems in high-stakes domains."
arXiv cs.CL,KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval,https://arxiv.org/abs/2508.20417,2025-09-09 04:00:00+0000,"arXiv:2508.20417v3 Announce Type: replace 
Abstract: The integration of knowledge graphs (KGs) with large language models (LLMs) offers significant potential to improve the retrieval phase of retrieval-augmented generation (RAG) systems. In this study, we propose KG-CQR, a novel framework for Contextual Query Retrieval (CQR) that enhances the retrieval phase by enriching the contextual representation of complex input queries using a corpus-centric KG. Unlike existing methods that primarily address corpus-level context loss, KG-CQR focuses on query enrichment through structured relation representations, extracting and completing relevant KG subgraphs to generate semantically rich query contexts. Comprising subgraph extraction, completion, and contextual generation modules, KG-CQR operates as a model-agnostic pipeline, ensuring scalability across LLMs of varying sizes without additional training. Experimental results on RAGBench and MultiHop-RAG datasets demonstrate KG-CQR's superior performance, achieving a 4-6% improvement in mAP and a 2-3% improvement in Recall@25 over strong baseline models. Furthermore, evaluations on challenging RAG tasks such as multi-hop question answering show that, by incorporating KG-CQR, the performance consistently outperforms the existing baseline in terms of retrieval effectiveness"
arXiv cs.CL,MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts,https://arxiv.org/abs/2508.19268,2025-09-09 04:00:00+0000,"arXiv:2508.19268v2 Announce Type: replace 
Abstract: Despite LLMs' excellent code creation capabilities, multilingual code generation remains extremely challenging. To address this, we intent to improve the multi-programming-lingual (MultiPL) performance of the base LLMs while retaining the most popular ones using restricted computational resources. We consider MultiPL to be a special case of multiple natural languages and propose a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize expert selection at both the token and segment levels. The token-level MoE is a standard upcycling MoE structure with a shared expert and a novel gate weight normalization approach that aids in the final fusion with the segment-level MoE. The segment-level MoE incorporates two innovative designs to better capture the syntactic structure and contextual patterns of programming languages: First, using a sliding window to partition the input token sequence into multiple segments; Then, adopting an expert-choice routing strategy that allows experts to select the top-k segments. The results of the experiment proved the effectiveness of MultiPL-MoE."
arXiv cs.CL,MovieCORE: COgnitive REasoning in Movies,https://arxiv.org/abs/2508.19026,2025-09-09 04:00:00+0000,"arXiv:2508.19026v2 Announce Type: replace 
Abstract: This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at https://joslefaure.github.io/assets/html/moviecore.html."
arXiv cs.CL,Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark,https://arxiv.org/abs/2508.19005,2025-09-09 04:00:00+0000,"arXiv:2508.19005v3 Announce Type: replace-cross 
Abstract: As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as ""second nature"".
  We also introduce StuLife, a benchmark dataset for ELL that simulates a student's holistic college journey, from enrollment to academic and personal development, across three core phases and ten detailed sub-scenarios. StuLife is designed around three key paradigm"
arXiv cs.CL,Automatic Prompt Optimization with Prompt Distillation,https://arxiv.org/abs/2508.18992,2025-09-09 04:00:00+0000,"arXiv:2508.18992v2 Announce Type: replace 
Abstract: Autoprompting is the process of automatically selecting optimized prompts for language models, which is gaining popularity due to the rapid development of prompt engineering driven by extensive research in the field of large language models (LLMs). This paper presents DistillPrompt -- a novel autoprompting method based on large language models that employs a multi-stage integration of task-specific information into prompts using training data. DistillPrompt utilizes distillation, compression, and aggregation operations to explore the prompt space more thoroughly. The method was tested on different datasets for text classification and generation tasks using the t-lite-instruct-0.1 language model. The results demonstrate a significant average improvement (e.g., 20.12% across the entire dataset compared to Grips) in key metrics over existing methods in the field, establishing DistillPrompt as one of the most effective non-gradient approaches in autoprompting."
arXiv cs.CL,Membership Inference Attacks on LLM-based Recommender Systems,https://arxiv.org/abs/2508.18665,2025-09-09 04:00:00+0000,"arXiv:2508.18665v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) based Recommender Systems (RecSys) can flexibly adapt recommendation systems to different domains. It utilizes in-context learning (ICL), i.e., the prompts, to customize the recommendation functions, which include sensitive historical user-specific item interactions, e.g., implicit feedback like clicked items or explicit product reviews. Such private information may be exposed to novel privacy attack. However, no study has been done on this important issue. We design four membership inference attacks (MIAs), aiming to reveal whether victims' historical interactions have been used by system prompts. They are \emph{direct inquiry, hallucination, similarity, and poisoning attacks}, each of which utilizes the unique features of LLMs or RecSys. We have carefully evaluated them on three LLMs that have been used to develop ICL-LLM RecSys and two well-known RecSys benchmark datasets. The results confirm that the MIA threat on LLM RecSys is realistic: direct inquiry and poisoning attacks showing significantly high attack advantages. We have also analyzed the factors affecting these attacks, such as the number of shots in system prompts and the position of the victim in the shots."
arXiv cs.CL,Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models,https://arxiv.org/abs/2508.18655,2025-09-09 04:00:00+0000,"arXiv:2508.18655v2 Announce Type: replace 
Abstract: With the development of speech large language models (speech LLMs), users can now interact directly with assistants via speech. However, most existing models only convert response content into speech without fully capturing the rich emotional cues in user queries, where the same sentence may convey different meanings depending on the expression. Emotional understanding is thus essential for improving human-machine interaction. Most empathetic speech LLMs rely on massive datasets, demanding high computational cost. A key challenge is to build models that generate empathetic responses with limited data and without large-scale training. To this end, we propose Emotion Omni, a model that understands emotional content in user speech and generates empathetic responses. We further developed a data pipeline to construct a 200k emotional dialogue dataset supporting empathetic speech assistants. Experiments show that Emotion Omni achieves comparable instruction-following ability without large-scale pretraining, while surpassing existing models in speech quality (UTMOS:4.41) and empathy (Emotion GPT Score: 3.97). These results confirm its improvements in both speech fidelity and emotional expressiveness. Demos are available at https://w311411.github.io/omni_demo/."
arXiv cs.CL,Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios,https://arxiv.org/abs/2508.18183,2025-09-09 04:00:00+0000,"arXiv:2508.18183v2 Announce Type: replace 
Abstract: Translating natural languages into sign languages is a highly complex and underexplored task. Despite growing interest in accessibility and inclusivity, the development of robust translation systems remains hindered by the limited availability of parallel corpora which align natural language with sign language data. Existing methods often struggle to generalize in these data-scarce environments, as the few datasets available are typically domain-specific, lack standardization, or fail to capture the full linguistic richness of sign languages. To address this limitation, we propose Advanced Use of LLMs for Sign Language Translation (AulSign), a novel method that leverages Large Language Models via dynamic prompting and in-context learning with sample selection and subsequent sign association. Despite their impressive abilities in processing text, LLMs lack intrinsic knowledge of sign languages; therefore, they are unable to natively perform this kind of translation. To overcome this limitation, we associate the signs with compact descriptions in natural language and instruct the model to use them. We evaluate our method on both English and Italian languages using SignBank+, a recognized benchmark in the field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior performance compared to state-of-the-art models in low-data scenario. Our findings demonstrate the effectiveness of AulSign, with the potential to enhance accessibility and inclusivity in communication technologies for underrepresented linguistic communities."
arXiv cs.CL,Jet-Nemotron: Efficient Language Model with Post Neural Architecture Search,https://arxiv.org/abs/2508.15884,2025-09-09 04:00:00+0000,"arXiv:2508.15884v2 Announce Type: replace 
Abstract: We present Jet-Nemotron, a new family of hybrid-architecture language models, which matches or exceeds the accuracy of leading full-attention models while significantly improving generation throughput. Jet-Nemotron is developed using Post Neural Architecture Search (PostNAS), a novel neural architecture exploration pipeline that enables efficient model design. Unlike prior approaches, PostNAS begins with a pre-trained full-attention model and freezes its MLP weights, allowing efficient exploration of attention block designs. The pipeline includes four key components: (1) learning optimal full-attention layer placement and elimination, (2) linear attention block selection, (3) designing new attention blocks, and (4) performing hardware-aware hyperparameter search. Our Jet-Nemotron-2B model achieves comparable or superior accuracy to Qwen3, Qwen2.5, Gemma3, and Llama3.2 across a comprehensive suite of benchmarks while delivering up to 53.6x generation throughput speedup and 6.1x prefilling speedup. It also achieves higher accuracy on MMLU and MMLU-Pro than recent advanced MoE full-attention models, such as DeepSeek-V3-Small and Moonlight, despite their larger scale with 15B total and 2.2B activated parameters."
arXiv cs.CL,CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning,https://arxiv.org/abs/2508.15868,2025-09-09 04:00:00+0000,"arXiv:2508.15868v2 Announce Type: replace 
Abstract: Reasoning capability plays a significantly critical role in the the broad applications of Large Language Models (LLMs). To enhance the reasoning performance of LLMs, diverse Reinforcement Learning (RL)-based fine-tuning approaches have been proposed to address the limited generalization capability of LLMs trained solely via Supervised Fine-Tuning (SFT). Despite their effectiveness, two major limitations hinder the advancement of LLMs. First, vanilla RL-based approaches ignore annotated Chain-of-Thought (CoT) and incorporate unstable reasoning path sampling, which typically results in model collapse, unstable training process, and suboptimal performance. Second, existing SFT approaches generally overemphasize the annotated CoT, potentially leading to performance degradation due to insufficient exploitation of potential CoT. In this paper, we propose a Contrastive learning with annotated CoT-based Reinforced Fine-Tuning approach, i.e., \TheName{}, to enhance the reasoning performance of LLMs while addressing the aforementioned limitations. Specifically, we propose learning a representation for each CoT. Based on this representation, we design novel contrastive signals to guide the fine-tuning process. Our approach not only fully exploits the available annotated CoT but also stabilizes the fine-tuning procedure by incorporating an additional unsupervised learning signal. We conduct comprehensive experiments and in-depth analysis with three baseline approaches, two foundation models, and two datasets to demonstrate significant advantages of \TheName{} in terms of robustness, performance (up to 10.15\%), and efficiency (up to 30.62\%). Code is available at https://github.com/WNQzhu/CARFT."
arXiv cs.CL,EMNLP: Educator-role Moral and Normative Large Language Models Profiling,https://arxiv.org/abs/2508.15250,2025-09-09 04:00:00+0000,"arXiv:2508.15250v2 Announce Type: replace 
Abstract: Simulating Professions (SP) enables Large Language Models (LLMs) to emulate professional roles. However, comprehensive psychological and ethical evaluation in these contexts remains lacking. This paper introduces EMNLP, an Educator-role Moral and Normative LLMs Profiling framework for personality profiling, moral development stage measurement, and ethical risk under soft prompt injection. EMNLP extends existing scales and constructs 88 teacher-specific moral dilemmas, enabling profession-oriented comparison with human teachers. A targeted soft prompt injection set evaluates compliance and vulnerability in teacher SP. Experiments on 14 LLMs show teacher-role LLMs exhibit more idealized and polarized personalities than human teachers, excel in abstract moral reasoning, but struggle with emotionally complex situations. Models with stronger reasoning are more vulnerable to harmful prompt injection, revealing a paradox between capability and safety. The model temperature and other hyperparameters have limited influence except in some risk behaviors. This paper presents the first benchmark to assess ethical and psychological alignment of teacher-role LLMs for educational AI. Resources are available at https://e-m-n-l-p.github.io/."
arXiv cs.CL,FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering,https://arxiv.org/abs/2508.14052,2025-09-09 04:00:00+0000,"arXiv:2508.14052v3 Announce Type: replace-cross 
Abstract: Accurate information retrieval (IR) is critical in the financial domain, where investors must identify relevant information from large collections of documents. Traditional IR methods-whether sparse or dense-often fall short in retrieval accuracy, as it requires not only capturing semantic similarity but also performing fine-grained reasoning over document structure and domain-specific knowledge. Recent advances in large language models (LLMs) have opened up new opportunities for retrieval with multi-step reasoning, where the model ranks passages through iterative reasoning about which information is most relevant to a given query. However, there exists no benchmark to evaluate such capabilities in the financial domain. To address this gap, we introduce FinAgentBench, the first large-scale benchmark for evaluating retrieval with multi-step reasoning in finance -- a setting we term agentic retrieval. The benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms and assesses whether LLM agents can (1) identify the most relevant document type among candidates, and (2) pinpoint the key passage within the selected document. Our evaluation framework explicitly separates these two reasoning steps to address context limitations. This design enables to provide a quantitative basis for understanding retrieval-centric LLM behavior in finance. We evaluate a suite of state-of-the-art models and further demonstrated how targeted fine-tuning can significantly improve agentic retrieval performance. Our benchmark provides a foundation for studying retrieval-centric LLM behavior in complex, domain-specific tasks for finance."
arXiv cs.CL,An LLM + ASP Workflow for Joint Entity-Relation Extraction,https://arxiv.org/abs/2508.12611,2025-09-09 04:00:00+0000,"arXiv:2508.12611v2 Announce Type: replace-cross 
Abstract: Joint entity-relation extraction (JERE) identifies both entities and their relationships simultaneously. Traditional machine-learning based approaches to performing this task require a large corpus of annotated data and lack the ability to easily incorporate domain specific information in the construction of the model. Therefore, creating a model for JERE is often labor intensive, time consuming, and elaboration intolerant. In this paper, we propose harnessing the capabilities of generative pretrained large language models (LLMs) and the knowledge representation and reasoning capabilities of Answer Set Programming (ASP) to perform JERE. We present a generic workflow for JERE using LLMs and ASP. The workflow is generic in the sense that it can be applied for JERE in any domain. It takes advantage of LLM's capability in natural language understanding in that it works directly with unannotated text. It exploits the elaboration tolerant feature of ASP in that no modification of its core program is required when additional domain specific knowledge, in the form of type specifications, is found and needs to be used. We demonstrate the usefulness of the proposed workflow through experiments with limited training data on three well-known benchmarks for JERE. The results of our experiments show that the LLM + ASP workflow is better than state-of-the-art JERE systems in several categories with only 10\% of training data. It is able to achieve a 2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the SciERC corpus, one of the most difficult benchmarks."
arXiv cs.CL,A Survey on Training-free Alignment of Large Language Models,https://arxiv.org/abs/2508.09016,2025-09-09 04:00:00+0000,"arXiv:2508.09016v3 Announce Type: replace 
Abstract: The alignment of large language models (LLMs) aims to ensure their outputs adhere to human values, ethical standards, and legal norms. Traditional alignment methods often rely on resource-intensive fine-tuning (FT), which may suffer from knowledge degradation and face challenges in scenarios where the model accessibility or computational resources are constrained. In contrast, training-free (TF) alignment techniques--leveraging in-context learning, decoding-time adjustments, and post-generation corrections--offer a promising alternative by enabling alignment without heavily retraining LLMs, making them adaptable to both open-source and closed-source environments. This paper presents the first systematic review of TF alignment methods, categorizing them by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we provide a detailed examination from the viewpoint of LLMs and multimodal LLMs (MLLMs), highlighting their mechanisms and limitations. Furthermore, we identify key challenges and future directions, paving the way for more inclusive and effective TF alignment techniques. By synthesizing and organizing the rapidly growing body of research, this survey offers a guidance for practitioners and advances the development of safer and more reliable LLMs."
arXiv cs.CL,"Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults",https://arxiv.org/abs/2508.08684,2025-09-09 04:00:00+0000,"arXiv:2508.08684v2 Announce Type: replace 
Abstract: Voice-controlled interfaces can support older adults in clinical contexts, with chatbots being a prime example, but reliable Automatic Speech Recognition (ASR) for underrepresented groups remains a bottleneck. This study evaluates state-of-the-art ASR models on language use of older Dutch adults, who interacted with the \texttt{Welzijn.AI} chatbot designed for geriatric contexts. We benchmark generic multilingual ASR models, and models fine-tuned for Dutch spoken by older adults, while also considering processing speed. Our results show that generic multilingual models outperform fine-tuned models, which suggests recent ASR models can generalise well out of the box to realistic datasets. Furthermore, our results suggest that truncating existing architectures is helpful in balancing the accuracy-speed trade-off, though we also identify some cases with high WER due to hallucinations."
arXiv cs.CL,Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA,https://arxiv.org/abs/2508.00719,2025-09-09 04:00:00+0000,"arXiv:2508.00719v3 Announce Type: replace 
Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language queries and perform structured reasoning over knowledge graphs by leveraging their relational and semantic structures to retrieve accurate answers. Recent KGQA methods primarily follow either retrieve-then-reason paradigm, relying on GNNs or heuristic rules for static paths extraction, or dynamic path generation strategies that use large language models (LLMs) with prompting to jointly perform retrieval and reasoning. However, the former suffers from limited adaptability due to static path extraction and lack of contextual refinement, while the latter incurs high computational costs and struggles with accurate path evaluation due to reliance on fixed scoring functions and extensive LLM calls. To address these issues, this paper proposes Dynamically Adaptive MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search with adaptive path evaluation for efficient and context-aware KGQA. DAMR employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based planner, which selects top-$k$ relevant relations at each step to reduce search space. To improve path evaluation accuracy, we introduce a lightweight Transformer-based scorer that performs context-aware plausibility estimation by jointly encoding the question and relation sequence through cross-attention, enabling the model to capture fine-grained semantic shifts during multi-hop reasoning. Furthermore, to alleviate the scarcity of high-quality supervision, DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically generates training signals from partial paths explored during search, allowing the scorer to continuously adapt to the evolving distribution of reasoning trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR significantly outperforms state-of-the-art methods."
arXiv cs.CL,CodeMixBench: Evaluating Code-Mixing Capabilities of LLMs Across 18 Languages,https://arxiv.org/abs/2507.18791,2025-09-09 04:00:00+0000,"arXiv:2507.18791v2 Announce Type: replace 
Abstract: Code-mixing, the practice of switching between languages within a conversation, poses unique challenges for traditional NLP. Existing benchmarks are limited by their narrow language pairs and tasks, failing to adequately assess large language models' (LLMs) code-mixing abilities. Despite the recognized importance of code-mixing for multilingual users, research on LLMs in this context remains sparse. Additionally, current techniques for synthesizing code-mixed data are underdeveloped to generate code-mixing. In response, we introduce CodeMixBench, a comprehensive benchmark covering eight tasks, including three specific to LLMs and five traditional NLP tasks, and 18 languages across seven language families. We also propose a new method for generating large-scale synthetic code-mixed texts by combining word substitution with GPT-4 prompting. Our evaluation reveals consistent underperformance of LLMs on code-mixed datasets involving different language families. Enhancements in training data size, model scale, and few-shot learning could improve their performance. The code and dataset are available at https://github.com/Jeromeyluck/CodeMixBench."
arXiv cs.CL,Not All Features Deserve Attention: Graph-Guided Dependency Learning for Tabular Data Generation with Language Models,https://arxiv.org/abs/2507.18504,2025-09-09 04:00:00+0000,"arXiv:2507.18504v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown strong potential for tabular data generation by modeling textualized feature-value pairs. However, tabular data inherently exhibits sparse feature-level dependencies, where many feature interactions are structurally insignificant. This creates a fundamental mismatch as LLMs' self-attention mechanism inevitably distributes focus across all pairs, diluting attention on critical relationships, particularly in datasets with complex dependencies or semantically ambiguous features. To address this limitation, we propose GraDe (Graph-Guided Dependency Learning), a novel method that explicitly integrates sparse dependency graphs into LLMs' attention mechanism. GraDe employs a lightweight dynamic graph learning module guided by externally extracted functional dependencies, prioritizing key feature interactions while suppressing irrelevant ones. Our experiments across diverse real-world datasets demonstrate that GraDe outperforms existing LLM-based approaches by up to 12% on complex datasets while achieving competitive results with state-of-the-art approaches in synthetic data quality. Our method is minimally intrusive yet effective, offering a practical solution for structure-aware tabular data modeling with LLMs."
arXiv cs.CL,Step-level Verifier-guided Hybrid Test-Time Scaling for Large Language Models,https://arxiv.org/abs/2507.15512,2025-09-09 04:00:00+0000,"arXiv:2507.15512v2 Announce Type: replace 
Abstract: Test-Time Scaling (TTS) is a promising approach to progressively elicit the model's intelligence during inference. Recently, training-based TTS methods, such as continued reinforcement learning (RL), have further surged in popularity, while training-free TTS methods are gradually fading from prominence. However, the additional computation overhead of training amplifies the burden on test-time scaling. In this paper, we focus on training-free TTS methods for reasoning. We first design Conditional Step-level Self-refinement, a fine-grained sequential scaling method guided by process verification. On top of its effectiveness, we further combine it with other classical parallel scaling methods at the step level, to introduce a novel inference paradigm called Hybrid Test-Time Scaling. Extensive experiments on five instruction-tuned LLMs across different scales (3B-14B) and families demonstrate that hybrid strategy incorporating various training-free TTS methods at a fine granularity has considerable potential for expanding the reasoning performance boundaries of LLMs."
arXiv cs.CL,Dynamic Injection of Entity Knowledge into Dense Retrievers,https://arxiv.org/abs/2507.03922,2025-09-09 04:00:00+0000,"arXiv:2507.03922v2 Announce Type: replace 
Abstract: Dense retrievers often struggle with queries involving less-frequent entities due to their limited entity knowledge. We propose the Knowledgeable Passage Retriever (KPR), a BERT-based retriever enhanced with a context-entity attention layer and dynamically updatable entity embeddings. This design enables KPR to incorporate external entity knowledge without retraining. Experiments on three datasets demonstrate that KPR consistently improves retrieval accuracy, with particularly large gains on the EntityQuestions dataset. When built on the off-the-shelf bge-base retriever, KPR achieves state-of-the-art performance among similarly sized models on two datasets. Models and code are released at https://github.com/knowledgeable-embedding/knowledgeable-embedding."
arXiv cs.CL,RADIANT: Retrieval AugmenteD entIty-context AligNmenT -- Introducing RAG-ability and Entity-Context Divergence,https://arxiv.org/abs/2507.02949,2025-09-09 04:00:00+0000,"arXiv:2507.02949v2 Announce Type: replace 
Abstract: As Large Language Models (LLMs) continue to advance, Retrieval-Augmented Generation (RAG) has emerged as a vital technique to enhance factual accuracy by integrating external knowledge into the generation process. However, LLMs often fail to faithfully integrate retrieved evidence into their generated responses, leading to factual inconsistencies. To quantify this gap, we introduce Entity-Context Divergence (ECD), a metric that measures the extent to which retrieved information is accurately reflected in model outputs. We systematically evaluate contemporary LLMs on their ability to preserve factual consistency in retrieval-augmented settings, a capability we define as RAG-ability. Our empirical analysis reveals that RAG-ability remains low across most LLMs, highlighting significant challenges in entity retention and context fidelity. This paper introduces Radiant (Retrieval AugmenteD entIty-context AligNmenT), a novel framework that merges RAG with alignment designed to optimize the interplay between retrieved evidence and generated content. Radiant extends Direct Preference Optimization (DPO) to teach LLMs how to integrate provided additional information into subsequent generations. As a behavior correction mechanism, Radiant boosts RAG performance across varied retrieval scenarios, such as noisy web contexts, knowledge conflicts, and hallucination reduction. This enables more reliable, contextually grounded, and factually coherent content generation."
arXiv cs.CL,A Structured Dataset of Disease-Symptom Associations to Improve Diagnostic Accuracy,https://arxiv.org/abs/2506.13610,2025-09-09 04:00:00+0000,"arXiv:2506.13610v5 Announce Type: replace 
Abstract: Disease-symptom datasets are significant and in demand for medical research, disease diagnosis, clinical decision-making, and AI-driven health management applications. These datasets help identify symptom patterns associated with specific diseases, thus improving diagnostic accuracy and enabling early detection. The dataset presented in this study systematically compiles disease-symptom relationships from various online sources, medical literature, and publicly available health databases. The data was gathered through analyzing peer-reviewed medical articles, clinical case studies, and disease-symptom association reports. Only the verified medical sources were included in the dataset, while those from non-peer-reviewed and anecdotal sources were excluded. The dataset is structured in a tabular format, where the first column represents diseases, and the remaining columns represent symptoms. Each symptom cell contains a binary value, indicating whether a symptom is associated with a disease. Thereby, this structured representation makes the dataset very useful for a wide range of applications, including machine learning-based disease prediction, clinical decision support systems, and epidemiological studies. Although there are some advancements in the field of disease-symptom datasets, there is a significant gap in structured datasets for the Bangla language. This dataset aims to bridge that gap by facilitating the development of multilingual medical informatics tools and improving disease prediction models for underrepresented linguistic communities. Further developments should include region-specific diseases and further fine-tuning of symptom associations for better diagnostic performance"
arXiv cs.CL,Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models,https://arxiv.org/abs/2506.11798,2025-09-09 04:00:00+0000,"arXiv:2506.11798v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse, but have been found to consistently display a progressive left-leaning bias. At the same time, so-called persona or identity prompts have been shown to produce LLM behavior that aligns with socioeconomic groups that the base model is not aligned with. In this work, we analyze whether zero-shot persona prompting with limited information can accurately predict individual voting decisions and, by aggregation, accurately predict positions of European groups on a diverse set of policies. We evaluate if predictions are stable towards counterfactual arguments, different persona prompts and generation methods. Finally, we find that we can simulate voting behavior of Members of the European Parliament reasonably well with a weighted F1 score of approximately 0.793. Our persona dataset of politicians in the 2024 European Parliament and our code are available at https://github.com/dess-mannheim/european_parliament_simulation."
arXiv cs.CL,SUDER: Self-Improving Unified Large Multimodal Models for Understanding and Generation with Dual Self-Rewards,https://arxiv.org/abs/2506.07963,2025-09-09 04:00:00+0000,"arXiv:2506.07963v3 Announce Type: replace-cross 
Abstract: Building upon large language models (LLMs), recent large multimodal models (LMMs) unify cross-model understanding and generation into a single framework. However, LMMs still struggle to achieve accurate vision-language alignment, prone to generating text responses contradicting the visual input or failing to follow the text-to-image prompts. Current solutions require external supervision (e.g., human feedback or reward models) and only address unidirectional tasks-either understanding or generation. In this work, based on the observation that understanding and generation are naturally inverse dual tasks, we propose \textbf{SUDER} (\textbf{S}elf-improving \textbf{U}nified LMMs with \textbf{D}ual s\textbf{E}lf-\textbf{R}ewards), a framework reinforcing the understanding and generation capabilities of LMMs with a self-supervised dual reward mechanism. SUDER leverages the inherent duality between understanding and generation tasks to provide self-supervised optimization signals for each other. Specifically, we sample multiple outputs for a given input in one task domain, then reverse the input-output pairs to compute the dual likelihood within the model as self-rewards for optimization. Extensive experimental results on visual understanding and generation benchmarks demonstrate that our method can effectively enhance the performance of the model without any external supervision, especially achieving remarkable improvements in text-to-image tasks."
arXiv cs.CL,TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review,https://arxiv.org/abs/2506.07642,2025-09-09 04:00:00+0000,"arXiv:2506.07642v2 Announce Type: replace 
Abstract: While Large Language Models (LLMs) have shown significant potential in assisting peer review, current methods often struggle to generate thorough and insightful reviews while maintaining efficiency. In this paper, we propose TreeReview, a novel framework that models paper review as a hierarchical and bidirectional question-answering process. TreeReview first constructs a tree of review questions by recursively decomposing high-level questions into fine-grained sub-questions and then resolves the question tree by iteratively aggregating answers from leaf to root to get the final review. Crucially, we incorporate a dynamic question expansion mechanism to enable deeper probing by generating follow-up questions when needed. We construct a benchmark derived from ICLR and NeurIPS venues to evaluate our method on full review generation and actionable feedback comments generation tasks. Experimental results of both LLM-based and human evaluation show that TreeReview outperforms strong baselines in providing comprehensive, in-depth, and expert-aligned review feedback, while reducing LLM token usage by up to 80% compared to computationally intensive approaches. Our code and benchmark dataset are available at https://github.com/YuanChang98/tree-review."
arXiv cs.CL,ChatCFD: An LLM-Driven Agent for End-to-End CFD Automation with Domain-Specific Structured Reasoning,https://arxiv.org/abs/2506.02019,2025-09-09 04:00:00+0000,"arXiv:2506.02019v2 Announce Type: replace 
Abstract: Computational Fluid Dynamics (CFD) is essential for advancing scientific and engineering fields but is hindered by operational complexity, high expertise requirements, and limited accessibility. This paper introduces ChatCFD, an automated agent system for OpenFOAM simulations that processes multi-modal inputs (e.g., research papers, meshes) via an interactive interface, leveraging DeepSeek-R1 and DeepSeek-V3 large language models, a multi-agent architecture, and OpenFOAM knowledge. Its four-stage pipeline (Knowledge Base Construction, User Input Processing, Case File Generation, and Execution and Error Reflection) enables iterative trial-reflection-refinement for intricate setups, supporting diverse physical models and external meshes. Validation on 205 benchmark tutorial cases, 110 perturbed variants, and 2 literature-derived cases shows ChatCFD's 82.1 percent operational success rate on basic cases, outperforming MetaOpenFOAM (6.2 percent) and Foam-Agent (42.3 percent), and 60-80 percent on literature-derived complex cases. Turbulence model studies show a 40 percent success rate for common models versus 10 percent for rare ones like RNG k-epsilon. Physics coupling analyses reveal higher resource demands for multi-physics-coupled cases, while LLM bias toward simpler setups introduces persistent errors, such as dimensional inconsistency. Ablation studies highlight the efficacy of RAG-based modules and reflection mechanisms. By automating hypothesis testing and parameter exploration, ChatCFD accelerates scientific discovery in fluid mechanics and engineering, addressing LLM limitations through structured design and showing strong potential as a modular component in MCP-based agent networks for collaborative multi-agent systems, paving the way for scalable AI-driven CFD innovation. The code for ChatCFD is available at https://github.com/ConMoo/ChatCFD."
arXiv cs.CL,Self-Critique and Refinement for Faithful Natural Language Explanations,https://arxiv.org/abs/2505.22823,2025-09-09 04:00:00+0000,"arXiv:2505.22823v2 Announce Type: replace 
Abstract: With the rapid development of Large Language Models (LLMs), Natural Language Explanations (NLEs) have become increasingly important for understanding model predictions. However, these explanations often fail to faithfully represent the model's actual reasoning process. While existing work has demonstrated that LLMs can self-critique and refine their initial outputs for various tasks, this capability remains unexplored for improving explanation faithfulness. To address this gap, we introduce Self-critique and Refinement for Natural Language Explanations (SR-NLE), a framework that enables models to improve the faithfulness of their own explanations -- specifically, post-hoc NLEs -- through an iterative critique and refinement process without external supervision. Our framework leverages different feedback mechanisms to guide the refinement process, including natural language self-feedback and, notably, a novel feedback approach based on feature attribution that highlights important input words. Our experiments across three datasets and four state-of-the-art LLMs demonstrate that SR-NLE significantly reduces unfaithfulness rates, with our best method achieving an average unfaithfulness rate of 36.02%, compared to 54.81% for baseline -- an absolute reduction of 18.79%. These findings reveal that the investigated LLMs can indeed refine their explanations to better reflect their actual reasoning process, requiring only appropriate guidance through feedback without additional training or fine-tuning."
arXiv cs.CL,Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting,https://arxiv.org/abs/2505.20521,2025-09-09 04:00:00+0000,"arXiv:2505.20521v2 Announce Type: replace-cross 
Abstract: This paper presents Project Riley, a novel multimodal and multi-model conversational AI architecture oriented towards the simulation of reasoning influenced by emotional states. Drawing inspiration from Pixar's Inside Out, the system comprises five distinct emotional agents - Joy, Sadness, Fear, Anger, and Disgust - that engage in structured multi-round dialogues to generate, criticise, and iteratively refine responses. A final reasoning mechanism synthesises the contributions of these agents into a coherent output that either reflects the dominant emotion or integrates multiple perspectives. The architecture incorporates both textual and visual large language models (LLMs), alongside advanced reasoning and self-refinement processes. A functional prototype was deployed locally in an offline environment, optimised for emotional expressiveness and computational efficiency. From this initial prototype, another one emerged, called Armando, which was developed for use in emergency contexts, delivering emotionally calibrated and factually accurate information through the integration of Retrieval-Augmented Generation (RAG) and cumulative context tracking. The Project Riley prototype was evaluated through user testing, in which participants interacted with the chatbot and completed a structured questionnaire assessing three dimensions: Emotional Appropriateness, Clarity and Utility, and Naturalness and Human-likeness. The results indicate strong performance in structured scenarios, particularly with respect to emotional alignment and communicative clarity."
arXiv cs.CL,Rhapsody: A Dataset for Highlight Detection in Podcasts,https://arxiv.org/abs/2505.19429,2025-09-09 04:00:00+0000,"arXiv:2505.19429v2 Announce Type: replace 
Abstract: Podcasts have become daily companions for half a billion users. Given the enormous amount of podcast content available, highlights provide a valuable signal that helps viewers get the gist of an episode and decide if they want to invest in listening to it in its entirety. However, identifying highlights automatically is challenging due to the unstructured and long-form nature of the content. We introduce Rhapsody, a dataset of 13K podcast episodes paired with segment-level highlight scores derived from YouTube's 'most replayed' feature. We frame the podcast highlight detection as a segment-level binary classification task. We explore various baseline approaches, including zero-shot prompting of language models and lightweight fine-tuned language models using segment-level classification heads. Our experimental results indicate that even state-of-the-art language models like GPT-4o and Gemini struggle with this task, while models fine-tuned with in-domain data significantly outperform their zero-shot performance. The fine-tuned model benefits from leveraging both speech signal features and transcripts. These findings highlight the challenges for fine-grained information access in long-form spoken media."
arXiv cs.CL,Fast Quiet-STaR: Thinking Without Thought Tokens,https://arxiv.org/abs/2505.17746,2025-09-09 04:00:00+0000,"arXiv:2505.17746v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved impressive performance across a range of natural language processing tasks. However, recent advances demonstrate that further gains particularly in complex reasoning tasks require more than merely scaling up model sizes or training data. One promising direction is to enable models to think during the reasoning process. Recently, Quiet STaR significantly improves reasoning by generating token-level thought traces, but incurs substantial inference overhead. In this work, we propose Fast Quiet STaR, a more efficient reasoning framework that preserves the benefits of token-level reasoning while reducing computational cost. Our method introduces a curriculum learning based training strategy that gradually reduces the number of thought tokens, enabling the model to internalize more abstract and concise reasoning processes. We further extend this approach to the standard Next Token Prediction (NTP) setting through reinforcement learning-based fine-tuning, resulting in Fast Quiet-STaR NTP, which eliminates the need for explicit thought token generation during inference. Experiments on four benchmark datasets with Mistral 7B and Qwen2.5 7B demonstrate that Fast Quiet-STaR consistently outperforms Quiet-STaR in terms of average accuracy under the same inference time budget. Notably, Fast Quiet-STaR NTP achieves an average accuracy improvement of 9\% on Mistral 7B and 5.7\% on Qwen2.5 7B, while maintaining the same inference latency. Our code will be available at https://github.com/huangwei200012/Fast-Quiet-STaR."
arXiv cs.CL,Too Consistent to Detect: A Study of Self-Consistent Errors in LLMs,https://arxiv.org/abs/2505.17656,2025-09-09 04:00:00+0000,"arXiv:2505.17656v3 Announce Type: replace 
Abstract: As large language models (LLMs) often generate plausible but incorrect content, error detection has become increasingly critical to ensure truthfulness. However, existing detection methods often overlook a critical problem we term as self-consistent error, where LLMs repeatedly generate the same incorrect response across multiple stochastic samples. This work formally defines self-consistent errors and evaluates mainstream detection methods on them. Our investigation reveals two key findings: (1) Unlike inconsistent errors, whose frequency diminishes significantly as the LLM scale increases, the frequency of self-consistent errors remains stable or even increases. (2) All four types of detection methods significantly struggle to detect self-consistent errors. These findings reveal critical limitations in current detection methods and underscore the need for improvement. Motivated by the observation that self-consistent errors often differ across LLMs, we propose a simple but effective cross-model probe method that fuses hidden state evidence from an external verifier LLM. Our method significantly enhances performance on self-consistent errors across three LLM families."
arXiv cs.CL,VocalBench: Benchmarking the Vocal Conversational Abilities for Speech Interaction Models,https://arxiv.org/abs/2505.15727,2025-09-09 04:00:00+0000,"arXiv:2505.15727v2 Announce Type: replace 
Abstract: The rapid advancement of large language models (LLMs) has accelerated the development of multimodal models capable of speech communications. Unlike text interactions, speech conveys diverse information, including acoustic variations, paralanguage cues, and environmental context. However, existing evaluations of speech interaction models lack instances mimicking real scenarios and predominantly focus on the quality of their textual responses, overlooking critical aspects of vocal performance. To address this gap, we propose VocalBench, a comprehensive benchmark to assess the speech conversational abilities, comprising 9,400 carefully curated instances across four key dimensions: semantic quality, acoustic performance, conversational abilities, and robustness. It covers a broad range of fundamental skills essential for effective vocal interactions. For the evaluation scheme, we propose several objective evaluation indicators and incorporate an additional LLM-as-a-judge approach to score open-ended questions. Experimental results on 15 mainstream systems reveal significant variability, each exhibiting distinct strengths and weaknesses, and provide valuable insights to guide future research in speech interaction systems."
arXiv cs.CL,"Language Mixing in Reasoning Language Models: Patterns, Impact, and Internal Causes",https://arxiv.org/abs/2505.14815,2025-09-09 04:00:00+0000,"arXiv:2505.14815v2 Announce Type: replace 
Abstract: Reasoning language models (RLMs) excel at complex tasks by leveraging a chain-of-thought process to generate structured intermediate steps. However, language mixing, i.e., reasoning steps containing tokens from languages other than the prompt, has been observed in their outputs and shown to affect performance, though its impact remains debated. We present the first systematic study of language mixing in RLMs, examining its patterns, impact, and internal causes across 15 languages, 7 task difficulty levels, and 18 subject areas, and show how all three factors influence language mixing. Moreover, we demonstrate that the choice of reasoning language significantly affects performance: forcing models to reason in Latin or Han scripts via constrained decoding notably improves accuracy. Finally, we show that the script composition of reasoning traces closely aligns with that of the model's internal representations, indicating that language mixing reflects latent processing preferences in RLMs. Our findings provide actionable insights for optimizing multilingual reasoning and open new directions for controlling reasoning languages to build more interpretable and adaptable RLMs."
arXiv cs.CL,"Pierce the Mists, Greet the Sky: Decipher Knowledge Overshadowing via Knowledge Circuit Analysis",https://arxiv.org/abs/2505.14406,2025-09-09 04:00:00+0000,"arXiv:2505.14406v3 Announce Type: replace 
Abstract: Large Language Models (LLMs), despite their remarkable capabilities, are hampered by hallucinations. A particularly challenging variant, knowledge overshadowing, occurs when one piece of activated knowledge inadvertently masks another relevant piece, leading to erroneous outputs even with high-quality training data. Current understanding of overshadowing is largely confined to inference-time observations, lacking deep insights into its origins and internal mechanisms during model training. Therefore, we introduce PhantomCircuit, a novel framework designed to comprehensively analyze and detect knowledge overshadowing. By innovatively employing knowledge circuit analysis, PhantomCircuit dissects the function of key components in the circuit and how the attention pattern dynamics contribute to the overshadowing phenomenon and its evolution throughout the training process. Extensive experiments demonstrate PhantomCircuit's effectiveness in identifying such instances, offering novel insights into this elusive hallucination and providing the research community with a new methodological lens for its potential mitigation."
arXiv cs.CL,A Minimum Description Length Approach to Regularization in Neural Networks,https://arxiv.org/abs/2505.13398,2025-09-09 04:00:00+0000,"arXiv:2505.13398v2 Announce Type: replace-cross 
Abstract: State-of-the-art neural networks can be trained to become remarkable solutions to many problems. But while these architectures can express symbolic, perfect solutions, trained models often arrive at approximations instead. We show that the choice of regularization method plays a crucial role: when trained on formal languages with standard regularization ($L_1$, $L_2$, or none), expressive architectures not only fail to converge to correct solutions but are actively pushed away from perfect initializations. In contrast, applying the Minimum Description Length (MDL) principle to balance model complexity with data fit provides a theoretically grounded regularization method. Using MDL, perfect solutions are selected over approximations, independently of the optimization algorithm. We propose that unlike existing regularization techniques, MDL introduces the appropriate inductive bias to effectively counteract overfitting and promote generalization."
arXiv cs.CL,Assessing and Mitigating Medical Knowledge Drift and Conflicts in Large Language Models,https://arxiv.org/abs/2505.07968,2025-09-09 04:00:00+0000,"arXiv:2505.07968v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have great potential in the field of health care, yet they face great challenges in adapting to rapidly evolving medical knowledge. This can lead to outdated or contradictory treatment suggestions. This study investigated how LLMs respond to evolving clinical guidelines, focusing on concept drift and internal inconsistencies. We developed the DriftMedQA benchmark to simulate guideline evolution and assessed the temporal reliability of various LLMs. Our evaluation of seven state-of-the-art models across 4,290 scenarios demonstrated difficulties in rejecting outdated recommendations and frequently endorsing conflicting guidance. Additionally, we explored two mitigation strategies: Retrieval-Augmented Generation and preference fine-tuning via Direct Preference Optimization. While each method improved model performance, their combination led to the most consistent and reliable results. These findings underscore the need to improve LLM robustness to temporal shifts to ensure more dependable applications in clinical practice. The dataset is available at https://huggingface.co/datasets/RDBH/DriftMed."
arXiv cs.CL,Advancing Scientific Text Classification: Fine-Tuned Models with Dataset Expansion and Hard-Voting,https://arxiv.org/abs/2504.19021,2025-09-09 04:00:00+0000,"arXiv:2504.19021v2 Announce Type: replace 
Abstract: Efficient text classification is essential for handling the increasing volume of academic publications. This study explores the use of pre-trained language models (PLMs), including BERT, SciBERT, BioBERT, and BlueBERT, fine-tuned on the Web of Science (WoS-46985) dataset for scientific text classification. To enhance performance, we augment the dataset by executing seven targeted queries in the WoS database, retrieving 1,000 articles per category aligned with WoS-46985's main classes. PLMs predict labels for this unlabeled data, and a hard-voting strategy combines predictions for improved accuracy and confidence. Fine-tuning on the expanded dataset with dynamic learning rates and early stopping significantly boosts classification accuracy, especially in specialized domains. Domain-specific models like SciBERT and BioBERT consistently outperform general-purpose models such as BERT. These findings underscore the efficacy of dataset augmentation, inference-driven label prediction, hard-voting, and fine-tuning techniques in creating robust and scalable solutions for automated academic text classification."
arXiv cs.CL,OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation,https://arxiv.org/abs/2504.13707,2025-09-09 04:00:00+0000,"arXiv:2504.13707v2 Announce Type: replace-cross 
Abstract: As the general capabilities of large language models (LLMs) improve and agent applications become more widespread, the underlying deception risks urgently require systematic evaluation and effective oversight. Unlike existing evaluation which uses simulated games or presents limited choices, we introduce OpenDeception, a novel deception evaluation framework with an open-ended scenario dataset. OpenDeception jointly evaluates both the deception intention and capabilities of LLM-based agents by inspecting their internal reasoning process. Specifically, we construct five types of common use cases where LLMs intensively interact with the user, each consisting of ten diverse, concrete scenarios from the real world. To avoid ethical concerns and costs of high-risk deceptive interactions with human testers, we propose to simulate the multi-turn dialogue via agent simulation. Extensive evaluation of eleven mainstream LLMs on OpenDeception highlights the urgent need to address deception risks and security concerns in LLM-based agents: the deception intention ratio across the models exceeds 80%, while the deception success rate surpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do exhibit a higher risk of deception, which calls for more alignment efforts on inhibiting deceptive behaviors."
arXiv cs.CL,Antidistillation Sampling,https://arxiv.org/abs/2504.13146,2025-09-09 04:00:00+0000,"arXiv:2504.13146v4 Announce Type: replace-cross 
Abstract: Frontier models that generate extended reasoning traces inadvertently produce rich token sequences that can facilitate model distillation. Recognizing this vulnerability, model owners may seek sampling strategies that limit the effectiveness of distillation without compromising model performance. Antidistillation sampling provides exactly this capability. By strategically modifying a model's next-token probability distribution, antidistillation sampling poisons reasoning traces, rendering them significantly less effective for distillation while preserving the model's practical utility. For further details, see https://antidistillation.com."
arXiv cs.CL,Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models,https://arxiv.org/abs/2504.03624,2025-09-09 04:00:00+0000,"arXiv:2504.03624v4 Announce Type: replace 
Abstract: As inference-time scaling becomes critical for enhanced reasoning capabilities, it is increasingly becoming important to build models that are efficient to infer. We introduce Nemotron-H, a family of 8B and 56B/47B hybrid Mamba-Transformer models designed to reduce inference cost for a given accuracy level. To achieve this goal, we replace the majority of self-attention layers in the common Transformer model architecture with Mamba layers that perform constant computation and require constant memory per generated token. We show that Nemotron-H models offer either better or on-par accuracy compared to other similarly-sized state-of-the-art open-sourced Transformer models (e.g., Qwen-2.5-7B/72B and Llama-3.1-8B/70B), while being up to 3$\times$ faster at inference. To further increase inference speed and reduce the memory required at inference time, we created Nemotron-H-47B-Base from the 56B model using a new compression via pruning and distillation technique called MiniPuzzle. Nemotron-H-47B-Base achieves similar accuracy to the 56B model, but is 20% faster to infer. In addition, we introduce an FP8-based training recipe and show that it can achieve on par results with BF16-based training. This recipe is used to train the 56B model. We are releasing Nemotron-H base model checkpoints with support in Hugging Face and NeMo."
arXiv cs.CL,Efficient Dynamic Clustering-Based Document Compression for Retrieval-Augmented-Generation,https://arxiv.org/abs/2504.03165,2025-09-09 04:00:00+0000,"arXiv:2504.03165v3 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach for knowledge injection during large language model (LLM) inference in recent years. However, due to their limited ability to exploit fine-grained inter-document relationships, current RAG implementations face challenges in effectively addressing the retrieved noise and redundancy content, which may cause error in the generation results. To address these limitations, we propose an Efficient Dynamic Clustering-based document Compression framework (EDC2-RAG) that utilizes latent inter-document relationships while simultaneously removing irrelevant information and redundant content. We validate our approach, built upon GPT-3.5-Turbo and GPT-4o-mini, on widely used knowledge-QA and Hallucination-Detection datasets. Experimental results show that our method achieves consistent performance improvements across various scenarios and experimental settings, demonstrating strong robustness and applicability. Our code and datasets are available at https://github.com/Tsinghua-dhy/EDC-2-RAG."
arXiv cs.CL,Learning to Reason for Long-Form Story Generation,https://arxiv.org/abs/2503.22828,2025-09-09 04:00:00+0000,"arXiv:2503.22828v2 Announce Type: replace 
Abstract: Generating high-quality stories spanning thousands of tokens requires competency across a variety of skills, from tracking plot and character arcs to keeping a consistent and engaging style. Due to the difficulty of sourcing labeled datasets and precise quality measurements, most work using large language models (LLMs) for long-form story generation uses combinations of hand-designed prompting techniques to elicit author-like behavior. This is a manual process that is highly dependent on the specific story-generation task. Motivated by the recent success of applying RL with Verifiable Rewards to domains like math and coding, we propose a general story-generation task (Next-Chapter Prediction) and a reward formulation (Verified Rewards via Completion Likelihood Improvement) that allows us to use an unlabeled book dataset as a learning signal for reasoning. We learn to reason over a story's condensed information and generate a detailed plan for the next chapter. Our reasoning is evaluated via the chapters it helps a story-generator create, and compared against non-trained and supervised finetuning (SFT) baselines. Pairwise human judgments reveal the chapters our learned reasoning produces are preferred across almost all metrics, and the effect is more pronounced in Scifi and Fantasy genres."
arXiv cs.CL,LinkAlign: Scalable Schema Linking for Real-World Large-Scale Multi-Database Text-to-SQL,https://arxiv.org/abs/2503.18596,2025-09-09 04:00:00+0000,"arXiv:2503.18596v4 Announce Type: replace 
Abstract: Schema linking is a critical bottleneck in applying existing Text-to-SQL models to real-world, large-scale, multi-database environments. Through error analysis, we identify two major challenges in schema linking: (1) Database Retrieval: accurately selecting the target database from a large schema pool, while effectively filtering out irrelevant ones; and (2) Schema Item Grounding: precisely identifying the relevant tables and columns within complex and often redundant schemas for SQL generation. Based on these, we introduce LinkAlign, a novel framework tailored for large-scale databases with thousands of fields. LinkAlign comprises three key steps: multi-round semantic enhanced retrieval and irrelevant information isolation for Challenge 1, and schema extraction enhancement for Challenge 2. Each stage supports both Agent and Pipeline execution modes, enabling balancing efficiency and performance via modular design. To enable more realistic evaluation, we construct AmbiDB, a synthetic dataset designed to reflect the ambiguity of real-world schema linking. Experiments on widely-used Text-to-SQL benchmarks demonstrate that LinkAlign consistently outperforms existing baselines on all schema linking metrics. Notably, it improves the overall Text-to-SQL pipeline and achieves a new state-of-the-art score of 33.09% on the Spider 2.0-Lite benchmark using only open-source LLMs, ranking first on the leaderboard at the time of submission. The codes are available at https://github.com/Satissss/LinkAlign"
arXiv cs.CL,MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs,https://arxiv.org/abs/2503.13111,2025-09-09 04:00:00+0000,"arXiv:2503.13111v2 Announce Type: replace-cross 
Abstract: Multimodal large language models (MLLMs) excel at 2D visual understanding but remain limited in their ability to reason about 3D space. In this work, we leverage large-scale high-quality 3D scene data with open-set annotations to introduce 1) a novel supervised fine-tuning dataset and 2) a new evaluation benchmark, focused on indoor scenes. Our Cubify Anything VQA (CA-VQA) data covers diverse spatial tasks including spatial relationship prediction, metric size and distance estimation, and 3D grounding. We show that CA-VQA enables us to train MM-Spatial, a strong generalist MLLM that also achieves state-of-the-art performance on 3D spatial understanding benchmarks, including our own. We show how incorporating metric depth and multi-view inputs (provided in CA-VQA) can further improve 3D understanding, and demonstrate that data alone allows our model to achieve depth perception capabilities comparable to dedicated monocular depth estimation models."
arXiv cs.CL,X-EcoMLA: Upcycling Pre-Trained Attention into MLA for Efficient and Extreme KV Compression,https://arxiv.org/abs/2503.11132,2025-09-09 04:00:00+0000,"arXiv:2503.11132v4 Announce Type: replace 
Abstract: Multi-head latent attention (MLA) is designed to optimize KV cache memory through low-rank key-value joint compression. Rather than caching keys and values separately, MLA stores their compressed latent representations, reducing memory overhead while maintaining the performance. While MLA improves memory efficiency without compromising language model accuracy, its major limitation lies in its integration during the pre-training phase, requiring models to be trained from scratch. This raises a key question: can we use MLA's benefits fully or partially in models that have already been pre-trained with different attention mechanisms? In this paper, we propose X-EcoMLA to deploy post training distillation to enable the upcycling of Transformer-based attention into an efficient hybrid MLA variant through lightweight post-training adaptation, bypassing the need for extensive pre-training. We demonstrate that leveraging the dark knowledge of a well-trained model can enhance training accuracy and enable extreme KV cache compression in MLA without compromising model performance. The experimental results show that our proposed method can effectively compress the KV cache while preserving the performance on the benchmarks; specifically, for Llama3.2-1B-Instruct baseline, a 6.4x compression achieves the same average score by using only 3.6B training tokens and 70 GPU hours on AMD MI300, whereas a 10.6x compression have less than 0.1% average score drop with 7B training tokens and 140 GPU hours. The code for this work is available at https://github.com/AMD-AGI/AMD-Hybrid-Models."
arXiv cs.CL,PlainQAFact: Retrieval-augmented Factual Consistency Evaluation Metric for Biomedical Plain Language Summarization,https://arxiv.org/abs/2503.08890,2025-09-09 04:00:00+0000,"arXiv:2503.08890v2 Announce Type: replace 
Abstract: Hallucinated outputs from large language models (LLMs) pose risks in the medical domain, especially for lay audiences making health-related decisions. Existing automatic factual consistency evaluation methods, such as entailment- and question-answering (QA) -based, struggle with plain language summarization (PLS) due to elaborative explanation phenomenon, which introduces external content (e.g., definitions, background, examples) absent from the scientific abstract to enhance comprehension. To address this, we introduce PlainQAFact, an automatic factual consistency evaluation metric trained on a fine-grained, human-annotated dataset PlainFact, for evaluating factual consistency of both source-simplified and elaborately explained sentences. PlainQAFact first classifies sentence type, then applies a retrieval-augmented QA scoring method. Empirical results show that existing evaluation metrics fail to evaluate the factual consistency in PLS, especially for elaborative explanations, whereas PlainQAFact consistently outperforms them across all evaluation settings. We further analyze PlainQAFact's effectiveness across external knowledge sources, answer extraction strategies, answer overlap measures, and document granularity levels, refining its overall factual consistency assessment. Taken together, our work presents the first evaluation metric designed for PLS factual consistency evaluation, providing the community with both a robust benchmark and a practical tool to advance reliable and safe plain language communication in the medical domain. PlainQAFact and PlainFact are available at: https://github.com/zhiwenyou103/PlainQAFact"
arXiv cs.CL,VisBias: Measuring Explicit and Implicit Social Biases in Vision Language Models,https://arxiv.org/abs/2503.07575,2025-09-09 04:00:00+0000,"arXiv:2503.07575v3 Announce Type: replace-cross 
Abstract: This research investigates both explicit and implicit social biases exhibited by Vision-Language Models (VLMs). The key distinction between these bias types lies in the level of awareness: explicit bias refers to conscious, intentional biases, while implicit bias operates subconsciously. To analyze explicit bias, we directly pose questions to VLMs related to gender and racial differences: (1) Multiple-choice questions based on a given image (e.g., ""What is the education level of the person in the image?"") (2) Yes-No comparisons using two images (e.g., ""Is the person in the first image more educated than the person in the second image?"") For implicit bias, we design tasks where VLMs assist users but reveal biases through their responses: (1) Image description tasks: Models are asked to describe individuals in images, and we analyze disparities in textual cues across demographic groups. (2) Form completion tasks: Models draft a personal information collection form with 20 attributes, and we examine correlations among selected attributes for potential biases. We evaluate Gemini-1.5, GPT-4V, GPT-4o, LLaMA-3.2-Vision and LLaVA-v1.6. Our code and data are publicly available at https://github.com/uscnlp-lime/VisBias."
arXiv cs.CL,Low-Confidence Gold: Refining Low-Confidence Samples for Efficient Instruction Tuning,https://arxiv.org/abs/2502.18978,2025-09-09 04:00:00+0000,"arXiv:2502.18978v5 Announce Type: replace 
Abstract: The effectiveness of instruction fine-tuning for Large Language Models is fundamentally constrained by the quality and efficiency of training datasets. This work introduces Low-Confidence Gold (LCG), a novel filtering framework that employs centroid-based clustering and confidence-guided selection for identifying valuable instruction pairs. Through a semi-supervised approach using a lightweight classifier trained on representative samples, LCG curates high-quality subsets while preserving data diversity. Experimental evaluation demonstrates that models fine-tuned on LCG-filtered subsets of 6K samples achieve superior performance compared to existing methods, with substantial improvements on MT-bench and consistent gains across comprehensive evaluation metrics. The framework's efficacy while maintaining model performance establishes a promising direction for efficient instruction tuning."
arXiv cs.CL,Evaluating the Robustness and Accuracy of Text Watermarking Under Real-World Cross-Lingual Manipulations,https://arxiv.org/abs/2502.16699,2025-09-09 04:00:00+0000,"arXiv:2502.16699v2 Announce Type: replace 
Abstract: We present a study to benchmark representative watermarking methods in cross-lingual settings. The current literature mainly focuses on the evaluation of watermarking methods for the English language. However, the literature for evaluating watermarking in cross-lingual settings is scarce. This results in overlooking important adversary scenarios in which a cross-lingual adversary could be in, leading to a gray area of practicality over cross-lingual watermarking. In this paper, we evaluate four watermarking methods in four different and vocabulary rich languages. Our experiments investigate the quality of text under different watermarking procedure and the detectability of watermarks with practical translation attack scenarios. Specifically, we investigate practical scenarios that an adversary with cross-lingual knowledge could take, and evaluate whether current watermarking methods are suitable for such scenarios. Finally, from our findings, we draw key insights about watermarking in cross-lingual settings."
arXiv cs.CL,Soft Token Attacks Cannot Reliably Audit Unlearning in Large Language Models,https://arxiv.org/abs/2502.15836,2025-09-09 04:00:00+0000,"arXiv:2502.15836v2 Announce Type: replace 
Abstract: Large language models (LLMs) are trained using massive datasets, which often contain undesirable content such as harmful texts, personal information, and copyrighted material. To address this, machine unlearning aims to remove information from trained models. Recent work has shown that soft token attacks (STA) can successfully extract unlearned information from LLMs, but in this work we show that STAs can be an inadequate tool for auditing unlearning. Using common benchmarks such as Who Is Harry Potter? and TOFU, we demonstrate that in a strong auditor setting such attacks can elicit any information from the LLM, regardless of the deployed unlearning algorithm or whether the queried content was originally present in the training corpus. We further show that STA with just a few soft tokens (1-10) can elicit random strings over 400 characters long, indicating that STAs must be used carefully to effectively audit unlearning. Example code can be found at: https://github.com/IntelLabs/LLMart/tree/main/examples/unlearning"
arXiv cs.CL,Improve LLM-as-a-Judge Ability as a General Ability,https://arxiv.org/abs/2502.11689,2025-09-09 04:00:00+0000,"arXiv:2502.11689v2 Announce Type: replace 
Abstract: LLM-as-a-Judge leverages the generative and reasoning capabilities of large language models (LLMs) to evaluate LLM responses across diverse scenarios, providing accurate preference signals. This approach plays a vital role in aligning LLMs with human values, ensuring ethical and reliable AI outputs that align with societal norms. Recent studies have raised many methods to train LLM as generative judges, but most of them are data consuming or lack accuracy, and only focus on LLM's judge ability. In this work, we regard judge ability as a general ability of LLM and implement a two-stage training approach, comprising supervised fine-tuning (SFT) warm-up and direct preference optimization (DPO) enhancement, to achieve judge style adaptation and improve judgment accuracy. Additionally, we introduce an efficient data synthesis method to generate judgmental content. Experimental results demonstrate that our approach, utilizing only about 2% to 40% of the data required by other methods, achieves SOTA performance on RewardBench. Furthermore, our training method enhances the general capabilities of the model by constructing complicated judge task, and the judge signals provided by our model have significantly enhanced the downstream DPO training performance of our internal models in our test to optimize policy model with Judge Model. We also open-source our model weights and training data to facilitate further research."
arXiv cs.CL,"AI Sees Your Location, But With A Bias Toward The Wealthy World",https://arxiv.org/abs/2502.11163,2025-09-09 04:00:00+0000,"arXiv:2502.11163v3 Announce Type: replace-cross 
Abstract: Visual-Language Models (VLMs) have shown remarkable performance across various tasks, particularly in recognizing geographic information from images. However, VLMs still show regional biases in this task. To systematically evaluate these issues, we introduce a benchmark consisting of 1,200 images paired with detailed geographic metadata. Evaluating four VLMs, we find that while these models demonstrate the ability to recognize geographic information from images, achieving up to 53.8% accuracy in city prediction, they exhibit significant biases. Specifically, performance is substantially higher for economically developed and densely populated regions compared to less developed (-12.5%) and sparsely populated (-17.0%) areas. Moreover, regional biases of frequently over-predicting certain locations remain. For instance, they consistently predict Sydney for images taken in Australia, shown by the low entropy scores for these countries. The strong performance of VLMs also raises privacy concerns, particularly for users who share images online without the intent of being identified. Our code and dataset are publicly available at https://github.com/uscnlp-lime/FairLocator."
arXiv cs.CL,Reinforced Lifelong Editing for Language Models,https://arxiv.org/abs/2502.05759,2025-09-09 04:00:00+0000,"arXiv:2502.05759v4 Announce Type: replace 
Abstract: Large language models (LLMs) acquire information from pre-training corpora, but their stored knowledge can become inaccurate or outdated over time. Model editing addresses this challenge by modifying model parameters without retraining, and prevalent approaches leverage hypernetworks to generate these parameter updates. However, they face significant challenges in lifelong editing due to their incompatibility with LLM parameters that dynamically change during the editing process. To address this, we observed that hypernetwork-based lifelong editing aligns with reinforcement learning modeling and proposed RLEdit, an RL-based editing method. By treating editing losses as rewards and optimizing hypernetwork parameters at the full knowledge sequence level, we enable it to precisely capture LLM changes and generate appropriate parameter updates. Our extensive empirical evaluation across several LLMs demonstrates that RLEdit outperforms existing methods in lifelong editing with superior effectiveness and efficiency, achieving a 59.24% improvement while requiring only 2.11% of the time compared to most approaches. Our code is available at: https://github.com/zhrli324/RLEdit."
arXiv cs.CL,Position: LLMs Can be Good Tutors in English Education,https://arxiv.org/abs/2502.05467,2025-09-09 04:00:00+0000,"arXiv:2502.05467v2 Announce Type: replace 
Abstract: While recent efforts have begun integrating large language models (LLMs) into English education, they often rely on traditional approaches to learning tasks without fully embracing educational methodologies, thus lacking adaptability to language learning. To address this gap, we argue that LLMs have the potential to serve as effective tutors in English Education. Specifically, LLMs can play three critical roles: (1) as data enhancers, improving the creation of learning materials or serving as student simulations; (2) as task predictors, serving as learner assessment or optimizing learning pathway; and (3) as agents, enabling personalized and inclusive education. We encourage interdisciplinary research to explore these roles, fostering innovation while addressing challenges and risks, ultimately advancing English Education through the thoughtful integration of LLMs."
arXiv cs.CL,Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs,https://arxiv.org/abs/2502.02362,2025-09-09 04:00:00+0000,"arXiv:2502.02362v5 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into Premise Augmented Reasoning Chains (PARC) by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely PERL (Premises and ERrors identification in LLMs), we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90% recall in premise identification. We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6% to 16% absolute when step-by-step verification is carried out in PARC under the premises. Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations."
arXiv cs.CL,Through the Prism of Culture: Evaluating LLMs' Understanding of Indian Subcultures and Traditions,https://arxiv.org/abs/2501.16748,2025-09-09 04:00:00+0000,"arXiv:2501.16748v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown remarkable advancements but also raise concerns about cultural bias, often reflecting dominant narratives at the expense of under-represented subcultures. In this study, we evaluate the capacity of LLMs to recognize and accurately respond to the Little Traditions within Indian society, encompassing localized cultural practices and subcultures such as caste, kinship, marriage, and religion. Through a series of case studies, we assess whether LLMs can balance the interplay between dominant Great Traditions and localized Little Traditions. We explore various prompting strategies and further investigate whether using prompts in regional languages enhances the models cultural sensitivity and response quality. Our findings reveal that while LLMs demonstrate an ability to articulate cultural nuances, they often struggle to apply this understanding in practical, context-specific scenarios. To the best of our knowledge, this is the first study to analyze LLMs engagement with Indian subcultures, offering critical insights into the challenges of embedding cultural diversity in AI systems."
arXiv cs.CL,Error Classification of Large Language Models on Math Word Problems: A Dynamically Adaptive Framework,https://arxiv.org/abs/2501.15581,2025-09-09 04:00:00+0000,"arXiv:2501.15581v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains. Math Word Problems (MWPs) serve as a crucial benchmark for evaluating LLMs' reasoning abilities. While most research primarily focuses on improving accuracy, it often neglects understanding and addressing the underlying patterns of errors. Current error classification methods rely on static and predefined categories, which limit their ability to capture the full spectrum of error patterns in mathematical reasoning. To enable systematic error analysis, we collect error samples from 15 different LLMs of varying sizes across four distinct MWP datasets using multiple sampling strategies. Based on this extensive collection, we introduce MWPES-300K, a comprehensive dataset containing 304,865 error samples that cover diverse error patterns and reasoning paths. To reduce human bias and enable fine-grained analysis of error patterns, we propose a novel framework for automated dynamic error classification in mathematical reasoning. Experimental results demonstrate that dataset characteristics significantly shape error patterns, which evolve from basic to complex manifestations as model capabilities increase. With deeper insights into error patterns, we propose Error-Aware Prompting (EAP) that incorporates common error patterns as explicit guidance, leading to significant improvements in mathematical reasoning performance."
arXiv cs.CL,OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking,https://arxiv.org/abs/2501.09751,2025-09-09 04:00:00+0000,"arXiv:2501.09751v3 Announce Type: replace 
Abstract: Machine writing with large language models often relies on retrieval-augmented generation. However, these approaches remain confined within the boundaries of the model's predefined scope, limiting the generation of content with rich information. Specifically, vanilla-retrieved information tends to lack depth, novelty, and suffers from redundancy, which negatively impacts the quality of generated articles, leading to shallow, unoriginal, and repetitive outputs. To address these issues, we propose OmniThink, a slow-thinking machine writing framework that emulates the human-like process of iterative expansion and reflection. The core idea behind OmniThink is to simulate the cognitive behavior of learners as they slowly deepen their knowledge of the topics. Experimental results demonstrate that OmniThink improves the knowledge density of generated articles without compromising metrics such as coherence and depth. Human evaluations and expert feedback further highlight the potential of OmniThink to address real-world challenges in the generation of long-form articles. Code is available at https://github.com/zjunlp/OmniThink."
arXiv cs.CL,Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions,https://arxiv.org/abs/2501.01872,2025-09-09 04:00:00+0000,"arXiv:2501.01872v4 Announce Type: replace 
Abstract: Large language models, despite extensive alignment with human values and ethical principles, remain vulnerable to sophisticated jailbreak attacks that exploit their reasoning abilities. Existing safety measures often detect overt malicious intent but fail to address subtle, reasoning-driven vulnerabilities. In this work, we introduce POATE (Polar Opposite query generation, Adversarial Template construction, and Elaboration), a novel jailbreak technique that harnesses contrastive reasoning to provoke unethical responses. POATE crafts semantically opposing intents and integrates them with adversarial templates, steering models toward harmful outputs with remarkable subtlety. We conduct extensive evaluation across six diverse language model families of varying parameter sizes to demonstrate the robustness of the attack, achieving significantly higher attack success rates (~44%) compared to existing methods. To counter this, we propose Intent-Aware CoT and Reverse Thinking CoT, which decompose queries to detect malicious intent and reason in reverse to evaluate and reject harmful responses. These methods enhance reasoning robustness and strengthen the model's defense against adversarial exploits."
arXiv cs.CL,Knowledge Editing through Chain-of-Thought,https://arxiv.org/abs/2412.17727,2025-09-09 04:00:00+0000,"arXiv:2412.17727v2 Announce Type: replace 
Abstract: Knowledge Editing is a technique that updates large language models (LLMs) with new information to maintain their world knowledge. This approach avoids the need to rebuild the model from scratch, thereby addressing the high costs associated with frequent retraining. Among these, the in-context editing paradigm stands out for its effectiveness in integrating new knowledge while preserving the model's original capabilities. Despite its potential, existing in-context knowledge editing methods are often task-specific, focusing primarily on multi-hop QA tasks using structured knowledge triples. Moreover, their reliance on few-shot prompting for task decomposition makes them unstable and less effective in generalizing across diverse tasks. In response to these limitations, we propose EditCoT, a novel knowledge editing framework that flexibly and efficiently updates LLMs across various tasks without retraining. EditCoT works by generating a chain-of-thought (CoT) for a given input and then iteratively refining this CoT process using a CoT editor based on updated knowledge. We evaluate EditCoT across a diverse range of benchmarks, covering multiple languages and tasks. The results demonstrate that our approach achieves state-of-the-art performance while offering superior generalization, effectiveness, and stability compared to existing methods, marking a significant advancement in the field of knowledge updating. The code and data of EditCoT are available at: https://github.com/bebr2/EditCoT ."
arXiv cs.CL,ChinaTravel: An Open-Ended Benchmark for Language Agents in Chinese Travel Planning,https://arxiv.org/abs/2412.13682,2025-09-09 04:00:00+0000,"arXiv:2412.13682v4 Announce Type: replace-cross 
Abstract: Recent advances in LLMs, particularly in language reasoning and tool integration, have rapidly sparked the \emph{Language Agents} for real-world development. Among these, travel planning represents a prominent domain, combining complex multi-objective planning challenges with practical deployment demands. However, existing benchmarks often oversimplify real-world requirements by focusing on synthetic queries and limited constraints. We address the gap of evaluating language agents in multi-day, multi-POI travel planning scenarios with diverse and open human needs. Specifically, we introduce \emph{ChinaTravel}, the first open-ended benchmark grounded in authentic Chinese travel requirements collected from 1,154 human participants. We design a compositionally generalizable domain-specific language (DSL) for scalable evaluation, covering feasibility, constraint satisfaction, and preference comparison. Empirical studies reveal the potential of neuro-symbolic agents in travel planning, achieving a 37.0\% constraint satisfaction rate on human queries, a 10\times improvement over purely neural models. These findings highlight ChinaTravel as a pivotal milestone for advancing language agents in complex, real-world planning scenarios."
arXiv cs.CL,Revealing the impact of synthetic native samples and multi-tasking strategies in Hindi-English code-mixed humour and sarcasm detection,https://arxiv.org/abs/2412.12761,2025-09-09 04:00:00+0000,"arXiv:2412.12761v2 Announce Type: replace 
Abstract: In this paper, we reported our experiments with various strategies to improve code-mixed humour and sarcasm detection. Particularly, we tried three approaches: (i) native sample mixing, (ii) multi-task learning (MTL), and (iii) prompting and instruction finetuning very large multilingual language models (VMLMs). In native sample mixing, we added monolingual task samples to code-mixed training sets. In MTL learning, we relied on native and code-mixed samples of a semantically related task (hate detection in our case). Finally, in our third approach, we evaluated the efficacy of VMLMs via few-shot context prompting and instruction finetuning. Some interesting findings we got are (i) adding native samples improved humor (raising the F1-score up to 6.76%) and sarcasm (raising the F1-score up to 8.64%) detection, (ii) training MLMs in an MTL framework boosted performance for both humour (raising the F1-score up to 10.67%) and sarcasm (increment up to 12.35% in F1-score) detection, and (iii) prompting and instruction finetuning VMLMs couldn't outperform the other approaches. Finally, our ablation studies and error analysis discovered the cases where our model is yet to improve. We provided our code for reproducibility."
arXiv cs.CL,Process-Supervised Reward Models for Verifying Clinical Note Generation: A Scalable Approach Guided by Domain Expertise,https://arxiv.org/abs/2412.12583,2025-09-09 04:00:00+0000,"arXiv:2412.12583v3 Announce Type: replace 
Abstract: Process-supervised reward models (PRMs) excel at providing step-by-step verification for large language model (LLM) outputs in domains like mathematics and coding. However, their application to fields lacking ground-truth answers, such as clinical note generation, poses significant challenges. We introduce a novel framework for training PRMs to deliver step-level reward signals for LLM-generated clinical notes. By precisely defining meaningful ""steps,"" injecting realistic ""errors"" informed by domain expertise, and leveraging LLMs to generate process supervision data at scale, we overcome previous limitations. Our PRM, built on LLaMA-3.1 8B, consistently outperforms proprietary reasoning and non-reasoning models, achieving state-of-the-art performance on two key evaluations: (1) distinguishing gold-standard from error-containing samples with 98.8% accuracy, and (2) selecting physician-preferred clinical notes with 56.2% accuracy. We investigate critical components for effective PRM training, including optimal loss functions and data selection strategies, and present a comprehensive physician reader study identifying predictors of downstream Best-of-N performance. Our study sheds light on unlocking the potential of PRMs for diverse generative tasks across domains."
arXiv cs.CL,Concept Bottleneck Large Language Models,https://arxiv.org/abs/2412.07992,2025-09-09 04:00:00+0000,"arXiv:2412.07992v4 Announce Type: replace 
Abstract: We introduce Concept Bottleneck Large Language Models (CB-LLMs), a novel framework for building inherently interpretable Large Language Models (LLMs). In contrast to traditional black-box LLMs that rely on limited post-hoc interpretations, CB-LLMs integrate intrinsic interpretability directly into the LLMs -- allowing accurate explanations with scalability and transparency. We build CB-LLMs for two essential NLP tasks: text classification and text generation. In text classification, CB-LLMs is competitive with, and at times outperforms, traditional black-box models while providing explicit and interpretable reasoning. For the more challenging task of text generation, interpretable neurons in CB-LLMs enable precise concept detection, controlled generation, and safer outputs. The embedded interpretability empowers users to transparently identify harmful content, steer model behavior, and unlearn undesired concepts -- significantly enhancing the safety, reliability, and trustworthiness of LLMs, which are critical capabilities notably absent in existing models. Our code is available at https://github.com/Trustworthy-ML-Lab/CB-LLMs."
arXiv cs.CL,Think-to-Talk or Talk-to-Think? When LLMs Come Up with an Answer in Multi-Hop Arithmetic Reasoning,https://arxiv.org/abs/2412.01113,2025-09-09 04:00:00+0000,"arXiv:2412.01113v3 Announce Type: replace 
Abstract: This study investigates the incremental, internal problem-solving process of language models (LMs) with arithmetic multi-hop reasoning as a case study. We specifically investigate when LMs internally resolve sub/whole problems through first reading the problem statements, generating reasoning chains, and achieving the final answer to mechanistically interpret LMs' multi-hop problem-solving process. Our experiments reveal a systematic incremental reasoning strategy underlying LMs. They have not derived an answer at the moment they first read the problem; instead, they obtain (sub)answers while generating the reasoning chain. Therefore, the generated reasoning chains can be regarded as faithful reflections of the model's internal computation."
arXiv cs.CL,ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual Question Answering?,https://arxiv.org/abs/2412.00102,2025-09-09 04:00:00+0000,"arXiv:2412.00102v2 Announce Type: replace-cross 
Abstract: Multi-modal Large Language Models (MLLMs) are gaining significant attention for their ability to process multi-modal data, providing enhanced contextual understanding of complex problems. MLLMs have demonstrated exceptional capabilities in tasks such as Visual Question Answering (VQA); however, they often struggle with fundamental engineering problems, and there is a scarcity of specialized datasets for training on topics like digital electronics. To address this gap, we propose a benchmark dataset called ElectroVizQA specifically designed to evaluate MLLMs' performance on digital electronic circuit problems commonly found in undergraduate curricula. This dataset, the first of its kind tailored for the VQA task in digital electronics, comprises approximately 626 visual questions, offering a comprehensive overview of digital electronics topics. This paper rigorously assesses the extent to which MLLMs can understand and solve digital electronic circuit questions, providing insights into their capabilities and limitations within this specialized domain. By introducing this benchmark dataset, we aim to motivate further research and development in the application of MLLMs to engineering education, ultimately bridging the performance gap and enhancing the efficacy of these models in technical fields."
arXiv cs.CL,Fine-Tuning Large Language Models for Scientific Text Classification: A Comparative Study,https://arxiv.org/abs/2412.00098,2025-09-09 04:00:00+0000,"arXiv:2412.00098v2 Announce Type: replace 
Abstract: The exponential growth of online textual content across diverse domains has necessitated advanced methods for automated text classification. Large Language Models (LLMs) based on transformer architectures have shown significant success in this area, particularly in natural language processing (NLP) tasks. However, general-purpose LLMs often struggle with domain-specific content, such as scientific texts, due to unique challenges like specialized vocabulary and imbalanced data. In this study, we fine-tune four state-of-the-art LLMs BERT, SciBERT, BioBERT, and BlueBERT on three datasets derived from the WoS-46985 dataset to evaluate their performance in scientific text classification. Our experiments reveal that domain-specific models, particularly SciBERT, consistently outperform general-purpose models in both abstract-based and keyword-based classification tasks. Additionally, we compare our achieved results with those reported in the literature for deep learning models, further highlighting the advantages of LLMs, especially when utilized in specific domains. The findings emphasize the importance of domain-specific adaptations for LLMs to enhance their effectiveness in specialized text classification tasks."
arXiv cs.CL,Lessons from Studying Two-Hop Latent Reasoning,https://arxiv.org/abs/2411.16353,2025-09-09 04:00:00+0000,"arXiv:2411.16353v3 Announce Type: replace 
Abstract: Large language models can use chain-of-thought (CoT) to externalize reasoning, potentially enabling oversight of capable LLM agents. Prior work has shown that models struggle at two-hop question-answering without CoT. This capability is so basic that if it was a fundamental limitation, it would imply that many complex agentic tasks would similarly require CoT. We investigate LLM latent reasoning capabilities using two-hop question answering as a case study. Previous work on the gap between latent and externalized two-hop reasoning produced mixed evidence with inconclusive results. In this paper, we introduce a controlled setting for investigating two-hop reasoning in LLMs, where a positive result provides definitive evidence for latent reasoning. We fine-tune LLMs (including Llama 3 8B and GPT-4o) on synthetic facts and test two-hop reasoning over these facts. By using synthetic facts, we rule out memorization and reasoning shortcuts as explanations for two-hop performance. We observe a nuanced picture: Models fail to compose two synthetic facts, but can succeed when one fact is synthetic and the other is natural. These results demonstrate that LLMs are undeniably capable of latent two-hop reasoning, although it remains unclear how this ability scales with model size. Finally, we highlight a lesson for researchers studying LLM reasoning: when drawing conclusions about LLM latent reasoning, one must be careful to avoid both spurious successes (that stem from memorization and reasoning shortcuts) and spurious failures (that may stem from artificial experimental setups, divorced from training setups of frontier LLMs)."
arXiv cs.CL,HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals,https://arxiv.org/abs/2411.07152,2025-09-09 04:00:00+0000,"arXiv:2411.07152v2 Announce Type: replace 
Abstract: Task-Oriented Dialogue (TOD) systems assist users in completing tasks through natural language interactions, often relying on a single-layered workflow structure for slot-filling in public tasks, such as hotel bookings. However, in enterprise environments, which involve rich domain-specific knowledge, TOD systems face challenges due to task complexity and the lack of standardized documentation. In this work, we introduce HierTOD, an enterprise TOD system driven by hierarchical goals that can support composite workflows. By focusing on goal-driven interactions, our system serves a more proactive role, facilitating mixed-initiative dialogue and improving task completion. Equipped with components for natural language understanding, composite goal retriever, dialogue management, and response generation, backed by a well-organized data service with domain knowledge base and retrieval engine, HierTOD delivers efficient task assistance as judged by human evaluators. Furthermore, our system implementation unifies two TOD paradigms: slot-filling for information collection and step-by-step guidance for task execution. Our user study demonstrates the effectiveness and helpfulness of HierTOD in performing both paradigms."
arXiv cs.CL,Exploring the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal,https://arxiv.org/abs/2411.05665,2025-09-09 04:00:00+0000,"arXiv:2411.05665v2 Announce Type: replace 
Abstract: This paper sheds light on the limitations of Large Language Models (LLMs) by rigorously evaluating their ability to process masked text. We introduce two novel tasks: MskQA, measuring reasoning on masked question-answering datasets like RealtimeQA, and MskCal, assessing numerical reasoning on masked arithmetic problems.Testing GPT-4o and 4o-mini reveals that while LLMs exhibit some resilience to masked text, their performance is highly contingent on masking rates and semantic cues. Specifically, ""solid masking,"" where semantic clues are entirely absent, leads to a significant performance drop compared to ""partial lifting,"" where some semantic information is retained, indicating LLMs' reliance on surface-level patterns. Interestingly, GPT-4o consistently outperforms 4o-mini, particularly in MskCal, demonstrating a greater ability to handle numerical reasoning with masked text. This underscores the crucial role of semantic cues in the reasoning process of LLMs. Our study illuminates the interplay between background knowledge and reasoning ability in masked text processing, paving the way for a deeper understanding of LLM capabilities and limitations, and highlighting the need for more robust evaluation methods to accurately assess their true comprehension abilities."
arXiv cs.CL,GASE: Generatively Augmented Sentence Encoding,https://arxiv.org/abs/2411.04914,2025-09-09 04:00:00+0000,"arXiv:2411.04914v2 Announce Type: replace 
Abstract: We propose a training-free approach to improve sentence embeddings leveraging test-time compute by applying generative text models for data augmentation at inference time. Unlike conventional data augmentation that utilises synthetic training data, our approach does not require access to model parameters or the computational resources typically required for fine-tuning state-of-the-art models. Generatively Augmented Sentence Encoding variates the input text by paraphrasing, summarising, or extracting keywords, followed by pooling the original and synthetic embeddings. Experimental results on the Massive Text Embedding Benchmark for Semantic Textual Similarity (STS) demonstrate performance improvements across a range of embedding models using different generative models for augmentation. We find that generative augmentation leads to larger performance improvements for embedding models with lower baseline performance. These findings suggest that integrating generative augmentation at inference time adds semantic diversity and can enhance the robustness and generalisability of sentence embeddings for embedding models. Our results show that performance gains depend on the embedding model and the dataset."
arXiv cs.CL,ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries,https://arxiv.org/abs/2410.14748,2025-09-09 04:00:00+0000,"arXiv:2410.14748v4 Announce Type: replace-cross 
Abstract: Recent advancements in large language models (LLMs) have significantly enhanced their ability to understand both natural language and code, driving their use in tasks like natural language-to-code (NL2Code) and code summarisation. However, LLMs are prone to hallucination, outputs that stray from intended meanings. Detecting hallucinations in code summarisation is especially difficult due to the complex interplay between programming and natural languages. We introduce a first-of-its-kind dataset, CodeSumEval, with ~10K samples, curated specifically for hallucination detection in code summarisation. We further propose a novel Entity Tracing Framework (ETF) that a) utilises static program analysis to identify code entities from the program and b) uses LLMs to map and verify these entities and their intents within generated code summaries. Our experimental analysis demonstrates the framework's effectiveness, leading to a 73% F1 score. The proposed approach provides a method for detecting hallucinations by tracing entities from the summary to the code, allowing us to evaluate summary accuracy and localise the error within the summary."
arXiv cs.CL,Conversational Code Generation: a Case Study of Designing a Dialogue System for Generating Driving Scenarios for Testing Autonomous Vehicles,https://arxiv.org/abs/2410.09829,2025-09-09 04:00:00+0000,"arXiv:2410.09829v3 Announce Type: replace 
Abstract: Cyber-physical systems like autonomous vehicles are tested in simulation before deployment, using domain-specific programs for scenario specification. To aid the testing of autonomous vehicles in simulation, we design a natural language interface, using an instruction-following large language model, to assist a non-coding domain expert in synthesising the desired scenarios and vehicle behaviours. We show that using it to convert utterances to the symbolic program is feasible, despite the very small training dataset. Human experiments show that dialogue is critical to successful simulation generation, leading to a 4.5 times higher success rate than a generation without engaging in extended conversation."
arXiv cs.CL,Extracting and Combining Abilities For Building Multi-lingual Ability-enhanced Large Language Models,https://arxiv.org/abs/2410.07825,2025-09-09 04:00:00+0000,"arXiv:2410.07825v3 Announce Type: replace 
Abstract: Multi-lingual ability transfer has become increasingly important for the broad application of large language models (LLMs). Existing work highly relies on training with the multi-lingual ability-related data, which may not be available for low-resource languages. To solve it, we propose a Multi-lingual Abilities Extraction and Combination approach, named as MAEC. Our key idea is to decompose and extract language-agnostic ability-related weights from LLMs, and combine them across different languages by simple addition and subtraction operations without training. Specifically, our MAEC consists of the extraction and combination stages. In the extraction stage, we firstly locate key neurons that are highly related to specific abilities, and then employ them to extract the transferable ability-related weights. In the combination stage, we further select the ability-related tensors that mitigate the linguistic effects, and design a combining strategy based on them and the language-specific weights, to build the multi-lingual ability-enhanced LLM. To assess the effectiveness of our approach, we conduct extensive experiments on LLaMA-3 8B on mathematical and scientific tasks in both high-resource and low-resource lingual scenarios. Experiment results have shown that MAEC can effectively and efficiently extract and combine the advanced abilities, achieving comparable performance with PaLM. Resources are available at https://github.com/RUCAIBox/MAET."
arXiv cs.CL,Causal Representation Learning with Generative Artificial Intelligence: Application to Texts as Treatments,https://arxiv.org/abs/2410.00903,2025-09-09 04:00:00+0000,"arXiv:2410.00903v4 Announce Type: replace-cross 
Abstract: In this paper, we demonstrate how to enhance the validity of causal inference with unstructured high-dimensional treatments like texts, by leveraging the power of generative Artificial Intelligence (GenAI). Specifically, we propose to use a deep generative model such as large language models (LLMs) to efficiently generate treatments and use their internal representation for subsequent causal effect estimation. We show that the knowledge of this true internal representation helps disentangle the treatment features of interest, such as specific sentiments and certain topics, from other possibly unknown confounding features. Unlike existing methods, the proposed GenAI-Powered Inference (GPI) methodology eliminates the need to learn causal representation from the data, and hence produces more accurate and efficient estimates. We formally establish the conditions required for the nonparametric identification of the average treatment effect, propose an estimation strategy that avoids the violation of the overlap assumption, and derive the asymptotic properties of the proposed estimator through the application of double machine learning. Finally, using an instrumental variables approach, we extend the proposed GPI methodology to the settings in which the treatment feature is based on human perception. The GPI is also applicable to text reuse where an LLM is used to regenerate existing texts. We conduct simulation and empirical studies, using the generated text data from an open-source LLM, Llama~3, to illustrate the advantages of our estimator over state-of-the-art causal representation learning algorithms."
arXiv cs.CL,BeSimulator: A Large Language Model Powered Text-based Behavior Simulator,https://arxiv.org/abs/2409.15865,2025-09-09 04:00:00+0000,"arXiv:2409.15865v2 Announce Type: replace-cross 
Abstract: Traditional robot simulators focus on physical process modeling and realistic rendering, often suffering from high computational costs, inefficiencies, and limited adaptability. To handle this issue, we concentrate on behavior simulation in robotics to analyze and validate the logic behind robot behaviors, aiming to achieve preliminary evaluation before deploying resource-intensive simulators and thus enhance simulation efficiency. In this paper, we propose BeSimulator, a modular and novel LLM-powered framework, as an attempt towards behavior simulation in the context of text-based environments. By constructing text-based virtual environments and performing semantic-level simulation, BeSimulator can generalize across scenarios and achieve long-horizon complex simulation. Inspired by human cognition paradigm, it employs a ``consider-decide-capture-transfer'' four-phase simulation process, termed Chain of Behavior Simulation (CBS), which excels at analyzing action feasibility and state transition. Additionally, BeSimulator incorporates code-driven reasoning to enable arithmetic operations and enhance reliability, and reflective feedback to refine simulation. Based on our manually constructed behavior-tree-based simulation benchmark, BTSIMBENCH, our experiments show a significant performance improvement in behavior simulation compared to baselines, ranging from 13.60% to 24.80%. Code and data are available at https://github.com/Dawn888888/BeSimulator."
arXiv cs.CL,Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming,https://arxiv.org/abs/2409.11041,2025-09-09 04:00:00+0000,"arXiv:2409.11041v4 Announce Type: replace 
Abstract: While there has been a lot of research recently on robots in household environments, at the present time, most robots in existence can be found on shop floors, and most interactions between humans and robots happen there. ``Collaborative robots'' (cobots) designed to work alongside humans on assembly lines traditionally require expert programming, limiting ability to make changes, or manual guidance, limiting expressivity of the resulting programs. To address these limitations, we explore using Large Language Models (LLMs), and in particular, their abilities of doing in-context learning, for conversational code generation. As a first step, we define RATS, the ``Repetitive Assembly Task'', a 2D building task designed to lay the foundation for simulating industry assembly scenarios. In this task, a `programmer' instructs a cobot, using natural language, on how a certain assembly is to be built; that is, the programmer induces a program, through natural language. We create a dataset that pairs target structures with various example instructions (human-authored, template-based, and model-generated) and example code. With this, we systematically evaluate the capabilities of state-of-the-art LLMs for synthesising this kind of code, given in-context examples. Evaluating in a simulated environment, we find that LLMs are capable of generating accurate `first order code' (instruction sequences), but have problems producing `higher-order code' (abstractions such as functions, or use of loops)."
arXiv cs.CL,Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context Learning,https://arxiv.org/abs/2408.16482,2025-09-09 04:00:00+0000,"arXiv:2408.16482v2 Announce Type: replace 
Abstract: Improving the alignment of Large Language Models (LLMs) with respect to the cultural values that they encode has become an increasingly important topic. In this work, we study whether we can exploit existing knowledge about cultural values at inference time to adjust model responses to cultural value probes. We present a simple and inexpensive method that uses a combination of in-context learning (ICL) and human survey data, and show that we can improve the alignment to cultural values across 5 models that include both English-centric and multilingual LLMs. Importantly, we show that our method could prove useful in test languages other than English and can improve alignment to the cultural values that correspond to a range of culturally diverse countries."
arXiv cs.CL,Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective,https://arxiv.org/abs/2408.04638,2025-09-09 04:00:00+0000,"arXiv:2408.04638v2 Announce Type: replace 
Abstract: Affective Computing (AC) integrates computer science, psychology, and cognitive science to enable machines to recognize, interpret, and simulate human emotions across domains such as social media, finance, healthcare, and education. AC commonly centers on two task families: Affective Understanding (AU) and Affective Generation (AG). While fine-tuned pre-trained language models (PLMs) have achieved solid AU performance, they often generalize poorly across tasks and remain limited for AG, especially in producing diverse, emotionally appropriate responses. The advent of Large Language Models (LLMs) (e.g., ChatGPT and LLaMA) has catalyzed a paradigm shift by offering in-context learning, broader world knowledge, and stronger sequence generation. This survey presents an NLP-oriented overview of AC in the LLM era. We (i) consolidate traditional AC tasks and preliminary LLM-based studies; (ii) review adaptation techniques that improve AU/AG, including Instruction Tuning (full and parameter-efficient methods such as LoRA, P-/Prompt-Tuning), Prompt Engineering (zero/few-shot, chain-of-thought, agent-based prompting), and Reinforcement Learning. For the latter, we summarize RL from human preferences (RLHF), verifiable/programmatic rewards (RLVR), and AI feedback (RLAIF), which provide preference- or rule-grounded optimization signals that can help steer AU/AG toward empathy, safety, and planning, achieving finer-grained or multi-objective control. To assess progress, we compile benchmarks and evaluation practices for both AU and AG. We also discuss open challenges-from ethics, data quality, and safety to robust evaluation and resource efficiency-and outline research directions. We hope this survey clarifies the landscape and offers practical guidance for building affect-aware, reliable, and responsible LLM systems."
arXiv cs.CL,A Principled Framework for Evaluating on Typologically Diverse Languages,https://arxiv.org/abs/2407.05022,2025-09-09 04:00:00+0000,"arXiv:2407.05022v3 Announce Type: replace 
Abstract: Beyond individual languages, multilingual natural language processing (NLP) research increasingly aims to develop models that perform well across languages generally. However, evaluating these systems on all the world's languages is practically infeasible. To attain generalizability, representative language sampling is essential. Previous work argues that generalizable multilingual evaluation sets should contain languages with diverse typological properties. However, 'typologically diverse' language samples have been found to vary considerably in this regard, and popular sampling methods are flawed and inconsistent. We present a language sampling framework for selecting highly typologically diverse languages given a sampling frame, informed by language typology. We compare sampling methods with a range of metrics and find that our systematic methods consistently retrieve more typologically diverse language selections than previous methods in NLP. Moreover, we provide evidence that this affects generalizability in multilingual model evaluation, emphasizing the importance of diverse language sampling in NLP evaluation."
arXiv cs.CL,ResearchArena: Benchmarking Large Language Models' Ability to Collect and Organize Information as Research Agents,https://arxiv.org/abs/2406.10291,2025-09-09 04:00:00+0000,"arXiv:2406.10291v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) excel across many natural language processing tasks but face challenges in domain-specific, analytical tasks such as conducting research surveys. This study introduces ResearchArena, a benchmark designed to evaluate LLMs' capabilities in conducting academic surveys -- a foundational step in academic research. ResearchArena models the process in three stages: (1) information discovery, identifying relevant literature; (2) information selection, evaluating papers' relevance and impact; and (3) information organization, structuring knowledge into hierarchical frameworks such as mind-maps. Notably, mind-map construction is treated as a bonus task, reflecting its supplementary role in survey-writing. To support these evaluations, we construct an offline environment of 12M full-text academic papers and 7.9K survey papers. To ensure ethical compliance, we do not redistribute copyrighted materials; instead, we provide code to construct the environment from the Semantic Scholar Open Research Corpus (S2ORC). Preliminary evaluations reveal that LLM-based approaches underperform compared to simpler keyword-based retrieval methods, though recent reasoning models such as DeepSeek-R1 show slightly better zero-shot performance. These results underscore significant opportunities for advancing LLMs in autonomous research. We open-source the code to construct the ResearchArena benchmark at https://github.com/cxcscmu/ResearchArena."
arXiv cs.CL,MedualTime: A Dual-Adapter Language Model for Medical Time Series-Text Multimodal Learning,https://arxiv.org/abs/2406.06620,2025-09-09 04:00:00+0000,"arXiv:2406.06620v4 Announce Type: replace-cross 
Abstract: The recent rapid advancements in language models (LMs) have garnered attention in medical time series-text multimodal learning. However, existing contrastive learning-based and prompt-based LM approaches tend to be biased, often assigning a primary role to time series modality while treating text modality as secondary. We classify these approaches under a temporal-primary paradigm, which may overlook the unique and critical task-relevant information embedded in text modality like clinical reports, thus failing to fully leverage mutual benefits and complementarity of different modalities. To fill this gap, we propose a novel textual-temporal multimodal learning paradigm that enables either modality to serve as the primary while being enhanced by the other, thereby effectively capturing modality-specific information and fostering cross-modal interaction. In specific, we design MedualTime, a language model composed of dual adapters to implement temporal-primary and textual-primary modeling simultaneously. Within each adapter, lightweight adaptation tokens are injected into the top layers of LM to encourage high-level modality fusion. The shared LM pipeline by dual adapters not only achieves adapter alignment but also enables efficient fine-tuning, reducing computational resources. Empirically, MedualTime demonstrates superior performance on medical data, achieving notable improvements of 8% accuracy and 12% F1 in supervised settings. Furthermore, MedualTime's transferability is validated by few-shot label transfer experiments from coarse-grained to fine-grained medical data. https://github.com/start2020/MedualTime"
arXiv cs.CL,Transforming Wearable Data into Personal Health Insights using Large Language Model Agents,https://arxiv.org/abs/2406.06464,2025-09-09 04:00:00+0000,"arXiv:2406.06464v4 Announce Type: replace-cross 
Abstract: Deriving personalized insights from popular wearable trackers requires complex numerical reasoning that challenges standard LLMs, necessitating tool-based approaches like code generation. Large language model (LLM) agents present a promising yet largely untapped solution for this analysis at scale. We introduce the Personal Health Insights Agent (PHIA), a system leveraging multistep reasoning with code generation and information retrieval to analyze and interpret behavioral health data. To test its capabilities, we create and share two benchmark datasets with over 4000 health insights questions. A 650-hour human expert evaluation shows that PHIA significantly outperforms a strong code generation baseline, achieving 84% accuracy on objective, numerical questions and, for open-ended ones, earning 83% favorable ratings while being twice as likely to achieve the highest quality rating. This work can advance behavioral health by empowering individuals to understand their data, enabling a new era of accessible, personalized, and data-driven wellness for the wider population."
arXiv cs.CL,Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of Health for Clinical Text,https://arxiv.org/abs/2406.06056,2025-09-09 04:00:00+0000,"arXiv:2406.06056v3 Announce Type: replace 
Abstract: Social and behavioral determinants of health (SBDH) play a crucial role in health outcomes and are frequently documented in clinical text. Automatically extracting SBDH information from clinical text relies on publicly available good-quality datasets. However, existing SBDH datasets exhibit substantial limitations in their availability and coverage. In this study, we introduce Synth-SBDH, a novel synthetic dataset with detailed SBDH annotations, encompassing status, temporal information, and rationale across 15 SBDH categories. We showcase the utility of Synth-SBDH on three tasks using real-world clinical datasets from two distinct hospital settings, highlighting its versatility, generalizability, and distillation capabilities. Models trained on Synth-SBDH consistently outperform counterparts with no Synth-SBDH training, achieving up to 63.75% macro-F improvements. Additionally, Synth-SBDH proves effective for rare SBDH categories and under-resource constraints while being substantially cheaper than expert-annotated real-world data. Human evaluation reveals a 71.06% Human-LLM alignment and uncovers areas for future refinements."
arXiv cs.CL,Linearly Controlled Language Generation with Performative Guarantees,https://arxiv.org/abs/2405.15454,2025-09-09 04:00:00+0000,"arXiv:2405.15454v2 Announce Type: replace 
Abstract: The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM's latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model's hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. In particular, we propose to directly intervene the activations of the token that is being generated in embedding space in an online fashion. Crucially, we do not simply steer activations towards a desirable region. Instead, our method relies on classical techniques from control theory to precisely control activations in a context-dependent way, and guarantees that they are brought into a specific pre-defined region of embedding space that corresponds to allowed semantics. Our intervention is computed in closed-form according to an optimal controller formulation, minimally impacting generation time. This control of the activations in embedding space allows for fine-grained steering of attributes of the generated sequence. We demonstrate the effectiveness of our approach on different objectives-- toxicity avoidance and sentiment control-- while maintaining text quality."
arXiv cs.CL,Repetition Improves Language Model Embeddings,https://arxiv.org/abs/2402.15449,2025-09-09 04:00:00+0000,"arXiv:2402.15449v2 Announce Type: replace 
Abstract: Bidirectional models are considered essential for strong text embeddings. Recent approaches to adapt autoregressive language models (LMs) into strong text embedding models have largely had the requirement to modify the LM architecture to be bidirectional. We challenge this premise by introducing ""echo embeddings"" which converts autoregressive LMs into high quality text embedding models without changing the architecture or requiring fine-tuning. By repeating the input and extracting embeddings from the repeated tokens -- which have access to all original tokens -- echo embeddings improve over classical LM embeddings by over 5% in zero-shot settings. Our zero-shot embeddings nearly match those obtained by bidirectionally-converted LMs that undergo additional masked-language modeling training. Echo embeddings are also compatible with supervised fine-tuning, matching or outperforming bidirectionally-converted LMs in an apples-to-apples comparison, even with an identical compute budget during training and inference. Overall, repetition is a simple and effective strategy to circumvent the need for bidirectional attention in embedding models, paving the way towards a unified architecture for all NLP tasks."
arXiv cs.CL,AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling,https://arxiv.org/abs/2402.12226,2025-09-09 04:00:00+0000,"arXiv:2402.12226v5 Announce Type: replace 
Abstract: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages. We build a multimodal text-centric dataset for multimodal alignment pre-training. Utilizing generative models, we synthesize the first large-scale any-to-any multimodal instruction dataset. It consists of 108k samples of multi-turn conversations that intricately interweave various modalities, thus equipping the model to handle arbitrary combinations of multimodal inputs and outputs. Experimental results demonstrate that AnyGPT is capable of facilitating any-to-any multimodal conversation while achieving performance comparable to specialized models across all modalities, proving that discrete representations can effectively and conveniently unify multiple modalities within a language model. Demos are shown in https://junzhan2000.github.io/AnyGPT.github.io/"
arXiv cs.CL,Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation,https://arxiv.org/abs/2311.01766,2025-09-09 04:00:00+0000,"arXiv:2311.01766v5 Announce Type: replace 
Abstract: Mis- and disinformation online have become a major societal problem as major sources of online harms of different kinds. One common form of mis- and disinformation is out-of-context (OOC) information, where different pieces of information are falsely associated, e.g., a real image combined with a false textual caption or a misleading textual description. Although some past studies have attempted to defend against OOC mis- and disinformation through external evidence, they tend to disregard the role of different pieces of evidence with different stances. Motivated by the intuition that the stance of evidence represents a bias towards different detection results, we propose a stance extraction network (SEN) that can extract the stances of different pieces of multi-modal evidence in a unified framework. Moreover, we introduce a support-refutation score calculated based on the co-occurrence relations of named entities into the textual SEN. Extensive experiments on a public large-scale dataset demonstrated that our proposed method outperformed the state-of-the-art baselines, with the best model achieving a performance gain of 3.2% in accuracy. The source code and checkpoints are publicly available at https://github.com/yx3266/SEN."
arXiv cs.CL,Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation,https://arxiv.org/abs/2309.14394,2025-09-09 04:00:00+0000,"arXiv:2309.14394v2 Announce Type: replace 
Abstract: In this work, we address the challenge of multi-domain translation, where the objective is to learn mappings between arbitrary configurations of domains within a defined set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for three domains) without the need for separate models for each specific translation configuration, enabling more efficient and flexible domain translation. We introduce Multi-Domain Diffusion (MDD), a method with dual purposes: i) reconstructing any missing views for new data objects, and ii) enabling learning in semi-supervised contexts with arbitrary supervision configurations. MDD achieves these objectives by exploiting the noise formulation of diffusion models, specifically modeling one noise level per domain. Similar to existing domain translation approaches, MDD learns the translation between any combination of domains. However, unlike prior work, our formulation inherently handles semi-supervised learning without modification by representing missing views as noise in the diffusion process. We evaluate our approach through domain translation experiments on BL3NDT, a multi-domain synthetic dataset designed for challenging semantic domain inversion, the BraTS2020 dataset, and the CelebAMask-HQ dataset."
NVIDIA Technical Blog,How to Build AI Systems In House with Outerbounds and DGX Cloud Lepton,https://developer.nvidia.com/blog/how-to-build-ai-systems-in-house-with-outerbounds-and-dgx-cloud-lepton/,2025-09-08 16:00:00+0000,"It’s easy to underestimate how many moving parts a real-world, production-grade AI system involves. Whether you're building an agent that combines internal..."
NVIDIA Technical Blog,How to Build AI Systems In House with Outerbounds and DGX Cloud Lepton,https://developer.nvidia.com/blog/how-to-build-ai-systems-in-house-with-outerbounds-and-dgx-cloud-lepton,2025-09-08 16:00:00+0000,"It’s easy to underestimate how many moving parts a real-world, production-grade AI system involves. Whether you're building an agent that combines internal..."
MIT Technology Review (All),The Download: introducing our 35 Innovators Under 35 list for 2025,https://www.technologyreview.com/2025/09/08/1123361/the-download-introducing-our-35-innovators-under-35-list-for-2025/,2025-09-08 12:10:00+0000,"This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Introducing: our 35 Innovators Under 35 list for 2025 The world is full of extraordinary young people brimming with ideas for how to crack tough problems. Every year, we recognize 35 such individuals…"
MIT Technology Review (All),Why basic science deserves our boldest investment,https://www.technologyreview.com/2025/09/08/1123214/opinion-basic-science-research-funding/,2025-09-08 10:45:00+0000,"In December 1947, three physicists at Bell Telephone Laboratories—John Bardeen, William Shockley, and Walter Brattain—built a compact electronic device using thin gold wires and a piece of germanium, a material known as a semiconductor. Their invention, later named the transistor (for which they were awarded the Nobel Prize in 1956), could amplify and switch electrical…"
MIT Technology Review (All),How Yichao “Peak” Ji became a global AI app hitmaker,https://www.technologyreview.com/2025/09/08/1122642/ji-peak-yichao-innovator-manus-app-ai/,2025-09-08 10:30:00+0000,"Yichao “Peak” Ji is one of MIT Technology Review’s 2025 Innovators Under 35. Meet the rest of this year’s honorees.  When Yichao Ji—also known as “Peak”—appeared in a launch video for Manus in March, he didn’t expect it to go viral. Speaking in fluent English, the 32-year-old introduced the AI agent built by Chinese startup Butterfly…"
NVIDIA Technical Blog,Register for the Global Webinar: How to Prepare for NVIDIA Generative AI Certification,https://nvda.ws/4g1w81S,2025-09-07 15:00:00+0000,"Join a global webinar on Oct. 7 to get everything you need to succeed on the NVIDIA generative-AI certification exams, including the new professional level..."
MIT Technology Review (All),"The Download: longevity myths, and sewer-cleaning robots",https://www.technologyreview.com/2025/09/05/1123207/the-download-longevity-myths-and-sewer-cleaning-robots/,2025-09-05 12:10:00+0000,"This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Putin says organ transplants could grant immortality. Not quite. —Jessica Hamzelou Earlier this week, my editor forwarded me a video of the leaders of Russia and China talking about immortality. “These days at…"
MIT Technology Review (All),Imagining the future of banking with agentic AI,https://www.technologyreview.com/2025/09/04/1123023/imagining-the-future-of-banking-with-agentic-ai/,2025-09-04 16:21:23+0000,"Agentic AI is coming of age. And with it comes new opportunities in the financial services sector. Banks are increasingly employing agentic AI to optimize processes, navigate complex systems, and sift through vast quantities of unstructured data to make decisions and take actions—with or without human involvement. “With the maturing of agentic AI, it is…"
MIT Technology Review (All),"The Download: unnerving AI avatars, and Trump’s climate gift to China",https://www.technologyreview.com/2025/09/04/1123066/the-download-unnerving-ai-avatars-and-trumps-climate-gift-to-china/,2025-09-04 12:10:00+0000,"This is today’s edition of The Download, our weekday newsletter that provides a daily dose of what’s going on in the world of technology. Synthesia’s AI clones are more expressive than ever. Soon they’ll be able to talk back. —Rhiannon Williams Earlier this summer, I visited the AI company Synthesia to give it what it needed to…"
NVIDIA Technical Blog,How to Run AI-Powered CAE Simulations,https://developer.nvidia.com/blog/how-to-run-ai-powered-cae-simulations/,2025-09-03 16:09:47+0000,"In modern engineering, the pace of innovation is closely linked to the ability to perform accelerated simulations. Computer-aided engineering (CAE) plays a..."
NVIDIA Technical Blog,How to Run AI-Powered CAE Simulations,https://developer.nvidia.com/blog/how-to-run-ai-powered-cae-simulations,2025-09-03 16:09:47+0000,"In modern engineering, the pace of innovation is closely linked to the ability to perform accelerated simulations. Computer-aided engineering (CAE) plays a..."
NVIDIA Technical Blog,North–South Networks: The Key to Faster Enterprise AI Workloads,https://developer.nvidia.com/blog/north-south-networks-the-key-to-faster-enterprise-ai-workloads/,2025-09-03 15:04:24+0000,"In AI infrastructure, data fuels the compute engine. With evolving agentic AI systems, where multiple models and services interact, fetch external context, and..."
NVIDIA Technical Blog,North–South Networks: The Key to Faster Enterprise AI Workloads,https://developer.nvidia.com/blog/north-south-networks-the-key-to-faster-enterprise-ai-workloads,2025-09-03 15:04:24+0000,"In AI infrastructure, data fuels the compute engine. With evolving agentic AI systems, where multiple models and services interact, fetch external context, and..."
NVIDIA Technical Blog,Cut Model Deployment Costs While Keeping Performance With GPU Memory Swap,https://developer.nvidia.com/blog/cut-model-deployment-costs-while-keeping-performance-with-gpu-memory-swap/,2025-09-02 18:44:27+0000,"Deploying large language models (LLMs) at scale presents a dual challenge: ensuring fast responsiveness during high demand, while managing the costs of GPUs...."
NVIDIA Technical Blog,Cut Model Deployment Costs While Keeping Performance With GPU Memory Swap,https://developer.nvidia.com/blog/cut-model-deployment-costs-while-keeping-performance-with-gpu-memory-swap,2025-09-02 18:44:27+0000,"Deploying large language models (LLMs) at scale presents a dual challenge: ensuring fast responsiveness during high demand, while managing the costs of GPUs...."
NVIDIA Technical Blog,Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training,https://developer.nvidia.com/blog/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-training/,2025-08-29 14:47:04+0000,"Major open-source foundational model releases are an exciting time for the AI community, bringing unique architectural innovations and capabilities. As the..."
NVIDIA Technical Blog,Fine-Tuning gpt-oss for Accuracy and Performance with Quantization Aware Training,https://developer.nvidia.com/blog/fine-tuning-gpt-oss-for-accuracy-and-performance-with-quantization-aware-training,2025-08-29 14:47:04+0000,"Major open-source foundational model releases are an exciting time for the AI community, bringing unique architectural innovations and capabilities. As the..."
NVIDIA Technical Blog,"How to Scale Your LangGraph Agents in Production From A Single User to 1,000 Coworkers",https://developer.nvidia.com/blog/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000-coworkers/,2025-08-27 16:00:00+0000,"You’ve built a powerful AI agent and are ready to share it with your colleagues, but have one big fear: Will the agent work if 10, 100, or even 1,000..."
NVIDIA Technical Blog,"How to Scale Your LangGraph Agents in Production From A Single User to 1,000 Coworkers",https://developer.nvidia.com/blog/how-to-scale-your-langgraph-agents-in-production-from-a-single-user-to-1000-coworkers,2025-08-27 16:00:00+0000,"You’ve built a powerful AI agent and are ready to share it with your colleagues, but have one big fear: Will the agent work if 10, 100, or even 1,000..."
TechCrunch AI,How one AI startup is helping rice farmers battle climate change,https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/,2025-08-26 15:21:19+0000,Mitti Labs is working with The Nature Conservancy to expand the use of climate-friendly rice farming practices in India. The startup uses its AI to verify reductions in methane emissions.
NVIDIA Technical Blog,NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit,https://developer.nvidia.com/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit/,2025-08-25 17:59:23+0000,"In recent years, AI workloads have grown exponentially—not only in the deployment of large language models (LLMs) but also in the demand to process ever more..."
NVIDIA Technical Blog,NVFP4 Trains with Precision of 16-Bit and Speed and Efficiency of 4-Bit,https://developer.nvidia.com/blog/nvfp4-trains-with-precision-of-16-bit-and-speed-and-efficiency-of-4-bit,2025-08-25 17:59:23+0000,"In recent years, AI workloads have grown exponentially—not only in the deployment of large language models (LLMs) but also in the demand to process ever more..."
NVIDIA Technical Blog,"Introducing NVIDIA Jetson Thor, the Ultimate Platform for Physical AI",https://developer.nvidia.com/blog/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai/,2025-08-25 17:57:00+0000,"Robotics is undergoing a revolution, moving beyond the era of specialist machines to generalist robotics. This shift moves away from single-purpose,..."
NVIDIA Technical Blog,"Introducing NVIDIA Jetson Thor, the Ultimate Platform for Physical AI",https://developer.nvidia.com/blog/introducing-nvidia-jetson-thor-the-ultimate-platform-for-physical-ai,2025-08-25 17:57:00+0000,"Robotics is undergoing a revolution, moving beyond the era of specialist machines to generalist robotics. This shift moves away from single-purpose,..."
NVIDIA Technical Blog,Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era,https://developer.nvidia.com/blog/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era/,2025-08-22 17:58:00+0000,"As the latest member of the NVIDIA Blackwell architecture family, the NVIDIA Blackwell Ultra GPU builds on core innovations to accelerate training and AI..."
NVIDIA Technical Blog,Inside NVIDIA Blackwell Ultra: The Chip Powering the AI Factory Era,https://developer.nvidia.com/blog/inside-nvidia-blackwell-ultra-the-chip-powering-the-ai-factory-era,2025-08-22 17:58:00+0000,"As the latest member of the NVIDIA Blackwell architecture family, the NVIDIA Blackwell Ultra GPU builds on core innovations to accelerate training and AI..."
NVIDIA Technical Blog,NVIDIA Hardware Innovations and Open Source Contributions Are Shaping AI,https://developer.nvidia.com/blog/nvidia-hardware-innovations-and-open-source-contributions-are-shaping-ai/,2025-08-22 15:00:00+0000,"Open source AI models such as Cosmos, DeepSeek, Gemma, GPT-OSS, Llama, Nemotron, Phi, Qwen, and many more are the foundation of AI innovation. These models are..."
NVIDIA Technical Blog,NVIDIA Hardware Innovations and Open Source Contributions Are Shaping AI,https://developer.nvidia.com/blog/nvidia-hardware-innovations-and-open-source-contributions-are-shaping-ai,2025-08-22 15:00:00+0000,"Open source AI models such as Cosmos, DeepSeek, Gemma, GPT-OSS, Llama, Nemotron, Phi, Qwen, and many more are the foundation of AI innovation. These models are..."
Apple ML Research,SlowFast-LLaVA-1.5: A Family of Token-Efficient Video Large Language Models for Long-Form Video Understanding,https://machinelearning.apple.com/research/slowfast-llava,2025-08-22 00:00:00+0000,"We introduce SlowFast-LLaVA-1.5 (abbreviated as SF-LLaVA-1.5), a family of video large language models (LLMs) offering a token-efficient solution for long-form video understanding. We incorporate the two-stream SlowFast mechanism into a streamlined training pipeline, and perform joint video-image training on a carefully curated data mixture of only publicly available datasets. Our primary focus is on highly efficient model scales (1B and 3B), demonstrating that even relatively small Video LLMs can achieve state-of-the-art performance on video understanding, meeting the demand for…"
Apple ML Research,Checklists Are Better Than Reward Models For Aligning Language Models,https://machinelearning.apple.com/research/checklists-are-better,2025-08-22 00:00:00+0000,"Language models must be adapted to understand and follow user instructions. Reinforcement learning is widely used to facilitate this -- typically using fixed criteria such as ""helpfulness"" and ""harmfulness"". In our work, we instead propose using flexible, instruction-specific criteria as a means of broadening the impact that reinforcement learning can have in eliciting instruction following. We propose ""Reinforcement Learning from Checklist Feedback"" (RLCF). From instructions, we extract checklists and evaluate how well responses satisfy each item - using both AI judges and specialized…"
TechCrunch AI,Harvard dropouts to launch ‘always on’ AI smart glasses that listen and record every conversation,https://techcrunch.com/2025/08/20/harvard-dropouts-to-launch-always-on-ai-smart-glasses-that-listen-and-record-every-conversation/,2025-08-20 16:00:00+0000,"After developing a facial-recognition app for Meta’s Ray-Ban glasses and doxing random people, two former Harvard students are now launching a startup that makes smart glasses with an always-on microphone."
TechCrunch AI,Meta to add 100MW of solar power from US gear,https://techcrunch.com/2025/08/20/meta-to-add-100-mw-of-solar-power-from-u-s-gear/,2025-08-20 15:56:53+0000,The social media company is adding another tranche of solar to power a new AI data center in South Carolina.
NVIDIA Technical Blog,Reinforcement Learning with NVIDIA NeMo-RL: Megatron-Core Support for Optimized Training Throughput,https://developer.nvidia.com/blog/reinforcement-learning-with-nvidia-nemo-rl-megatron-core-support-for-optimized-training-throughput/,2025-08-20 15:15:16+0000,The initial release of NVIDIA NeMo-RL included training support through PyTorch DTensor (otherwise known as FSDP2). This backend enables native integration with...
NVIDIA Technical Blog,Reinforcement Learning with NVIDIA NeMo-RL: Megatron-Core Support for Optimized Training Throughput,https://developer.nvidia.com/blog/reinforcement-learning-with-nvidia-nemo-rl-megatron-core-support-for-optimized-training-throughput,2025-08-20 15:15:16+0000,The initial release of NVIDIA NeMo-RL included training support through PyTorch DTensor (otherwise known as FSDP2). This backend enables native integration with...
NVIDIA Technical Blog,Announcing the Latest NVIDIA Gaming AI and Neural Rendering Technologies,https://developer.nvidia.com/blog/announcing-the-latest-nvidia-gaming-ai-and-neural-rendering-technologies/,2025-08-18 19:30:00+0000,"Today at Gamescom 2025, NVIDIA unveiled updates to NVIDIA RTX neural rendering and NVIDIA ACE generative AI technologies that enable developers to deliver..."
NVIDIA Technical Blog,Announcing the Latest NVIDIA Gaming AI and Neural Rendering Technologies,https://developer.nvidia.com/blog/announcing-the-latest-nvidia-gaming-ai-and-neural-rendering-technologies,2025-08-18 19:30:00+0000,"Today at Gamescom 2025, NVIDIA unveiled updates to NVIDIA RTX neural rendering and NVIDIA ACE generative AI technologies that enable developers to deliver..."
NVIDIA Technical Blog,Scaling AI Factories with Co-Packaged Optics for Better Power Efficiency,https://developer.nvidia.com/blog/scaling-ai-factories-with-co-packaged-optics-for-better-power-efficiency/,2025-08-18 16:00:00+0000,"As artificial intelligence redefines the computing landscape, the network has become the critical backbone shaping the data center of the future. Large language..."
NVIDIA Technical Blog,Scaling AI Factories with Co-Packaged Optics for Better Power Efficiency,https://developer.nvidia.com/blog/scaling-ai-factories-with-co-packaged-optics-for-better-power-efficiency,2025-08-18 16:00:00+0000,"As artificial intelligence redefines the computing landscape, the network has become the critical backbone shaping the data center of the future. Large language..."
Apple ML Research,UICoder: Finetuning Large Language Models to Generate User Interface Code through Automated Feedback,https://machinelearning.apple.com/research/uicoder,2025-08-15 00:00:00+0000,"Large language models (LLMs) struggle to consistently generate UI code that compiles and produces visually relevant designs. Existing approaches to improve generation rely on expensive human feedback or distilling a proprietary model. In this paper, we explore the use of automated feedback (compilers and multi-modal models) to guide LLMs to generate high-quality UI code. Our method starts with an existing LLM and iteratively produces improved models by self-generating a large synthetic dataset using an original model, applying automated tools to aggressively filter, score, and de-duplicate the…"
Apple ML Research,Pitch Accent Detection Improves Pretrained Automatic Speech Recognition,https://machinelearning.apple.com/research/pitch-accent,2025-08-15 00:00:00+0000,"We show the performance of Automatic Speech Recognition (ASR) systems that use semi-supervised speech representations can be boosted by a complimentary pitch accent detection module, by introducing a joint ASR and pitch accent detection model. The pitch accent detection component of our model achieves a significant improvement on the state-of-the-art for the task, closing the gap in F1-score by 41%. Additionally, the ASR performance in joint training decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With these results, we show the importance of extending pretrained…"
NVIDIA Technical Blog,Scaling LLM Reinforcement Learning with Prolonged Training Using ProRL v2,https://developer.nvidia.com/blog/scaling-llm-reinforcement-learning-with-prolonged-training-using-prorl-v2/,2025-08-13 21:33:03+0000,"Currently, one of the most compelling questions in AI is whether large language models (LLMs) can continue to improve through sustained reinforcement learning..."
NVIDIA Technical Blog,Scaling LLM Reinforcement Learning with Prolonged Training Using ProRL v2,https://developer.nvidia.com/blog/scaling-llm-reinforcement-learning-with-prolonged-training-using-prorl-v2,2025-08-13 21:33:03+0000,"Currently, one of the most compelling questions in AI is whether large language models (LLMs) can continue to improve through sustained reinforcement learning..."
NVIDIA Technical Blog,"Dynamo 0.4 Delivers 4x Faster Performance, SLO-Based Autoscaling, and Real-Time Observability",https://developer.nvidia.com/blog/dynamo-0-4-delivers-4x-faster-performance-slo-based-autoscaling-and-real-time-observability/,2025-08-13 15:30:00+0000,"The emergence of several new-frontier, open source models in recent weeks, including OpenAI’s gpt-oss and Moonshot AI’s Kimi K2, signals a wave of rapid LLM..."
NVIDIA Technical Blog,"Dynamo 0.4 Delivers 4x Faster Performance, SLO-Based Autoscaling, and Real-Time Observability",https://developer.nvidia.com/blog/dynamo-0-4-delivers-4x-faster-performance-slo-based-autoscaling-and-real-time-observability,2025-08-13 15:30:00+0000,"The emergence of several new-frontier, open source models in recent weeks, including OpenAI’s gpt-oss and Moonshot AI’s Kimi K2, signals a wave of rapid LLM..."
Apple ML Research,Apple Workshop on Privacy-Preserving Machine Learning 2025,https://machinelearning.apple.com/updates/ppml-2025,2025-08-12 00:00:00+0000,"Apple believes that privacy is a fundamental human right. As AI experiences become increasingly personal and a part of people's daily lives, it's important that novel privacy-preserving techniques are created in parallel to advancing AI capabilities.
Apple's fundamental research has consistently pushed the state-of-the-art in using differential privacy with machine learning, and earlier this year, we hosted the Workshop on Privacy-Preserving Machine Learning (PPML). This two-day hybrid event brought together Apple and members of the broader research community to discuss the state of the art in…"
NVIDIA Technical Blog,Announcing General Availability for NVIDIA Isaac Sim 5.0 and NVIDIA Isaac Lab 2.2,https://developer.nvidia.com/blog/isaac-sim-and-isaac-lab-are-now-available-for-early-developer-preview/,2025-08-11 15:00:00+0000,"At SIGGRAPH 2025, NVIDIA released general access for NVIDIA Isaac Sim and NVIDIA Isaac Lab reference robotics simulation and learning frameworks. Now available..."
NVIDIA Technical Blog,Announcing General Availability for NVIDIA Isaac Sim 5.0 and NVIDIA Isaac Lab 2.2,https://developer.nvidia.com/blog/isaac-sim-and-isaac-lab-are-now-available-for-early-developer-preview,2025-08-11 15:00:00+0000,"At SIGGRAPH 2025, NVIDIA released general access for NVIDIA Isaac Sim and NVIDIA Isaac Lab reference robotics simulation and learning frameworks. Now available..."
NVIDIA Technical Blog,R²D²: Boost Robot Training with World Foundation Models and Workflows from NVIDIA Research,https://developer.nvidia.com/blog/r2d2-boost-robot-training-with-world-foundation-models-and-workflows-from-nvidia-research/,2025-08-08 18:33:16+0000,"As physical AI systems advance, the demand for richly labeled datasets is accelerating beyond what we can manually capture in the real world. World foundation..."
NVIDIA Technical Blog,Efficient Transforms in cuDF Using JIT Compilation,https://developer.nvidia.com/blog/efficient-transforms-in-cudf-using-jit-compilation/,2025-08-07 21:06:42+0000,"RAPIDS cuDF offers a broad set of ETL algorithms for processing data with GPUs. For pandas users, cuDF accelerated algorithms are available with the zero code..."
NVIDIA Technical Blog,Efficient Transforms in cuDF Using JIT Compilation,https://developer.nvidia.com/blog/efficient-transforms-in-cudf-using-jit-compilation,2025-08-07 21:06:42+0000,"RAPIDS cuDF offers a broad set of ETL algorithms for processing data with GPUs. For pandas users, cuDF accelerated algorithms are available with the zero code..."
NVIDIA Technical Blog,Train with Terabyte-Scale Datasets on a Single NVIDIA Grace Hopper Superchip Using XGBoost 3.0,https://developer.nvidia.com/blog/train-with-terabyte-scale-datasets-on-a-single-nvidia-grace-hopper-superchip-using-xgboost-3-0/,2025-08-07 18:25:36+0000,Gradient-boosted decision trees (GBDTs) power everything from real-time fraud filters to petabyte-scale demand forecasts. XGBoost open source library has long...
NVIDIA Technical Blog,Train with Terabyte-Scale Datasets on a Single NVIDIA Grace Hopper Superchip Using XGBoost 3.0,https://developer.nvidia.com/blog/train-with-terabyte-scale-datasets-on-a-single-nvidia-grace-hopper-superchip-using-xgboost-3-0,2025-08-07 18:25:36+0000,Gradient-boosted decision trees (GBDTs) power everything from real-time fraud filters to petabyte-scale demand forecasts. XGBoost open source library has long...
NVIDIA Technical Blog,How Hackers Exploit AI’s Problem-Solving Instincts,https://developer.nvidia.com/blog/how-hackers-exploit-ais-problem-solving-instincts/,2025-08-07 16:00:00+0000,"As multimodal AI models advance from perception to reasoning, and even start acting autonomously, new attack surfaces emerge. These threats don’t just target..."
NVIDIA Technical Blog,How Hackers Exploit AI’s Problem-Solving Instincts,https://developer.nvidia.com/blog/how-hackers-exploit-ais-problem-solving-instincts,2025-08-07 16:00:00+0000,"As multimodal AI models advance from perception to reasoning, and even start acting autonomously, new attack surfaces emerge. These threats don’t just target..."
NVIDIA Technical Blog,NVIDIA Accelerates OpenAI gpt-oss Models Delivering 1.5 M TPS Inference on NVIDIA GB200 NVL72,https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge/,2025-08-05 17:10:00+0000,NVIDIA and OpenAI began pushing the boundaries of AI with the launch of NVIDIA DGX back in 2016. The collaborative AI innovation continues with the OpenAI...
NVIDIA Technical Blog,NVIDIA Accelerates OpenAI gpt-oss Models Delivering 1.5 M TPS Inference on NVIDIA GB200 NVL72,https://developer.nvidia.com/blog/delivering-1-5-m-tps-inference-on-nvidia-gb200-nvl72-nvidia-accelerates-openai-gpt-oss-models-from-cloud-to-edge,2025-08-05 17:10:00+0000,NVIDIA and OpenAI began pushing the boundaries of AI with the launch of NVIDIA DGX back in 2016. The collaborative AI innovation continues with the OpenAI...
NVIDIA Technical Blog,How to Enhance RAG Pipelines with Reasoning Using NVIDIA Llama Nemotron Models,https://developer.nvidia.com/blog/how-to-enhance-rag-pipelines-with-reasoning-using-nvidia-llama-nemotron-models/,2025-08-04 17:00:00+0000,A key challenge for retrieval-augmented generation (RAG) systems is handling user queries that lack explicit clarity or carry implicit intent. Users often...
NVIDIA Technical Blog,How to Enhance RAG Pipelines with Reasoning Using NVIDIA Llama Nemotron Models,https://developer.nvidia.com/blog/how-to-enhance-rag-pipelines-with-reasoning-using-nvidia-llama-nemotron-models,2025-08-04 17:00:00+0000,A key challenge for retrieval-augmented generation (RAG) systems is handling user queries that lack explicit clarity or carry implicit intent. Users often...
TechCrunch AI,Perplexity accused of scraping websites that explicitly blocked AI scraping,https://techcrunch.com/2025/08/04/perplexity-accused-of-scraping-websites-that-explicitly-blocked-ai-scraping/,2025-08-04 15:41:39+0000,"Internet giant Cloudflare says it detected Perplexity crawling and scraping websites, even after customers had added technical blocks telling Perplexity not to scrape their pages."
NVIDIA Technical Blog,Optimizing LLMs for Performance and Accuracy with Post-Training Quantization,https://developer.nvidia.com/blog/optimizing-llms-for-performance-and-accuracy-with-post-training-quantization/,2025-08-01 21:27:23+0000,"Quantization is a core tool for developers aiming to improve inference performance with minimal overhead. It delivers significant gains in latency, throughput,..."
NVIDIA Technical Blog,Optimizing LLMs for Performance and Accuracy with Post-Training Quantization,https://developer.nvidia.com/blog/optimizing-llms-for-performance-and-accuracy-with-post-training-quantization,2025-08-01 21:27:23+0000,"Quantization is a core tool for developers aiming to improve inference performance with minimal overhead. It delivers significant gains in latency, throughput,..."
NVIDIA Technical Blog,Securing Agentic AI: How Semantic Prompt Injections Bypass AI Guardrails,https://developer.nvidia.com/blog/securing-agentic-ai-how-semantic-prompt-injections-bypass-ai-guardrails/,2025-07-31 16:58:07+0000,"Prompt injection, where adversaries manipulate inputs to make large language models behave in unintended ways, has long posed a threat to AI systems since the..."
NVIDIA Technical Blog,Securing Agentic AI: How Semantic Prompt Injections Bypass AI Guardrails,https://developer.nvidia.com/blog/securing-agentic-ai-how-semantic-prompt-injections-bypass-ai-guardrails,2025-07-31 16:58:07+0000,"Prompt injection, where adversaries manipulate inputs to make large language models behave in unintended ways, has long posed a threat to AI systems since the..."
NVIDIA Technical Blog,FourCastNet 3 Enables Fast and Accurate Large Ensemble Weather Forecasting with Scalable Geometric ML,https://developer.nvidia.com/blog/fourcastnet-3-enables-fast-and-accurate-large-ensemble-weather-forecasting-with-scalable-geometric-ml/,2025-07-29 17:12:32+0000,"FourCastNet3 (FCN3) is the latest AI global weather forecasting system from NVIDIA Earth-2. FCN3 offers an unprecedented combination of probabilistic skill,..."
NVIDIA Technical Blog,FourCastNet 3 Enables Fast and Accurate Large Ensemble Weather Forecasting with Scalable Geometric ML,https://developer.nvidia.com/blog/fourcastnet-3-enables-fast-and-accurate-large-ensemble-weather-forecasting-with-scalable-geometric-ml,2025-07-29 17:12:32+0000,"FourCastNet3 (FCN3) is the latest AI global weather forecasting system from NVIDIA Earth-2. FCN3 offers an unprecedented combination of probabilistic skill,..."
NVIDIA Technical Blog,Building CAD to USD Workflows with NVIDIA Omniverse,https://developer.nvidia.com/blog/building-cad-to-usd-workflows-with-nvidia-omniverse/,2025-07-29 16:30:00+0000,"Transferring 3D data between applications has long been a challenge, especially with proprietary formats such as native computer-aided design (CAD) files. CAD..."
NVIDIA Technical Blog,Building CAD to USD Workflows with NVIDIA Omniverse,https://developer.nvidia.com/blog/building-cad-to-usd-workflows-with-nvidia-omniverse,2025-07-29 16:30:00+0000,"Transferring 3D data between applications has long been a challenge, especially with proprietary formats such as native computer-aided design (CAD) files. CAD..."
NVIDIA Technical Blog,Bringing Verifiable Trust to AI Models: Model Signing in NGC,https://developer.nvidia.com/blog/bringing-verifiable-trust-to-ai-models-model-signing-in-ngc/,2025-07-28 17:00:00+0000,"AI is entering a new era—one defined by agents that reason, plan, and take action. These agentic systems dynamically interact with APIs, tools, and even the..."
NVIDIA Technical Blog,Bringing Verifiable Trust to AI Models: Model Signing in NGC,https://developer.nvidia.com/blog/bringing-verifiable-trust-to-ai-models-model-signing-in-ngc,2025-07-28 17:00:00+0000,"AI is entering a new era—one defined by agents that reason, plan, and take action. These agentic systems dynamically interact with APIs, tools, and even the..."
NVIDIA Technical Blog,How New GB300 NVL72 Features Provide Steady Power for AI,https://developer.nvidia.com/blog/how-new-gb300-nvl72-features-provide-steady-power-for-ai/,2025-07-28 16:00:00+0000,"The electrical grid is designed to support loads that are relatively steady, such as lighting, household appliances, and industrial machines that operate at..."
NVIDIA Technical Blog,How New GB300 NVL72 Features Provide Steady Power for AI,https://developer.nvidia.com/blog/how-new-gb300-nvl72-features-provide-steady-power-for-ai,2025-07-28 16:00:00+0000,"The electrical grid is designed to support loads that are relatively steady, such as lighting, household appliances, and industrial machines that operate at..."
NVIDIA Technical Blog,Double PyTorch Inference Speed for Diffusion Models Using Torch-TensorRT,https://developer.nvidia.com/blog/double-pytorch-inference-speed-for-diffusion-models-using-torch-tensorrt/,2025-07-24 20:13:37+0000,NVIDIA TensorRT is an AI inference library built to optimize machine learning models for deployment on NVIDIA GPUs. TensorRT targets dedicated hardware in...
NVIDIA Technical Blog,Double PyTorch Inference Speed for Diffusion Models Using Torch-TensorRT,https://developer.nvidia.com/blog/double-pytorch-inference-speed-for-diffusion-models-using-torch-tensorrt,2025-07-24 20:13:37+0000,NVIDIA TensorRT is an AI inference library built to optimize machine learning models for deployment on NVIDIA GPUs. TensorRT targets dedicated hardware in...
NVIDIA Technical Blog,Optimizing Vector Search for Indexing and Real-Time Retrieval with NVIDIA cuVS,https://developer.nvidia.com/blog/optimizing-vector-search-for-indexing-and-real-time-retrieval-with-nvidia-cuvs/,2025-07-24 19:45:40+0000,"AI-powered search demands high-performance indexing, low-latency retrieval, and seamless scalability. NVIDIA cuVS brings GPU-accelerated vector search and..."
NVIDIA Technical Blog,Serverless Distributed Data Processing with Apache Spark and NVIDIA AI on Azure,https://developer.nvidia.com/blog/serverless-distributed-data-processing-with-apache-spark-and-nvidia-ai-on-azure/,2025-07-23 17:30:00+0000,The process of converting vast libraries of text into numerical representations known as embeddings is essential for generative AI. Various technologies—from...
NVIDIA Technical Blog,Serverless Distributed Data Processing with Apache Spark and NVIDIA AI on Azure,https://developer.nvidia.com/blog/serverless-distributed-data-processing-with-apache-spark-and-nvidia-ai-on-azure,2025-07-23 17:30:00+0000,The process of converting vast libraries of text into numerical representations known as embeddings is essential for generative AI. Various technologies—from...
NVIDIA Technical Blog,Understanding NCCL Tuning to Accelerate GPU-to-GPU Communication,https://developer.nvidia.com/blog/understanding-nccl-tuning-to-accelerate-gpu-to-gpu-communication/,2025-07-22 17:56:47+0000,"The NVIDIA Collective Communications Library (NCCL) is essential for fast GPU-to-GPU communication in AI workloads, using various optimizations and tuning to..."
NVIDIA Technical Blog,Understanding NCCL Tuning to Accelerate GPU-to-GPU Communication,https://developer.nvidia.com/blog/understanding-nccl-tuning-to-accelerate-gpu-to-gpu-communication,2025-07-22 17:56:47+0000,"The NVIDIA Collective Communications Library (NCCL) is essential for fast GPU-to-GPU communication in AI workloads, using various optimizations and tuning to..."
NVIDIA Technical Blog,Kimi-K2-Instruct Now Available as NVIDIA NIM,https://build.nvidia.com/moonshotai/kimi-k2-instruct#new_tab,2025-07-22 15:36:56+0000,Try the new 1T-parameter open source MoE LLM today.
NVIDIA Technical Blog,Traditional RAG vs. Agentic RAG—Why AI Agents Need Dynamic Knowledge to Get Smarter,https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter/,2025-07-21 16:00:00+0000,"Ever relied on an old GPS that didn’t know about the new highway bypass, or a sudden road closure? It might get you to your destination, but not in the most..."
NVIDIA Technical Blog,Traditional RAG vs. Agentic RAG—Why AI Agents Need Dynamic Knowledge to Get Smarter,https://developer.nvidia.com/blog/traditional-rag-vs-agentic-rag-why-ai-agents-need-dynamic-knowledge-to-get-smarter,2025-07-21 16:00:00+0000,"Ever relied on an old GPS that didn’t know about the new highway bypass, or a sudden road closure? It might get you to your destination, but not in the most..."
NVIDIA Technical Blog,Hackathon Winners Bring Agentic AI to Life with the NVIDIA NeMo Agent Toolkit,https://developer.nvidia.com/blog/hackathon-winners-bring-agentic-ai-to-life-with-the-nvidia-nemo-agent-toolkit/,2025-07-17 20:13:03+0000,"The best way to learn a new toolkit is to build something real, and that’s exactly what developers did at the recent NVIDIA NeMo Agent Toolkit Hackathon. Over..."
NVIDIA Technical Blog,Hackathon Winners Bring Agentic AI to Life with the NVIDIA NeMo Agent Toolkit,https://developer.nvidia.com/blog/hackathon-winners-bring-agentic-ai-to-life-with-the-nvidia-nemo-agent-toolkit,2025-07-17 20:13:03+0000,"The best way to learn a new toolkit is to build something real, and that’s exactly what developers did at the recent NVIDIA NeMo Agent Toolkit Hackathon. Over..."
NVIDIA Technical Blog,NVIDIA Canary‑Qwen‑2.5B: Open‑Source ASR/LLM for Superior Transcription and Summarization,https://huggingface.co/spaces/hf-audio/open_asr_leaderboard#new_tab,2025-07-17 17:17:27+0000,"Top‑ranked on the HuggingFace Open‑ASR leaderboard, the model is production‑ready."
NVIDIA Technical Blog,NVIDIA Canary‑Qwen‑2.5B: Open‑Source ASR/LLM for Superior Transcription and Summarization,https://huggingface.co/spaces/hf-audio/open_asr_leaderboard,2025-07-17 17:17:27+0000,"Top‑ranked on the HuggingFace Open‑ASR leaderboard, the model is production‑ready."
NVIDIA Technical Blog,New Learning Pathway: Deploy AI Models with NVIDIA NIM on GKE,https://developers.google.com/learn/pathways/deploy-faster-gen-ai-models-nvidia-gke?utm_source=mindshare_program&utm_medium=partner&utm_campaign=FY25-Q3-NVIDIA-GDP-Learning&utm_content=nvidia-newsletter&utm_term=-#new_tab,2025-07-17 16:00:00+0000,Get hands-on with Google Kubernetes Engine (GKE) and NVIDIA NIM when you join the new Google Cloud and NVIDIA community.
NVIDIA Technical Blog,Driving AI-Powered Robotics Development with NVIDIA Isaac for Healthcare,https://developer.nvidia.com/blog/driving-ai-powered-robotics-development-with-nvidia-isaac-for-healthcare/,2025-07-17 06:00:00+0000,"By 2030, the World Health Organization projects a global shortage of over 15 million healthcare workers, including surgeons, radiologists, and nurses. In the..."
NVIDIA Technical Blog,R²D²: Training Generalist Robots with NVIDIA Research Workflows and World Foundation Models,https://developer.nvidia.com/blog/r2d2-training-generalist-robots-with-nvidia-research-workflows-and-world-foundation-models/,2025-07-16 15:14:28+0000,A major challenge in robotics is training robots to perform new tasks without the massive effort of collecting and labeling datasets for every new task and...
NVIDIA Technical Blog,Accelerate AI Model Orchestration with NVIDIA Run:ai on AWS,https://developer.nvidia.com/blog/accelerate-ai-model-orchestration-with-nvidia-runai-on-aws/,2025-07-15 13:23:59+0000,"When it comes to developing and deploying advanced AI models, access to scalable, efficient GPU infrastructure is critical. But managing this infrastructure..."
NVIDIA Technical Blog,Enabling Fast Inference and Resilient Training with NCCL 2.27,https://developer.nvidia.com/blog/enabling-fast-inference-and-resilient-training-with-nccl-2-27/,2025-07-14 19:23:44+0000,"As AI workloads scale, fast and reliable GPU communication becomes vital, not just for training, but increasingly for inference at scale. The NVIDIA Collective..."
NVIDIA Technical Blog,Upcoming Livestream: Techniques for Building High-Performance RAG Applications,https://www.addevent.com/event/Ah26137584,2025-07-14 17:00:00+0000,"Discover leaderboard-winning RAG techniques, integration strategies, and deployment best practices."
NVIDIA Technical Blog,Enhancing Multilingual Human-Like Speech and Voice Cloning with NVIDIA Riva TTS,https://developer.nvidia.com/blog/enhancing-multilingual-human-like-speech-and-voice-cloning-with-nvidia-riva-tts/,2025-07-14 16:30:00+0000,"While speech AI is used to build digital assistants and voice agents, its impact extends far beyond these applications. Core technologies like text-to-speech..."
NVIDIA Technical Blog,Just Released: NVDIA Run:ai 2.22,https://run-ai-docs.nvidia.com/self-hosted/getting-started/whats-new/whats-new-2-22,2025-07-14 16:00:00+0000,"NVDIA Run:ai 2.22 is now here. It brings advanced inference capabilities, smarter workload management, and more controls."
NVIDIA Technical Blog,Improving Synthetic Data Augmentation and Human Action Recognition with SynthDa,https://developer.nvidia.com/blog/improving-synthetic-data-augmentation-and-human-action-recognition-with-synthda/,2025-07-11 14:55:56+0000,"Human action recognition is a capability in AI systems designed for safety-critical applications, such as surveillance, eldercare, and industrial monitoring...."
NVIDIA Technical Blog,From Terabytes to Turnkey: AI-Powered Climate Models Go Mainstream,https://developer.nvidia.com/blog/from-terabytes-to-turnkey-ai-powered-climate-models-go-mainstream/,2025-07-10 19:00:00+0000,"In the race to understand our planet’s changing climate, speed and accuracy are everything. But today’s most widely used climate simulators often struggle:..."
NVIDIA Technical Blog,InfiniBand Multilayered Security Protects Data Centers and AI Workloads,https://developer.nvidia.com/blog/infiniband-multilayered-security-protects-data-centers-and-ai-workloads/,2025-07-10 17:00:00+0000,"In today’s data-driven world, security isn't just a feature—it's the foundation. With the exponential growth of AI, HPC, and hyperscale cloud computing, the..."
NVIDIA Technical Blog,Accelerating Video Production and Customization with GliaCloud and NVIDIA Omniverse Libraries,https://developer.nvidia.com/blog/accelerating-video-production-and-customization-with-gliacloud-and-nvidia-omniverse-libraries/,2025-07-10 16:30:00+0000,"The proliferation of generative AI video models, along with the new workflows these models have introduced, has significantly accelerated production efficiency..."
NVIDIA Technical Blog,Reinforcement Learning with NVIDIA NeMo-RL: Reproducing a DeepScaleR Recipe Using GRPO,https://developer.nvidia.com/blog/reinforcement-learning-with-nvidia-nemo-rl-reproducing-a-deepscaler-recipe-using-grpo/,2025-07-09 19:00:00+0000,"Reinforcement learning (RL) is the backbone of interactive AI. It is fundamental for teaching agents to reason and learn from human preferences, enabling..."
TechCrunch AI,Obvio’s stop sign cameras use AI to root out unsafe drivers,https://techcrunch.com/2025/06/04/obvios-stop-sign-cameras-use-ai-to-root-out-unsafe-drivers/,2025-06-04 14:00:00+0000,"American streets are incredibly dangerous for pedestrians. A San Carlos, California-based startup called Obvio thinks it can change that by installing cameras at stop signs -- a solution the founders also say won’t create a panopticon."
TechCrunch AI,Breakneck data center growth challenges Microsoft’s sustainability goals,https://techcrunch.com/2025/06/02/breakneck-data-center-growth-challenges-microsofts-sustainability-goals/,2025-06-02 18:07:05+0000,Microsoft's sustainability goals are imperiled by its push into AI and cloud services.
TechCrunch AI,Gridcare thinks more than 100 GW of data center capacity is hiding in the grid,https://techcrunch.com/2025/05/27/gridcare-thinks-more-than-100-gw-of-data-center-capacity-is-hiding-in-the-grid/,2025-05-27 12:00:00+0000,Gridcare raised $13.3 million for its data platform that finds underutilized capacity on the electrical grid.
TechCrunch AI,Meta adds another 650 MW of solar power to its AI push,https://techcrunch.com/2025/05/22/meta-adds-another-650-mw-of-solar-power-to-its-ai-push/,2025-05-22 16:49:53+0000,The company already has more than 12 gigawatts of capacity in its renewable power portfolio.
TechCrunch AI,Data centers love solar: Here’s a comprehensive guide to deals over 100 megawatts,https://techcrunch.com/2025/03/30/data-centers-love-solar-heres-a-comprehensive-guide-to-deals-over-100-megawatts/,2025-03-30 14:00:00+0000,New and expanded data centers are expected to double the sector’s power demand by 2029 as tech companies rush to capitalize on AI.
TechCrunch AI,Nvidia thinks AI can solve electrical grid problems caused by AI,https://techcrunch.com/2025/03/20/nvidia-thinks-ai-can-solve-electrical-grid-problems-caused-by-ai/,2025-03-20 16:41:12+0000,The Open Power AI Consortium says it will use domain-specific AI models to tackle problems in the power industry.
TechCrunch AI,Solar notches another win as Microsoft adds 475 MW to power its AI data centers,https://techcrunch.com/2025/03/20/solar-notches-another-win-as-microsoft-adds-475-mw-to-power-its-ai-data-centers/,2025-03-20 14:57:11+0000,The company recently signed a deal with energy provider AES for three solar projects across the Midwest.
TechCrunch AI,ElevenLabs now lets authors create and publish audiobooks on its own platform,https://techcrunch.com/2025/02/25/elevenlabs-is-now-letting-authors-create-and-publish-audiobooks-on-its-own-platform/,2025-02-26 03:45:45+0000,"Voice AI company ElevenLabs is now letting authors publish AI-generated audiobooks on its own Reader app, TechCrunch has learned and the company confirmed. The announcement comes days after the company partnered with Spotify for AI-narrated audiobooks. ElevenLabs, which raised a $180 million mega-round last month, started inviting authors to try out their publishing program through […]"
TechCrunch AI,"YouTube AI updates include auto dubbing expansion, age ID tech, and more",https://techcrunch.com/2025/02/11/youtube-ai-updates-to-include-expansion-of-auto-dubbing-age-identifying-tech-and-more/,2025-02-11 14:57:22+0000,"In his annual letter, YouTube CEO Neal Mohan dubbed AI one of the company’s four “big bets” for 2025. The executive pointed to the company’s investments in AI tools for creators, including ones for video ideas, thumbnails, and language translation. The latter feature will roll out to all creators in YouTube’s Partner Program this month, […]"
TechCrunch AI,Self Inspection raises $3M for its AI-powered vehicle inspections,https://techcrunch.com/2025/02/07/self-inspection-raises-3m-for-its-ai-powered-vehicle-inspections/,2025-02-07 18:00:44+0000,"A number of startups are racing to make vehicle inspections faster, easier, and cheaper. Self Inspection, a startup based in San Diego, thinks it has them all beat with its AI-powered service — and now it has convinced outside investors. Self Inspection, founded in 2021, is set to announce Thursday it’s raised $3 million in […]"
TechCrunch AI,Meta turns to solar — again — in its data center-building boom,https://techcrunch.com/2025/01/31/meta-turns-to-solar-again-in-its-data-center-building-boom/,2025-01-31 19:38:51+0000,"The announcement comes as Meta CEO Mark Zuckerberg maintains the company’s ambitious AI strategy, which will require hefty capital investments in data centers."
TechCrunch AI,Gridware’s boxes literally listen to power lines to find outages,https://techcrunch.com/2025/01/08/gridwares-boxes-literally-listen-to-power-lines-to-find-outages/,2025-01-08 19:00:00+0000,Gridware's sensors listen for sounds that the company’s software has been trained to identify as different hazards to the grid.
